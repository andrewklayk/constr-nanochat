'Starting'
h02
Resolved 97 packages in 11ms
Uninstalled 2 packages in 513ms
warning: Failed to hardlink files; falling back to full copy. This may lead to degraded performance.
         If the cache and target directories are on different filesystems, hardlinking may not be supported.
         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.
Installed 1 package in 537ms
 - pip==25.3
 - setuptools==80.10.1
 + setuptools==80.9.0
Resolved 7 packages in 68ms
Prepared 2 packages in 1ms
Uninstalled 1 package in 191ms
warning: Failed to hardlink files; falling back to full copy. This may lead to degraded performance.
         If the cache and target directories are on different filesystems, hardlinking may not be supported.
         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.
Installed 2 packages in 519ms
 + pip==25.3
 - setuptools==80.9.0
 + setuptools==80.10.1
Reset report and wrote header to /home/kliacand/.cache/nanochat/report/header.md
Waiting for dataset download to complete...
Autodetected device type: cuda
2026-01-21 14:10:46,584 - nanochat.common - [32m[1mINFO[0m - Distributed world size: 2
2026-01-21 14:10:46,587 - nanochat.checkpoint_manager - [32m[1mINFO[0m - Loading model from /home/kliacand/.cache/nanochat/mid_checkpoints/d12 with step 790
2026-01-21 14:10:50,698 - nanochat.checkpoint_manager - [32m[1mINFO[0m - Patching missing window_pattern in model config to 'L'
2026-01-21 14:10:50,698 - nanochat.checkpoint_manager - [32m[1mINFO[0m - Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 12, 'n_head': 6, 'n_kv_head': 6, 'n_embd': 768, 'window_pattern': 'L'}
2026-01-21 14:10:50,763 - nanochat.checkpoint_manager - [32m[1mINFO[0m - loaded state dict
2026-01-21 14:10:50,945 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:10:50,949 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:10:50,950 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:10:50,954 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:10:51,069 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:51,071 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:51,423 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:51,430 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:51,546 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/allenai/ai2_arc/revision/210d026faf9955653af8916fad021475a3f00453 "HTTP/1.1 200 OK"
2026-01-21 14:10:51,547 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/allenai/ai2_arc/revision/210d026faf9955653af8916fad021475a3f00453 "HTTP/1.1 200 OK"
2026-01-21 14:10:51,661 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:10:51,662 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:10:51,822 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:10:51,854 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:10:51,941 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/allenai/ai2_arc/tree/210d026faf9955653af8916fad021475a3f00453/ARC-Challenge?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:52,060 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/allenai/ai2_arc/tree/210d026faf9955653af8916fad021475a3f00453/ARC-Challenge?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:52,063 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/allenai/ai2_arc/tree/210d026faf9955653af8916fad021475a3f00453?recursive=false&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:52,174 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/allenai/ai2_arc/tree/210d026faf9955653af8916fad021475a3f00453?recursive=false&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:52,180 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:10:52,288 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:10:52,300 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/allenai/ai2_arc/tree/210d026faf9955653af8916fad021475a3f00453/ARC-Easy?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:52,466 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:10:52,470 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:10:52,586 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:52,596 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/allenai/ai2_arc/tree/210d026faf9955653af8916fad021475a3f00453/ARC-Easy?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:52,705 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:52,719 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-01-21 14:10:52,719 - huggingface_hub.utils._http - [33m[1mWARNING[0m - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-01-21 14:10:52,723 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:10:52,824 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:10:52,835 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:52,947 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:10:52,955 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:53,064 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:10:53,070 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:10:53,191 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:10:53,194 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:10:53,197 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/openai/gsm8k/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/README.md "HTTP/1.1 200 OK"
2026-01-21 14:10:53,309 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:10:53,313 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/gsm8k.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:53,431 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/openai/gsm8k/openai/gsm8k.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:53,433 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:10:53,438 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/openai/gsm8k/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/README.md "HTTP/1.1 200 OK"
2026-01-21 14:10:53,550 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/openai/gsm8k/revision/cc7b047b6e5bb11b4f1af84efc572db110a51b3c "HTTP/1.1 200 OK"
2026-01-21 14:10:53,553 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/gsm8k.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:53,673 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/openai/gsm8k/openai/gsm8k.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:53,696 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:10:53,792 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/openai/gsm8k/revision/cc7b047b6e5bb11b4f1af84efc572db110a51b3c "HTTP/1.1 200 OK"
2026-01-21 14:10:53,819 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=openai/gsm8k "HTTP/1.1 200 OK"
2026-01-21 14:10:53,905 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:10:53,934 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/openai/gsm8k/tree/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:54,033 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=openai/gsm8k "HTTP/1.1 200 OK"
2026-01-21 14:10:54,047 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/openai/gsm8k/tree/cc7b047b6e5bb11b4f1af84efc572db110a51b3c?recursive=false&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:54,150 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/openai/gsm8k/tree/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:54,163 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:10:54,273 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/openai/gsm8k/tree/cc7b047b6e5bb11b4f1af84efc572db110a51b3c?recursive=false&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:54,321 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:10:54,325 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/HuggingFaceTB/smol-smoltalk/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/README.md "HTTP/1.1 200 OK"
2026-01-21 14:10:54,385 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:10:54,553 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:10:54,559 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/HuggingFaceTB/smol-smoltalk/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/README.md "HTTP/1.1 200 OK"
2026-01-21 14:10:54,606 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/smol-smoltalk.py "HTTP/1.1 404 Not Found"
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-01-21 14:10:54,606 - huggingface_hub.utils._http - [33m[1mWARNING[0m - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-01-21 14:10:54,672 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/smol-smoltalk.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:54,727 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/HuggingFaceTB/smol-smoltalk/HuggingFaceTB/smol-smoltalk.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:54,794 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/HuggingFaceTB/smol-smoltalk/HuggingFaceTB/smol-smoltalk.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:54,843 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/HuggingFaceTB/smol-smoltalk/revision/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc "HTTP/1.1 200 OK"
2026-01-21 14:10:54,955 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/HuggingFaceTB/smol-smoltalk/revision/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc "HTTP/1.1 200 OK"
2026-01-21 14:10:55,006 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:10:55,067 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:10:55,134 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=HuggingFaceTB/smol-smoltalk "HTTP/1.1 200 OK"
2026-01-21 14:10:55,194 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=HuggingFaceTB/smol-smoltalk "HTTP/1.1 200 OK"
2026-01-21 14:10:55,328 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/HuggingFaceTB/smol-smoltalk/tree/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/data?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:55,344 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/HuggingFaceTB/smol-smoltalk/tree/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/data?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:55,462 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/HuggingFaceTB/smol-smoltalk/tree/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc?recursive=false&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:55,466 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/HuggingFaceTB/smol-smoltalk/tree/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc?recursive=false&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:10:55,604 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:10:55,703 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:10:56,168 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:10:56,173 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/HuggingFaceTB/smol-smoltalk/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/README.md "HTTP/1.1 200 OK"
2026-01-21 14:10:56,213 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:10:56,218 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/HuggingFaceTB/smol-smoltalk/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/README.md "HTTP/1.1 200 OK"
2026-01-21 14:10:56,285 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/smol-smoltalk.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:56,334 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/smol-smoltalk.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:56,407 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/HuggingFaceTB/smol-smoltalk/HuggingFaceTB/smol-smoltalk.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:56,454 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/HuggingFaceTB/smol-smoltalk/HuggingFaceTB/smol-smoltalk.py "HTTP/1.1 404 Not Found"
2026-01-21 14:10:56,522 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:10:56,569 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:10:56,645 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=HuggingFaceTB/smol-smoltalk "HTTP/1.1 200 OK"
2026-01-21 14:10:56,689 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=HuggingFaceTB/smol-smoltalk "HTTP/1.1 200 OK"
2026-01-21 14:10:56,763 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/dataset_infos.json "HTTP/1.1 404 Not Found"
Target examples per step: 32
Device batch size: 4
Examples per step is device_batch_size * ddp_world_size: 8
=> Setting grad accum steps: 4
Scaling the LR for the AdamW parameters ‚àù1/‚àö(768/768) = 1.000000
2026-01-21 14:10:56,806 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/dataset_infos.json "HTTP/1.1 404 Not Found"
Step 00000 | Validation loss: 1.141274
Step 00000/03096 | Training loss: 0.866440 | Training constraint: -3.390364, duals [4.536869]| lrm: 1.000000| num_tokens: 3,233
Step 00001/03096 | Training loss: 1.083702 | Training constraint: -1.829741, duals [4.3538947]| lrm: 0.999677| num_tokens: 2,099
Step 00002/03096 | Training loss: 1.085205 | Training constraint: 2.292480, duals [4.5831428]| lrm: 0.999354| num_tokens: 3,118
Step 00003/03096 | Training loss: 0.828860 | Training constraint: -2.898049, duals [4.3060293]| lrm: 0.999031| num_tokens: 6,115
Step 00004/03096 | Training loss: 1.025696 | Training constraint: 0.656649, duals [4.371694]| lrm: 0.998708| num_tokens: 4,094
Step 00005/03096 | Training loss: 1.338234 | Training constraint: 3.173737, duals [4.689068]| lrm: 0.998385| num_tokens: 5,273
Step 00006/03096 | Training loss: 1.152060 | Training constraint: -1.686842, duals [4.5203834]| lrm: 0.998062| num_tokens: 2,361
Step 00007/03096 | Training loss: 0.872771 | Training constraint: -0.156233, duals [4.5047603]| lrm: 0.997739| num_tokens: 2,858
Step 00008/03096 | Training loss: 1.039135 | Training constraint: -1.422842, duals [4.362476]| lrm: 0.997416| num_tokens: 3,551
Step 00009/03096 | Training loss: 0.941340 | Training constraint: 3.677077, duals [4.7301836]| lrm: 0.997093| num_tokens: 2,576
Step 00010/03096 | Training loss: 1.042679 | Training constraint: -1.037009, duals [4.6264825]| lrm: 0.996770| num_tokens: 2,357
Step 00011/03096 | Training loss: 1.062891 | Training constraint: -2.331718, duals [4.3933253]| lrm: 0.996447| num_tokens: 2,013
Step 00012/03096 | Training loss: 0.902110 | Training constraint: -2.879730, duals [4.1215544]| lrm: 0.996124| num_tokens: 2,177
Step 00013/03096 | Training loss: 1.064432 | Training constraint: -2.137901, duals [3.9080424]| lrm: 0.995801| num_tokens: 2,227
Step 00014/03096 | Training loss: 1.106158 | Training constraint: -2.442432, duals [3.6735659]| lrm: 0.995478| num_tokens: 2,312
Step 00015/03096 | Training loss: 1.186783 | Training constraint: -2.948818, duals [3.42062]| lrm: 0.995155| num_tokens: 2,665
Step 00016/03096 | Training loss: 1.143584 | Training constraint: -0.459839, duals [3.3746362]| lrm: 0.994832| num_tokens: 3,517
Step 00017/03096 | Training loss: 1.111634 | Training constraint: -7.947716, duals [3.0729947]| lrm: 0.994509| num_tokens: 2,072
Step 00018/03096 | Training loss: 0.997516 | Training constraint: -0.286209, duals [3.0443738]| lrm: 0.994186| num_tokens: 1,950
Step 00019/03096 | Training loss: 0.981272 | Training constraint: -1.503699, duals [2.8940039]| lrm: 0.993863| num_tokens: 5,011
Step 00020/03096 | Training loss: 0.969360 | Training constraint: -5.263978, duals [2.6443799]| lrm: 0.993540| num_tokens: 3,213
Step 00021/03096 | Training loss: 0.737699 | Training constraint: -4.452015, duals [2.419209]| lrm: 0.993217| num_tokens: 2,220
Step 00022/03096 | Training loss: 1.023578 | Training constraint: -8.105689, duals [2.195339]| lrm: 0.992894| num_tokens: 3,270
Step 00023/03096 | Training loss: 1.198093 | Training constraint: -1.756737, duals [2.0443912]| lrm: 0.992571| num_tokens: 1,511
Step 00024/03096 | Training loss: 0.995485 | Training constraint: -0.984516, duals [1.9459395]| lrm: 0.992248| num_tokens: 3,543
Step 00025/03096 | Training loss: 1.025286 | Training constraint: -19.806610, duals [1.7561251]| lrm: 0.991925| num_tokens: 2,265
Step 00026/03096 | Training loss: 0.906218 | Training constraint: -0.513683, duals [1.7047567]| lrm: 0.991602| num_tokens: 3,109
Step 00027/03096 | Training loss: 0.806055 | Training constraint: 0.237617, duals [1.7285185]| lrm: 0.991279| num_tokens: 4,858
Step 00028/03096 | Training loss: 1.067764 | Training constraint: -1.742799, duals [1.5985254]| lrm: 0.990956| num_tokens: 3,076
Step 00029/03096 | Training loss: 0.980874 | Training constraint: 1.022128, duals [1.7007382]| lrm: 0.990633| num_tokens: 5,000
Step 00030/03096 | Training loss: 0.957604 | Training constraint: -4.376134, duals [1.5471886]| lrm: 0.990310| num_tokens: 3,927
Step 00031/03096 | Training loss: 1.218274 | Training constraint: -4.114540, duals [1.4070145]| lrm: 0.989987| num_tokens: 4,184
Step 00032/03096 | Training loss: 0.843331 | Training constraint: -9.968178, duals [1.271278]| lrm: 0.989664| num_tokens: 4,271
Step 00033/03096 | Training loss: 1.051401 | Training constraint: -12.100447, duals [1.1474892]| lrm: 0.989341| num_tokens: 1,312
Step 00034/03096 | Training loss: 0.992897 | Training constraint: 1.118430, duals [1.2593322]| lrm: 0.989018| num_tokens: 4,066
Step 00035/03096 | Training loss: 0.998558 | Training constraint: -1.057670, duals [1.170885]| lrm: 0.988695| num_tokens: 2,837
Step 00036/03096 | Training loss: 0.686800 | Training constraint: -6.235271, duals [1.0592933]| lrm: 0.988372| num_tokens: 3,332
Step 00037/03096 | Training loss: 1.137085 | Training constraint: -0.596030, duals [1.0004295]| lrm: 0.988049| num_tokens: 2,261
Step 00038/03096 | Training loss: 0.917492 | Training constraint: -0.999812, duals [0.9254127]| lrm: 0.987726| num_tokens: 4,996
Step 00039/03096 | Training loss: 0.978451 | Training constraint: -8.074646, duals [0.8355229]| lrm: 0.987403| num_tokens: 3,955
Step 00040/03096 | Training loss: 1.118860 | Training constraint: 0.966863, duals [0.9322092]| lrm: 0.987080| num_tokens: 3,798
Step 00041/03096 | Training loss: 1.133188 | Training constraint: -6.315971, duals [0.84242797]| lrm: 0.986757| num_tokens: 2,576
Step 00042/03096 | Training loss: 1.156559 | Training constraint: 1.271698, duals [0.9695977]| lrm: 0.986434| num_tokens: 3,565
Step 00043/03096 | Training loss: 1.138067 | Training constraint: -6.533988, duals [0.87623495]| lrm: 0.986111| num_tokens: 3,781
Step 00044/03096 | Training loss: 1.091300 | Training constraint: -0.169300, duals [0.85930496]| lrm: 0.985788| num_tokens: 3,598
Step 00045/03096 | Training loss: 0.714143 | Training constraint: -9.570278, duals [0.77530336]| lrm: 0.985465| num_tokens: 1,755
Step 00046/03096 | Training loss: 1.050716 | Training constraint: 1.037132, duals [0.8790165]| lrm: 0.985142| num_tokens: 4,528
Step 00047/03096 | Training loss: 0.962130 | Training constraint: 4.011355, duals [1.2801521]| lrm: 0.984819| num_tokens: 4,795
Step 00048/03096 | Training loss: 1.137462 | Training constraint: -15.259431, duals [1.1548216]| lrm: 0.984496| num_tokens: 3,569
Step 00049/03096 | Training loss: 1.025703 | Training constraint: -3.071547, duals [1.050194]| lrm: 0.984173| num_tokens: 3,717
Step 00050/03096 | Training loss: 1.009900 | Training constraint: -6.642866, duals [0.9493253]| lrm: 0.983850| num_tokens: 2,861
Step 00051/03096 | Training loss: 1.359954 | Training constraint: 4.422732, duals [1.3915985]| lrm: 0.983527| num_tokens: 1,759
Step 00052/03096 | Training loss: 1.014250 | Training constraint: 5.695461, duals [1.9611444]| lrm: 0.983204| num_tokens: 4,307
Step 00053/03096 | Training loss: 1.049214 | Training constraint: -6.545868, duals [1.7797189]| lrm: 0.982881| num_tokens: 1,132
Step 00054/03096 | Training loss: 1.068331 | Training constraint: -4.496427, duals [1.6193576]| lrm: 0.982558| num_tokens: 1,910
Step 00055/03096 | Training loss: 1.101007 | Training constraint: 1.328452, duals [1.7522027]| lrm: 0.982235| num_tokens: 4,277
Step 00056/03096 | Training loss: 0.912874 | Training constraint: -10.411448, duals [1.5843546]| lrm: 0.981912| num_tokens: 2,289
Step 00057/03096 | Training loss: 0.965184 | Training constraint: 4.870898, duals [2.0714445]| lrm: 0.981589| num_tokens: 3,670
Step 00058/03096 | Training loss: 1.325064 | Training constraint: -1.585609, duals [1.9319535]| lrm: 0.981266| num_tokens: 3,745
Step 00059/03096 | Training loss: 0.979215 | Training constraint: -1.264207, duals [1.8125682]| lrm: 0.980943| num_tokens: 3,355
Step 00060/03096 | Training loss: 1.089733 | Training constraint: 1.354458, duals [1.9480139]| lrm: 0.980620| num_tokens: 3,379
Step 00061/03096 | Training loss: 1.165561 | Training constraint: -3.041910, duals [1.7843997]| lrm: 0.980297| num_tokens: 3,438
Step 00062/03096 | Training loss: 1.088542 | Training constraint: -1.355009, duals [1.6647063]| lrm: 0.979974| num_tokens: 2,553
Step 00063/03096 | Training loss: 0.919669 | Training constraint: -5.702928, duals [1.5103841]| lrm: 0.979651| num_tokens: 2,621
Step 00064/03096 | Training loss: 0.841792 | Training constraint: 0.254044, duals [1.5357885]| lrm: 0.979328| num_tokens: 1,573
Step 00065/03096 | Training loss: 0.782975 | Training constraint: -2.462180, duals [1.4061584]| lrm: 0.979005| num_tokens: 4,103
Step 00066/03096 | Training loss: 0.809920 | Training constraint: -9.245116, duals [1.2708894]| lrm: 0.978682| num_tokens: 3,904
Step 00067/03096 | Training loss: 1.006753 | Training constraint: -7.244946, duals [1.1493738]| lrm: 0.978359| num_tokens: 5,942
Step 00068/03096 | Training loss: 1.093939 | Training constraint: -1.486284, duals [1.0566572]| lrm: 0.978036| num_tokens: 4,071
Step 00069/03096 | Training loss: 1.007030 | Training constraint: -1.722994, duals [0.9671918]| lrm: 0.977713| num_tokens: 1,928
Step 00070/03096 | Training loss: 1.074060 | Training constraint: 1.531966, duals [1.1203884]| lrm: 0.977390| num_tokens: 2,132
Step 00071/03096 | Training loss: 1.098848 | Training constraint: -2.484662, duals [1.0209798]| lrm: 0.977067| num_tokens: 4,075
Step 00072/03096 | Training loss: 0.756727 | Training constraint: -4.515336, duals [0.92465323]| lrm: 0.976744| num_tokens: 5,699
Step 00073/03096 | Training loss: 1.030254 | Training constraint: 0.960851, duals [1.0207384]| lrm: 0.976421| num_tokens: 3,992
Step 00074/03096 | Training loss: 0.939482 | Training constraint: -3.053125, duals [0.92719597]| lrm: 0.976098| num_tokens: 1,726
Step 00075/03096 | Training loss: 1.147680 | Training constraint: 0.476030, duals [0.974799]| lrm: 0.975775| num_tokens: 3,592
Step 00076/03096 | Training loss: 0.884209 | Training constraint: -0.957132, duals [0.9021388]| lrm: 0.975452| num_tokens: 2,937
Step 00077/03096 | Training loss: 0.903905 | Training constraint: -6.082756, duals [0.8152699]| lrm: 0.975129| num_tokens: 3,536
Step 00078/03096 | Training loss: 1.121703 | Training constraint: -6.291861, duals [0.73638386]| lrm: 0.974806| num_tokens: 4,413
Step 00079/03096 | Training loss: 0.934472 | Training constraint: 3.033218, duals [1.0397058]| lrm: 0.974483| num_tokens: 1,126
Step 00080/03096 | Training loss: 1.070145 | Training constraint: -19.210032, duals [0.93714195]| lrm: 0.974160| num_tokens: 2,887
Step 00081/03096 | Training loss: 1.224149 | Training constraint: -4.779184, duals [0.8480218]| lrm: 0.973837| num_tokens: 2,409
Step 00082/03096 | Training loss: 1.087734 | Training constraint: -7.921127, duals [0.7654893]| lrm: 0.973514| num_tokens: 2,866
Step 00083/03096 | Training loss: 0.729716 | Training constraint: 3.098172, duals [1.0753064]| lrm: 0.973191| num_tokens: 4,730
Step 00084/03096 | Training loss: 0.919963 | Training constraint: -4.727147, duals [0.9738909]| lrm: 0.972868| num_tokens: 2,017
Step 00085/03096 | Training loss: 0.920914 | Training constraint: 2.339017, duals [1.2077926]| lrm: 0.972545| num_tokens: 3,053
Step 00086/03096 | Training loss: 1.038581 | Training constraint: 1.762846, duals [1.3840772]| lrm: 0.972222| num_tokens: 3,675
Step 00087/03096 | Training loss: 1.073469 | Training constraint: -2.682401, duals [1.2635236]| lrm: 0.971899| num_tokens: 3,514
Step 00088/03096 | Training loss: 1.115948 | Training constraint: -5.859247, duals [1.143983]| lrm: 0.971576| num_tokens: 3,496
Step 00089/03096 | Training loss: 0.911730 | Training constraint: -8.198913, duals [1.033575]| lrm: 0.971253| num_tokens: 1,844
Step 00090/03096 | Training loss: 0.921868 | Training constraint: -2.987235, duals [0.93915784]| lrm: 0.970930| num_tokens: 2,509
Step 00091/03096 | Training loss: 0.933847 | Training constraint: -11.927023, duals [0.8470908]| lrm: 0.970607| num_tokens: 1,972
Step 00092/03096 | Training loss: 0.821178 | Training constraint: -13.155334, duals [0.7637453]| lrm: 0.970284| num_tokens: 2,765
Step 00093/03096 | Training loss: 0.628939 | Training constraint: -1.330697, duals [0.69832945]| lrm: 0.969961| num_tokens: 3,831
Step 00094/03096 | Training loss: 1.095028 | Training constraint: 0.191710, duals [0.7175004]| lrm: 0.969638| num_tokens: 3,983
Step 00095/03096 | Training loss: 0.907001 | Training constraint: -3.100531, duals [0.6499013]| lrm: 0.969315| num_tokens: 3,541
Step 00096/03096 | Training loss: 1.410565 | Training constraint: -0.198231, duals [0.6300782]| lrm: 0.968992| num_tokens: 2,294
Step 00097/03096 | Training loss: 0.783819 | Training constraint: -8.467297, duals [0.5682425]| lrm: 0.968669| num_tokens: 3,888
Step 00098/03096 | Training loss: 1.074510 | Training constraint: -1.294686, duals [0.5176533]| lrm: 0.968346| num_tokens: 3,455
Step 00099/03096 | Training loss: 1.196470 | Training constraint: -2.537344, duals [0.46852815]| lrm: 0.968023| num_tokens: 4,919
Step 00100 | Validation loss: 1.144511
Step 00100/03096 | Training loss: 0.840559 | Training constraint: -2.612272, duals [0.42377615]| lrm: 0.967700| num_tokens: 3,379
Step 00101/03096 | Training loss: 1.109729 | Training constraint: -3.221673, duals [0.38279212]| lrm: 0.967377| num_tokens: 2,094
Step 00102/03096 | Training loss: 1.027087 | Training constraint: 0.058937, duals [0.3886858]| lrm: 0.967054| num_tokens: 3,245
Step 00103/03096 | Training loss: 0.900981 | Training constraint: 1.490584, duals [0.5377442]| lrm: 0.966731| num_tokens: 2,359
Step 00104/03096 | Training loss: 1.089529 | Training constraint: -4.707754, duals [0.48550537]| lrm: 0.966408| num_tokens: 2,824
Step 00105/03096 | Training loss: 0.983607 | Training constraint: 4.156701, duals [0.9011755]| lrm: 0.966085| num_tokens: 1,740
Step 00106/03096 | Training loss: 0.982197 | Training constraint: -5.843034, duals [0.81453264]| lrm: 0.965762| num_tokens: 2,230
Step 00107/03096 | Training loss: 0.922584 | Training constraint: -2.322329, duals [0.7402216]| lrm: 0.965439| num_tokens: 2,896
Step 00108/03096 | Training loss: 0.988495 | Training constraint: -5.249256, duals [0.668809]| lrm: 0.965116| num_tokens: 1,910
Step 00109/03096 | Training loss: 1.109510 | Training constraint: -11.331240, duals [0.6029149]| lrm: 0.964793| num_tokens: 5,156
Step 00110/03096 | Training loss: 1.218662 | Training constraint: -0.778514, duals [0.5542965]| lrm: 0.964470| num_tokens: 1,487
Step 00111/03096 | Training loss: 0.888828 | Training constraint: -9.493563, duals [0.4996759]| lrm: 0.964147| num_tokens: 5,111
Step 00112/03096 | Training loss: 0.911795 | Training constraint: -8.771231, duals [0.45041993]| lrm: 0.963824| num_tokens: 3,023
Step 00113/03096 | Training loss: 1.079731 | Training constraint: -4.815876, duals [0.4064311]| lrm: 0.963501| num_tokens: 3,960
Step 00114/03096 | Training loss: 0.817029 | Training constraint: -1.365214, duals [0.3688129]| lrm: 0.963178| num_tokens: 4,165
Step 00115/03096 | Training loss: 1.052742 | Training constraint: -0.013949, duals [0.367418]| lrm: 0.962855| num_tokens: 4,307
Step 00116/03096 | Training loss: 1.162282 | Training constraint: -0.656227, duals [0.3358191]| lrm: 0.962532| num_tokens: 2,446
Step 00117/03096 | Training loss: 1.147800 | Training constraint: -4.212255, duals [0.3029065]| lrm: 0.962209| num_tokens: 3,241
Step 00118/03096 | Training loss: 1.196954 | Training constraint: -1.669271, duals [0.27398998]| lrm: 0.961886| num_tokens: 2,930
Step 00119/03096 | Training loss: 1.204458 | Training constraint: -1.768466, duals [0.2476522]| lrm: 0.961563| num_tokens: 5,391
Step 00120/03096 | Training loss: 0.924611 | Training constraint: -9.849650, duals [0.22304265]| lrm: 0.961240| num_tokens: 1,966
Step 00121/03096 | Training loss: 1.221154 | Training constraint: 6.035446, duals [0.8265872]| lrm: 0.960917| num_tokens: 3,337
Step 00122/03096 | Training loss: 1.034069 | Training constraint: -1.164512, duals [0.75859654]| lrm: 0.960594| num_tokens: 2,289
Step 00123/03096 | Training loss: 1.049446 | Training constraint: 1.559448, duals [0.9145413]| lrm: 0.960271| num_tokens: 1,399
Step 00124/03096 | Training loss: 1.120386 | Training constraint: -10.865013, duals [0.8250117]| lrm: 0.959948| num_tokens: 1,634
Step 00125/03096 | Training loss: 1.057036 | Training constraint: -6.065120, duals [0.7453161]| lrm: 0.959625| num_tokens: 4,165
Step 00126/03096 | Training loss: 0.658408 | Training constraint: -18.255478, duals [0.6715452]| lrm: 0.959302| num_tokens: 5,196
Step 00127/03096 | Training loss: 0.864148 | Training constraint: -7.048247, duals [0.6059903]| lrm: 0.958979| num_tokens: 2,925
Step 00128/03096 | Training loss: 0.969848 | Training constraint: -2.899746, duals [0.5485573]| lrm: 0.958656| num_tokens: 2,959
Step 00129/03096 | Training loss: 1.090714 | Training constraint: -8.765625, duals [0.49455976]| lrm: 0.958333| num_tokens: 3,040
Step 00130/03096 | Training loss: 1.245277 | Training constraint: -3.695436, duals [0.44675845]| lrm: 0.958010| num_tokens: 2,984
Step 00131/03096 | Training loss: 1.397228 | Training constraint: -3.305621, duals [0.40359208]| lrm: 0.957687| num_tokens: 3,742
Step 00132/03096 | Training loss: 1.004181 | Training constraint: -6.592873, duals [0.3638505]| lrm: 0.957364| num_tokens: 1,916
Step 00133/03096 | Training loss: 0.937719 | Training constraint: -5.041667, duals [0.3281219]| lrm: 0.957041| num_tokens: 1,742
Step 00134/03096 | Training loss: 0.856930 | Training constraint: -8.274853, duals [0.29563496]| lrm: 0.956718| num_tokens: 3,329
Step 00135/03096 | Training loss: 1.073967 | Training constraint: 3.446440, duals [0.64027894]| lrm: 0.956395| num_tokens: 3,376
Step 00136/03096 | Training loss: 0.941984 | Training constraint: -0.853881, duals [0.5882538]| lrm: 0.956072| num_tokens: 2,468
Step 00137/03096 | Training loss: 1.000638 | Training constraint: -2.553481, duals [0.53281635]| lrm: 0.955749| num_tokens: 3,622
Step 00138/03096 | Training loss: 0.886614 | Training constraint: -1.156062, duals [0.48567393]| lrm: 0.955426| num_tokens: 1,801
Step 00139/03096 | Training loss: 0.953976 | Training constraint: -3.589973, duals [0.43874913]| lrm: 0.955103| num_tokens: 3,201
Step 00140/03096 | Training loss: 1.104345 | Training constraint: -2.589087, duals [0.396733]| lrm: 0.954780| num_tokens: 6,148
Step 00141/03096 | Training loss: 0.760418 | Training constraint: -3.847309, duals [0.35808247]| lrm: 0.954457| num_tokens: 2,869
Step 00142/03096 | Training loss: 0.949915 | Training constraint: -10.333236, duals [0.32258442]| lrm: 0.954134| num_tokens: 2,467
Step 00143/03096 | Training loss: 0.895095 | Training constraint: 0.448734, duals [0.36745784]| lrm: 0.953811| num_tokens: 2,790
Step 00144/03096 | Training loss: 1.112584 | Training constraint: -2.577894, duals [0.3320215]| lrm: 0.953488| num_tokens: 2,945
Step 00145/03096 | Training loss: 0.984259 | Training constraint: -2.085008, duals [0.30014113]| lrm: 0.953165| num_tokens: 3,747
Step 00146/03096 | Training loss: 1.008225 | Training constraint: -0.015623, duals [0.2985788]| lrm: 0.952842| num_tokens: 2,388
Step 00147/03096 | Training loss: 1.075724 | Training constraint: -13.578770, duals [0.26888505]| lrm: 0.952519| num_tokens: 4,638
Step 00148/03096 | Training loss: 1.112899 | Training constraint: -0.006772, duals [0.26820782]| lrm: 0.952196| num_tokens: 2,853
Step 00149/03096 | Training loss: 1.136808 | Training constraint: 0.597908, duals [0.32799864]| lrm: 0.951873| num_tokens: 2,194
Step 00150/03096 | Training loss: 0.880408 | Training constraint: -4.014135, duals [0.29586878]| lrm: 0.951550| num_tokens: 1,320
Step 00151/03096 | Training loss: 0.889454 | Training constraint: -12.808510, duals [0.26645276]| lrm: 0.951227| num_tokens: 3,057
Step 00152/03096 | Training loss: 1.092281 | Training constraint: -5.585851, duals [0.24012522]| lrm: 0.950904| num_tokens: 3,047
Step 00153/03096 | Training loss: 0.987950 | Training constraint: -10.281720, duals [0.21625291]| lrm: 0.950581| num_tokens: 3,729
Step 00154/03096 | Training loss: 0.937024 | Training constraint: -5.674597, duals [0.19483364]| lrm: 0.950258| num_tokens: 3,258
Step 00155/03096 | Training loss: 1.068202 | Training constraint: -7.205976, duals [0.17548196]| lrm: 0.949935| num_tokens: 5,767
Step 00156/03096 | Training loss: 1.295257 | Training constraint: -2.198854, duals [0.15828387]| lrm: 0.949612| num_tokens: 3,325
Step 00157/03096 | Training loss: 1.090056 | Training constraint: -5.224735, duals [0.14257537]| lrm: 0.949289| num_tokens: 3,321
Step 00158/03096 | Training loss: 1.234014 | Training constraint: 4.015501, duals [0.5441255]| lrm: 0.948966| num_tokens: 4,071
Step 00159/03096 | Training loss: 0.985235 | Training constraint: 1.334914, duals [0.6776169]| lrm: 0.948643| num_tokens: 1,536
Step 00160/03096 | Training loss: 1.029815 | Training constraint: -8.372635, duals [0.6112262]| lrm: 0.948320| num_tokens: 2,533
Step 00161/03096 | Training loss: 0.910683 | Training constraint: -5.277671, duals [0.55187327]| lrm: 0.947997| num_tokens: 3,515
Step 00162/03096 | Training loss: 0.933613 | Training constraint: -7.307631, duals [0.49772787]| lrm: 0.947674| num_tokens: 1,904
Step 00163/03096 | Training loss: 0.803786 | Training constraint: -17.228952, duals [0.44831455]| lrm: 0.947351| num_tokens: 1,963
Step 00164/03096 | Training loss: 1.021650 | Training constraint: -8.908582, duals [0.4040471]| lrm: 0.947028| num_tokens: 4,433
Step 00165/03096 | Training loss: 1.218231 | Training constraint: -8.853775, duals [0.36410338]| lrm: 0.946705| num_tokens: 3,416
Step 00166/03096 | Training loss: 0.898331 | Training constraint: -12.695608, duals [0.3279541]| lrm: 0.946382| num_tokens: 3,330
Step 00167/03096 | Training loss: 0.898039 | Training constraint: -2.129153, duals [0.29642156]| lrm: 0.946059| num_tokens: 2,159
Step 00168/03096 | Training loss: 1.032269 | Training constraint: -1.798653, duals [0.26800066]| lrm: 0.945736| num_tokens: 4,017
Step 00169/03096 | Training loss: 1.024401 | Training constraint: -2.688879, duals [0.24186839]| lrm: 0.945413| num_tokens: 2,106
Step 00170/03096 | Training loss: 0.991981 | Training constraint: -10.861149, duals [0.2178162]| lrm: 0.945090| num_tokens: 3,003
Step 00171/03096 | Training loss: 1.023337 | Training constraint: -4.151782, duals [0.19632027]| lrm: 0.944767| num_tokens: 3,527
Step 00172/03096 | Training loss: 0.751840 | Training constraint: -9.418289, duals [0.17679055]| lrm: 0.944444| num_tokens: 3,336
Step 00173/03096 | Training loss: 1.057477 | Training constraint: 0.783950, duals [0.25518557]| lrm: 0.944121| num_tokens: 2,905
Step 00174/03096 | Training loss: 1.179096 | Training constraint: -1.854088, duals [0.23054506]| lrm: 0.943798| num_tokens: 2,514
Step 00175/03096 | Training loss: 1.100932 | Training constraint: -12.177467, duals [0.20759967]| lrm: 0.943475| num_tokens: 2,871
Step 00176/03096 | Training loss: 0.916984 | Training constraint: -21.691677, duals [0.18688937]| lrm: 0.943152| num_tokens: 4,110
Step 00177/03096 | Training loss: 1.064842 | Training constraint: -9.043562, duals [0.16829698]| lrm: 0.942829| num_tokens: 3,779
Step 00178/03096 | Training loss: 0.829605 | Training constraint: -0.663818, duals [0.15253398]| lrm: 0.942506| num_tokens: 1,778
Step 00179/03096 | Training loss: 0.873540 | Training constraint: -5.891399, duals [0.13737932]| lrm: 0.942183| num_tokens: 5,058
Step 00180/03096 | Training loss: 0.819782 | Training constraint: -5.285378, duals [0.12373066]| lrm: 0.941860| num_tokens: 3,734
Step 00181/03096 | Training loss: 1.149197 | Training constraint: -12.539082, duals [0.11138812]| lrm: 0.941537| num_tokens: 2,822
Step 00182/03096 | Training loss: 0.985070 | Training constraint: -4.644223, duals [0.10031609]| lrm: 0.941214| num_tokens: 3,834
Step 00183/03096 | Training loss: 1.067236 | Training constraint: -2.395073, duals [0.09038952]| lrm: 0.940891| num_tokens: 2,470
Step 00184/03096 | Training loss: 1.137429 | Training constraint: -10.264749, duals [0.08137047]| lrm: 0.940568| num_tokens: 2,714
Step 00185/03096 | Training loss: 0.893243 | Training constraint: -6.158271, duals [0.0732603]| lrm: 0.940245| num_tokens: 2,352
Step 00186/03096 | Training loss: 0.748854 | Training constraint: -7.763996, duals [0.06595156]| lrm: 0.939922| num_tokens: 3,354
Step 00187/03096 | Training loss: 1.077070 | Training constraint: -3.139964, duals [0.05939103]| lrm: 0.939599| num_tokens: 4,052
Step 00188/03096 | Training loss: 0.573887 | Training constraint: -9.852094, duals [0.05346088]| lrm: 0.939276| num_tokens: 5,414
Step 00189/03096 | Training loss: 1.151042 | Training constraint: -5.918839, duals [0.04812686]| lrm: 0.938953| num_tokens: 3,071
Step 00190/03096 | Training loss: 1.210436 | Training constraint: -9.184526, duals [0.04332048]| lrm: 0.938630| num_tokens: 3,561
Step 00191/03096 | Training loss: 1.111425 | Training constraint: 5.173052, duals [0.5606257]| lrm: 0.938307| num_tokens: 4,626
Step 00192/03096 | Training loss: 1.219749 | Training constraint: -0.646670, duals [0.51671386]| lrm: 0.937984| num_tokens: 4,139
Step 00193/03096 | Training loss: 1.047912 | Training constraint: -7.498656, duals [0.4659326]| lrm: 0.937661| num_tokens: 4,308
Step 00194/03096 | Training loss: 0.974133 | Training constraint: -10.456410, duals [0.41985837]| lrm: 0.937339| num_tokens: 3,580
Step 00195/03096 | Training loss: 0.823310 | Training constraint: -1.484039, duals [0.38084215]| lrm: 0.937016| num_tokens: 2,629
Step 00196/03096 | Training loss: 1.004115 | Training constraint: -1.903866, duals [0.34466246]| lrm: 0.936693| num_tokens: 3,941
Step 00197/03096 | Training loss: 1.303087 | Training constraint: -0.257219, duals [0.32174203]| lrm: 0.936370| num_tokens: 1,388
Step 00198/03096 | Training loss: 1.073062 | Training constraint: -13.479981, duals [0.2897598]| lrm: 0.936047| num_tokens: 2,601
Step 00199/03096 | Training loss: 1.031054 | Training constraint: 4.500103, duals [0.7397702]| lrm: 0.935724| num_tokens: 5,670
Step 00200 | Validation loss: 1.147146
2026-01-21 14:11:35,345 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:11:35,348 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:11:35,349 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:11:35,355 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:11:35,467 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:11:35,467 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:11:35,827 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:11:35,830 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:11:36,023 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/cais/mmlu/revision/c30699e8356da336a370243923dbaf21066bb9fe "HTTP/1.1 200 OK"
2026-01-21 14:11:36,028 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/cais/mmlu/revision/c30699e8356da336a370243923dbaf21066bb9fe "HTTP/1.1 200 OK"
2026-01-21 14:11:36,157 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:11:36,164 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:11:36,306 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:11:36,308 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:11:36,430 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/cais/mmlu/tree/c30699e8356da336a370243923dbaf21066bb9fe/abstract_algebra?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:11:36,430 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/cais/mmlu/tree/c30699e8356da336a370243923dbaf21066bb9fe/abstract_algebra?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:11:36,547 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/cais/mmlu/tree/c30699e8356da336a370243923dbaf21066bb9fe?recursive=false&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:11:36,549 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/cais/mmlu/tree/c30699e8356da336a370243923dbaf21066bb9fe?recursive=false&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:11:36,672 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/cais/mmlu/tree/c30699e8356da336a370243923dbaf21066bb9fe/all?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:11:36,675 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/cais/mmlu/tree/c30699e8356da336a370243923dbaf21066bb9fe/all?recursive=true&expand=false "HTTP/1.1 200 OK"
Final: 318/1024 (31.05%)
2026-01-21 14:11:37,404 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:11:37,404 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:11:37,408 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:11:37,408 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:11:37,521 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:11:37,522 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:11:37,644 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:11:37,651 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:11:37,760 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:11:37,767 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:11:37,887 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:11:37,892 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:11:38,002 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:11:38,009 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 362/1024 (35.35%)
Step 00200 | mmlu_acc: 0.310547, arc_easy_acc: 0.353516
Step 00200/03096 | Training loss: 1.097489 | Training constraint: 1.989598, duals [0.9387299]| lrm: 0.935401| num_tokens: 1,549
Step 00201/03096 | Training loss: 0.789132 | Training constraint: -4.592610, duals [0.8496538]| lrm: 0.935078| num_tokens: 1,778
Step 00202/03096 | Training loss: 0.900488 | Training constraint: -6.019728, duals [0.7676865]| lrm: 0.934755| num_tokens: 1,802
Step 00203/03096 | Training loss: 1.061657 | Training constraint: -8.976507, duals [0.6925591]| lrm: 0.934432| num_tokens: 2,950
Step 00204/03096 | Training loss: 1.154095 | Training constraint: -4.340846, duals [0.62606555]| lrm: 0.934109| num_tokens: 3,103
Step 00205/03096 | Training loss: 1.203395 | Training constraint: 3.275176, duals [0.9535831]| lrm: 0.933786| num_tokens: 1,668
Step 00206/03096 | Training loss: 1.060286 | Training constraint: -6.842566, duals [0.8615471]| lrm: 0.933463| num_tokens: 5,221
Step 00207/03096 | Training loss: 1.091522 | Training constraint: -7.965669, duals [0.77772194]| lrm: 0.933140| num_tokens: 3,638
Step 00208/03096 | Training loss: 1.108137 | Training constraint: -1.452982, duals [0.71035683]| lrm: 0.932817| num_tokens: 1,316
Step 00209/03096 | Training loss: 0.959238 | Training constraint: -5.120326, duals [0.6417849]| lrm: 0.932494| num_tokens: 1,594
Step 00210/03096 | Training loss: 1.151821 | Training constraint: -3.756958, duals [0.58034724]| lrm: 0.932171| num_tokens: 3,011
Step 00211/03096 | Training loss: 1.003652 | Training constraint: -11.046422, duals [0.52307475]| lrm: 0.931848| num_tokens: 4,607
Step 00212/03096 | Training loss: 1.149604 | Training constraint: -0.897355, duals [0.47838986]| lrm: 0.931525| num_tokens: 2,745
Step 00213/03096 | Training loss: 0.863690 | Training constraint: -7.645011, duals [0.43129927]| lrm: 0.931202| num_tokens: 2,484
Step 00214/03096 | Training loss: 0.988830 | Training constraint: -5.318074, duals [0.38904378]| lrm: 0.930879| num_tokens: 2,462
Step 00215/03096 | Training loss: 1.048923 | Training constraint: -4.367923, duals [0.35100567]| lrm: 0.930556| num_tokens: 3,371
Step 00216/03096 | Training loss: 0.787180 | Training constraint: -21.173737, duals [0.31605056]| lrm: 0.930233| num_tokens: 3,815
Step 00217/03096 | Training loss: 1.007795 | Training constraint: -4.479926, duals [0.28500292]| lrm: 0.929910| num_tokens: 5,358
Step 00218/03096 | Training loss: 1.006298 | Training constraint: -7.013517, duals [0.25679216]| lrm: 0.929587| num_tokens: 3,358
Step 00219/03096 | Training loss: 1.067443 | Training constraint: -10.916050, duals [0.23126397]| lrm: 0.929264| num_tokens: 5,497
Step 00220/03096 | Training loss: 1.012576 | Training constraint: -8.256506, duals [0.2082995]| lrm: 0.928941| num_tokens: 3,398
Step 00221/03096 | Training loss: 1.166570 | Training constraint: -9.339560, duals [0.18758568]| lrm: 0.928618| num_tokens: 2,599
Step 00222/03096 | Training loss: 1.104049 | Training constraint: -9.293432, duals [0.16892175]| lrm: 0.928295| num_tokens: 4,266
Step 00223/03096 | Training loss: 0.958592 | Training constraint: -7.016149, duals [0.15213124]| lrm: 0.927972| num_tokens: 3,796
Step 00224/03096 | Training loss: 1.097286 | Training constraint: -8.550726, duals [0.13698578]| lrm: 0.927649| num_tokens: 2,585
Step 00225/03096 | Training loss: 1.100695 | Training constraint: -5.800407, duals [0.12336808]| lrm: 0.927326| num_tokens: 4,468
Step 00226/03096 | Training loss: 1.116624 | Training constraint: -5.638926, duals [0.11109874]| lrm: 0.927003| num_tokens: 4,538
Step 00227/03096 | Training loss: 1.119119 | Training constraint: -6.325116, duals [0.10003765]| lrm: 0.926680| num_tokens: 2,994
Step 00228/03096 | Training loss: 1.162922 | Training constraint: -7.837266, duals [0.09006581]| lrm: 0.926357| num_tokens: 2,280
Step 00229/03096 | Training loss: 1.104895 | Training constraint: -4.560277, duals [0.0811037]| lrm: 0.926034| num_tokens: 3,060
Step 00230/03096 | Training loss: 1.244175 | Training constraint: 0.120093, duals [0.09311301]| lrm: 0.925711| num_tokens: 2,295
Step 00231/03096 | Training loss: 1.192760 | Training constraint: -8.034281, duals [0.08382869]| lrm: 0.925388| num_tokens: 1,771
Step 00232/03096 | Training loss: 0.933858 | Training constraint: -12.275788, duals [0.07546013]| lrm: 0.925065| num_tokens: 2,501
Step 00233/03096 | Training loss: 0.856148 | Training constraint: -15.370383, duals [0.06792337]| lrm: 0.924742| num_tokens: 2,481
Step 00234/03096 | Training loss: 0.851416 | Training constraint: -2.831799, duals [0.06117176]| lrm: 0.924419| num_tokens: 2,627
Step 00235/03096 | Training loss: 1.164826 | Training constraint: 6.373251, duals [0.6984969]| lrm: 0.924096| num_tokens: 5,051
Step 00236/03096 | Training loss: 1.107385 | Training constraint: -11.421772, duals [0.6297151]| lrm: 0.923773| num_tokens: 3,104
Step 00237/03096 | Training loss: 1.096995 | Training constraint: -2.595366, duals [0.57056326]| lrm: 0.923450| num_tokens: 1,686
Step 00238/03096 | Training loss: 0.905464 | Training constraint: -23.432133, duals [0.5138542]| lrm: 0.923127| num_tokens: 5,314
Step 00239/03096 | Training loss: 1.264119 | Training constraint: -6.433939, duals [0.46349475]| lrm: 0.922804| num_tokens: 3,161
Step 00240/03096 | Training loss: 0.980620 | Training constraint: -5.317060, duals [0.41815534]| lrm: 0.922481| num_tokens: 4,120
Step 00241/03096 | Training loss: 0.905900 | Training constraint: -16.097469, duals [0.37661135]| lrm: 0.922158| num_tokens: 1,577
Step 00242/03096 | Training loss: 0.894128 | Training constraint: -2.192426, duals [0.34056756]| lrm: 0.921835| num_tokens: 2,653
Step 00243/03096 | Training loss: 1.026793 | Training constraint: -8.208275, duals [0.30686405]| lrm: 0.921512| num_tokens: 2,877
Step 00244/03096 | Training loss: 0.863006 | Training constraint: -21.154310, duals [0.27628893]| lrm: 0.921189| num_tokens: 2,209
Step 00245/03096 | Training loss: 0.974170 | Training constraint: -7.706701, duals [0.24890766]| lrm: 0.920866| num_tokens: 3,688
Step 00246/03096 | Training loss: 1.099846 | Training constraint: -6.374958, duals [0.22425985]| lrm: 0.920543| num_tokens: 2,043
Step 00247/03096 | Training loss: 1.121020 | Training constraint: -7.723319, duals [0.20199665]| lrm: 0.920220| num_tokens: 3,617
Step 00248/03096 | Training loss: 1.118402 | Training constraint: -11.708344, duals [0.18188411]| lrm: 0.919897| num_tokens: 4,177
Step 00249/03096 | Training loss: 0.875255 | Training constraint: -2.118270, duals [0.16408613]| lrm: 0.919574| num_tokens: 2,008
Step 00250/03096 | Training loss: 1.006763 | Training constraint: -1.687401, duals [0.14807642]| lrm: 0.919251| num_tokens: 3,246
Step 00251/03096 | Training loss: 1.093083 | Training constraint: -6.381070, duals [0.13335468]| lrm: 0.918928| num_tokens: 3,727
Step 00252/03096 | Training loss: 0.998985 | Training constraint: -15.476080, duals [0.12004793]| lrm: 0.918605| num_tokens: 3,857
Step 00253/03096 | Training loss: 0.920778 | Training constraint: -3.965424, duals [0.108134]| lrm: 0.918282| num_tokens: 5,415
Step 00254/03096 | Training loss: 1.029782 | Training constraint: -8.330698, duals [0.09735569]| lrm: 0.917959| num_tokens: 5,175
Step 00255/03096 | Training loss: 1.179579 | Training constraint: -12.894743, duals [0.0876385]| lrm: 0.917636| num_tokens: 4,518
Step 00256/03096 | Training loss: 0.991967 | Training constraint: -11.512438, duals [0.07889133]| lrm: 0.917313| num_tokens: 3,581
Step 00257/03096 | Training loss: 1.226280 | Training constraint: -2.558504, duals [0.071063]| lrm: 0.916990| num_tokens: 3,558
Step 00258/03096 | Training loss: 1.081713 | Training constraint: -5.910807, duals [0.06397806]| lrm: 0.916667| num_tokens: 4,922
Step 00259/03096 | Training loss: 1.191983 | Training constraint: -9.466147, duals [0.05759107]| lrm: 0.916344| num_tokens: 2,870
Step 00260/03096 | Training loss: 0.984297 | Training constraint: -9.426049, duals [0.05184075]| lrm: 0.916021| num_tokens: 3,216
Step 00261/03096 | Training loss: 0.952746 | Training constraint: -12.225476, duals [0.04666217]| lrm: 0.915698| num_tokens: 2,799
Step 00262/03096 | Training loss: 0.891917 | Training constraint: -2.400513, duals [0.04201863]| lrm: 0.915375| num_tokens: 3,535
Step 00263/03096 | Training loss: 1.087619 | Training constraint: -8.351385, duals [0.03782205]| lrm: 0.915052| num_tokens: 4,291
Step 00264/03096 | Training loss: 1.148381 | Training constraint: -15.511014, duals [0.03404215]| lrm: 0.914729| num_tokens: 5,074
Step 00265/03096 | Training loss: 0.949227 | Training constraint: -9.952141, duals [0.03064085]| lrm: 0.914406| num_tokens: 3,121
Step 00266/03096 | Training loss: 0.780576 | Training constraint: -17.843529, duals [0.02757808]| lrm: 0.914083| num_tokens: 3,436
Step 00267/03096 | Training loss: 0.973410 | Training constraint: -7.063553, duals [0.02482296]| lrm: 0.913760| num_tokens: 922
Step 00268/03096 | Training loss: 0.968066 | Training constraint: -16.717087, duals [0.02234159]| lrm: 0.913437| num_tokens: 2,834
Step 00269/03096 | Training loss: 1.063550 | Training constraint: -9.181174, duals [0.02010879]| lrm: 0.913114| num_tokens: 3,252
Step 00270/03096 | Training loss: 0.877228 | Training constraint: -10.159947, duals [0.0180989]| lrm: 0.912791| num_tokens: 3,636
Step 00271/03096 | Training loss: 1.195876 | Training constraint: -7.971882, duals [0.01629004]| lrm: 0.912468| num_tokens: 4,213
Step 00272/03096 | Training loss: 0.984766 | Training constraint: -8.320683, duals [0.01466183]| lrm: 0.912145| num_tokens: 4,319
Step 00273/03096 | Training loss: 0.990307 | Training constraint: -4.036480, duals [0.01319698]| lrm: 0.911822| num_tokens: 2,540
Step 00274/03096 | Training loss: 0.824258 | Training constraint: -7.549202, duals [0.01187786]| lrm: 0.911499| num_tokens: 2,162
Step 00275/03096 | Training loss: 0.938802 | Training constraint: -3.649095, duals [0.01069104]| lrm: 0.911176| num_tokens: 1,779
Step 00276/03096 | Training loss: 1.045352 | Training constraint: -5.334958, duals [0.01]| lrm: 0.910853| num_tokens: 5,235
Step 00277/03096 | Training loss: 0.916332 | Training constraint: -5.691836, duals [0.01]| lrm: 0.910530| num_tokens: 2,909
Step 00278/03096 | Training loss: 1.219853 | Training constraint: -6.004709, duals [0.01]| lrm: 0.910207| num_tokens: 3,993
Step 00279/03096 | Training loss: 1.093126 | Training constraint: 2.152985, duals [0.24921058]| lrm: 0.909884| num_tokens: 5,329
Step 00280/03096 | Training loss: 1.087640 | Training constraint: -14.404350, duals [0.22439732]| lrm: 0.909561| num_tokens: 3,199
Step 00281/03096 | Training loss: 1.121204 | Training constraint: -15.965572, duals [0.20203643]| lrm: 0.909238| num_tokens: 4,210
Step 00282/03096 | Training loss: 1.006518 | Training constraint: -4.969403, duals [0.18203813]| lrm: 0.908915| num_tokens: 4,467
Step 00283/03096 | Training loss: 0.873053 | Training constraint: -5.204592, duals [0.1639935]| lrm: 0.908592| num_tokens: 3,668
Step 00284/03096 | Training loss: 1.065428 | Training constraint: -17.608040, duals [0.14763232]| lrm: 0.908269| num_tokens: 3,769
Step 00285/03096 | Training loss: 0.775138 | Training constraint: -15.368807, duals [0.13290453]| lrm: 0.907946| num_tokens: 5,451
Step 00286/03096 | Training loss: 0.717128 | Training constraint: -17.877563, duals [0.11963877]| lrm: 0.907623| num_tokens: 5,066
Step 00287/03096 | Training loss: 1.087967 | Training constraint: -11.010668, duals [0.10770739]| lrm: 0.907300| num_tokens: 2,865
Step 00288/03096 | Training loss: 1.095450 | Training constraint: -15.302523, duals [0.0969556]| lrm: 0.906977| num_tokens: 2,232
Step 00289/03096 | Training loss: 0.811885 | Training constraint: -17.426537, duals [0.08727353]| lrm: 0.906654| num_tokens: 1,548
Step 00290/03096 | Training loss: 1.134829 | Training constraint: -4.033883, duals [0.07859338]| lrm: 0.906331| num_tokens: 2,565
Step 00291/03096 | Training loss: 0.975450 | Training constraint: -16.951384, duals [0.07074315]| lrm: 0.906008| num_tokens: 3,641
Step 00292/03096 | Training loss: 1.183342 | Training constraint: -12.040784, duals [0.06367923]| lrm: 0.905685| num_tokens: 4,007
Step 00293/03096 | Training loss: 1.152659 | Training constraint: -3.418488, duals [0.05734096]| lrm: 0.905362| num_tokens: 4,304
Step 00294/03096 | Training loss: 0.824505 | Training constraint: -11.413406, duals [0.05161406]| lrm: 0.905039| num_tokens: 3,058
Step 00295/03096 | Training loss: 0.842135 | Training constraint: -21.893757, duals [0.0464557]| lrm: 0.904716| num_tokens: 3,654
Step 00296/03096 | Training loss: 0.968642 | Training constraint: -14.838575, duals [0.04181376]| lrm: 0.904393| num_tokens: 2,070
Step 00297/03096 | Training loss: 1.309519 | Training constraint: -19.389511, duals [0.03763464]| lrm: 0.904070| num_tokens: 2,836
Step 00298/03096 | Training loss: 0.975132 | Training constraint: -17.413868, duals [0.03387321]| lrm: 0.903747| num_tokens: 1,823
Step 00299/03096 | Training loss: 1.270013 | Training constraint: -8.864608, duals [0.03048912]| lrm: 0.903424| num_tokens: 5,254
Step 00300 | Validation loss: 1.148150
Step 00300/03096 | Training loss: 1.059700 | Training constraint: -8.089231, duals [0.02744308]| lrm: 0.903101| num_tokens: 4,363
Step 00301/03096 | Training loss: 0.909946 | Training constraint: -13.155005, duals [0.0247002]| lrm: 0.902778| num_tokens: 3,653
Step 00302/03096 | Training loss: 1.001054 | Training constraint: -21.512928, duals [0.02223089]| lrm: 0.902455| num_tokens: 3,041
Step 00303/03096 | Training loss: 0.929846 | Training constraint: -3.128760, duals [0.02001175]| lrm: 0.902132| num_tokens: 2,702
Step 00304/03096 | Training loss: 0.954933 | Training constraint: -11.713520, duals [0.01801143]| lrm: 0.901809| num_tokens: 4,256
Step 00305/03096 | Training loss: 0.955605 | Training constraint: -7.776278, duals [0.01621133]| lrm: 0.901486| num_tokens: 3,146
Step 00306/03096 | Training loss: 1.056628 | Training constraint: -18.183353, duals [0.01459056]| lrm: 0.901163| num_tokens: 2,315
Step 00307/03096 | Training loss: 1.089844 | Training constraint: -7.052759, duals [0.01313226]| lrm: 0.900840| num_tokens: 3,376
Step 00308/03096 | Training loss: 0.997827 | Training constraint: -4.883609, duals [0.01181991]| lrm: 0.900517| num_tokens: 3,070
Step 00309/03096 | Training loss: 0.774851 | Training constraint: -7.126863, duals [0.01063841]| lrm: 0.900194| num_tokens: 3,327
Step 00310/03096 | Training loss: 1.112166 | Training constraint: -17.582458, duals [0.01]| lrm: 0.899871| num_tokens: 2,922
Step 00311/03096 | Training loss: 1.032564 | Training constraint: -9.730966, duals [0.01]| lrm: 0.899548| num_tokens: 2,959
Step 00312/03096 | Training loss: 1.140877 | Training constraint: -12.740819, duals [0.01]| lrm: 0.899225| num_tokens: 1,971
Step 00313/03096 | Training loss: 1.145746 | Training constraint: -6.569596, duals [0.01]| lrm: 0.898902| num_tokens: 3,274
Step 00314/03096 | Training loss: 1.031467 | Training constraint: -2.044530, duals [0.01]| lrm: 0.898579| num_tokens: 2,376
Step 00315/03096 | Training loss: 1.037274 | Training constraint: -17.818323, duals [0.01]| lrm: 0.898256| num_tokens: 2,761
Step 00316/03096 | Training loss: 1.136865 | Training constraint: -18.054176, duals [0.01]| lrm: 0.897933| num_tokens: 2,859
Step 00317/03096 | Training loss: 1.428003 | Training constraint: -11.333973, duals [0.01]| lrm: 0.897610| num_tokens: 4,616
Step 00318/03096 | Training loss: 0.717254 | Training constraint: -10.955478, duals [0.01]| lrm: 0.897287| num_tokens: 3,653
Step 00319/03096 | Training loss: 1.092733 | Training constraint: -14.758469, duals [0.01]| lrm: 0.896964| num_tokens: 3,020
Step 00320/03096 | Training loss: 1.033808 | Training constraint: -25.710859, duals [0.01]| lrm: 0.896641| num_tokens: 4,934
Step 00321/03096 | Training loss: 1.277610 | Training constraint: -9.953701, duals [0.01]| lrm: 0.896318| num_tokens: 3,726
Step 00322/03096 | Training loss: 0.944461 | Training constraint: -20.978561, duals [0.01]| lrm: 0.895995| num_tokens: 3,933
Step 00323/03096 | Training loss: 1.059592 | Training constraint: -11.583601, duals [0.01]| lrm: 0.895672| num_tokens: 1,913
Step 00324/03096 | Training loss: 1.048003 | Training constraint: -11.249706, duals [0.01]| lrm: 0.895349| num_tokens: 2,683
Step 00325/03096 | Training loss: 0.962605 | Training constraint: -16.276058, duals [0.01]| lrm: 0.895026| num_tokens: 2,553
Step 00326/03096 | Training loss: 0.562920 | Training constraint: -16.035561, duals [0.01]| lrm: 0.894703| num_tokens: 1,164
Step 00327/03096 | Training loss: 0.710625 | Training constraint: -7.782084, duals [0.01]| lrm: 0.894380| num_tokens: 4,212
Step 00328/03096 | Training loss: 1.168620 | Training constraint: -10.003445, duals [0.01]| lrm: 0.894057| num_tokens: 2,177
Step 00329/03096 | Training loss: 1.058813 | Training constraint: -14.861277, duals [0.01]| lrm: 0.893734| num_tokens: 2,110
Step 00330/03096 | Training loss: 1.028001 | Training constraint: -16.459965, duals [0.01]| lrm: 0.893411| num_tokens: 2,758
Step 00331/03096 | Training loss: 1.203384 | Training constraint: -2.238266, duals [0.01]| lrm: 0.893088| num_tokens: 4,697
Step 00332/03096 | Training loss: 1.062637 | Training constraint: -10.690096, duals [0.01]| lrm: 0.892765| num_tokens: 3,108
Step 00333/03096 | Training loss: 1.135451 | Training constraint: -30.700169, duals [0.01]| lrm: 0.892442| num_tokens: 4,159
Step 00334/03096 | Training loss: 0.683537 | Training constraint: -13.145973, duals [0.01]| lrm: 0.892119| num_tokens: 1,751
Step 00335/03096 | Training loss: 0.828889 | Training constraint: -16.591505, duals [0.01]| lrm: 0.891796| num_tokens: 3,667
Step 00336/03096 | Training loss: 1.122774 | Training constraint: -7.010610, duals [0.01]| lrm: 0.891473| num_tokens: 3,014
Step 00337/03096 | Training loss: 0.869317 | Training constraint: -19.707794, duals [0.01]| lrm: 0.891150| num_tokens: 3,109
Step 00338/03096 | Training loss: 1.163233 | Training constraint: -13.630419, duals [0.01]| lrm: 0.890827| num_tokens: 1,793
Step 00339/03096 | Training loss: 0.962901 | Training constraint: -11.179747, duals [0.01]| lrm: 0.890504| num_tokens: 1,201
Step 00340/03096 | Training loss: 0.984360 | Training constraint: -4.969949, duals [0.01]| lrm: 0.890181| num_tokens: 2,855
Step 00341/03096 | Training loss: 0.868231 | Training constraint: -8.191753, duals [0.01]| lrm: 0.889858| num_tokens: 1,778
Step 00342/03096 | Training loss: 1.205196 | Training constraint: -13.385161, duals [0.01]| lrm: 0.889535| num_tokens: 3,607
Step 00343/03096 | Training loss: 1.209181 | Training constraint: -7.194632, duals [0.01]| lrm: 0.889212| num_tokens: 2,004
Step 00344/03096 | Training loss: 0.932727 | Training constraint: -16.245520, duals [0.01]| lrm: 0.888889| num_tokens: 2,290
Step 00345/03096 | Training loss: 0.970280 | Training constraint: -12.623156, duals [0.01]| lrm: 0.888566| num_tokens: 3,933
Step 00346/03096 | Training loss: 1.173581 | Training constraint: -9.991749, duals [0.01]| lrm: 0.888243| num_tokens: 4,175
Step 00347/03096 | Training loss: 1.150012 | Training constraint: -15.785285, duals [0.01]| lrm: 0.887920| num_tokens: 3,774
Step 00348/03096 | Training loss: 1.303112 | Training constraint: -7.362298, duals [0.01]| lrm: 0.887597| num_tokens: 3,103
Step 00349/03096 | Training loss: 1.118428 | Training constraint: -4.549083, duals [0.01]| lrm: 0.887274| num_tokens: 476
Step 00350/03096 | Training loss: 1.072614 | Training constraint: -17.255098, duals [0.01]| lrm: 0.886951| num_tokens: 4,553
Step 00351/03096 | Training loss: 1.008286 | Training constraint: -6.297492, duals [0.01]| lrm: 0.886628| num_tokens: 3,181
Step 00352/03096 | Training loss: 0.966802 | Training constraint: -7.697441, duals [0.01]| lrm: 0.886305| num_tokens: 1,379
Step 00353/03096 | Training loss: 1.000621 | Training constraint: -13.819561, duals [0.01]| lrm: 0.885982| num_tokens: 3,070
Step 00354/03096 | Training loss: 1.217912 | Training constraint: -9.773087, duals [0.01]| lrm: 0.885659| num_tokens: 4,503
Step 00355/03096 | Training loss: 0.853026 | Training constraint: -10.424505, duals [0.01]| lrm: 0.885336| num_tokens: 5,644
Step 00356/03096 | Training loss: 1.115615 | Training constraint: -22.021975, duals [0.01]| lrm: 0.885013| num_tokens: 2,015
Step 00357/03096 | Training loss: 0.939134 | Training constraint: -19.394459, duals [0.01]| lrm: 0.884690| num_tokens: 2,966
Step 00358/03096 | Training loss: 0.834965 | Training constraint: -23.861862, duals [0.01]| lrm: 0.884367| num_tokens: 4,716
Step 00359/03096 | Training loss: 1.194777 | Training constraint: -8.721098, duals [0.01]| lrm: 0.884044| num_tokens: 4,872
Step 00360/03096 | Training loss: 0.798024 | Training constraint: -12.322642, duals [0.01]| lrm: 0.883721| num_tokens: 3,045
Step 00361/03096 | Training loss: 1.095841 | Training constraint: -15.644935, duals [0.01]| lrm: 0.883398| num_tokens: 5,616
Step 00362/03096 | Training loss: 0.988127 | Training constraint: -10.115814, duals [0.01]| lrm: 0.883075| num_tokens: 3,687
Step 00363/03096 | Training loss: 0.777496 | Training constraint: -15.150969, duals [0.01]| lrm: 0.882752| num_tokens: 2,757
Step 00364/03096 | Training loss: 0.791213 | Training constraint: -4.981292, duals [0.01]| lrm: 0.882429| num_tokens: 2,300
Step 00365/03096 | Training loss: 0.987638 | Training constraint: -8.667824, duals [0.01]| lrm: 0.882106| num_tokens: 3,200
Step 00366/03096 | Training loss: 1.107343 | Training constraint: -2.732474, duals [0.01]| lrm: 0.881783| num_tokens: 4,061
Step 00367/03096 | Training loss: 0.979089 | Training constraint: -20.417023, duals [0.01]| lrm: 0.881460| num_tokens: 1,499
Step 00368/03096 | Training loss: 1.171568 | Training constraint: -10.467191, duals [0.01]| lrm: 0.881137| num_tokens: 4,967
Step 00369/03096 | Training loss: 0.937607 | Training constraint: -11.802204, duals [0.01]| lrm: 0.880814| num_tokens: 3,698
Step 00370/03096 | Training loss: 0.919204 | Training constraint: -15.065016, duals [0.01]| lrm: 0.880491| num_tokens: 917
Step 00371/03096 | Training loss: 0.941198 | Training constraint: -19.626635, duals [0.01]| lrm: 0.880168| num_tokens: 2,579
Step 00372/03096 | Training loss: 1.111990 | Training constraint: -6.047470, duals [0.01]| lrm: 0.879845| num_tokens: 3,680
Step 00373/03096 | Training loss: 1.052095 | Training constraint: -16.391825, duals [0.01]| lrm: 0.879522| num_tokens: 3,198
Step 00374/03096 | Training loss: 1.196901 | Training constraint: -4.022538, duals [0.01]| lrm: 0.879199| num_tokens: 3,034
Step 00375/03096 | Training loss: 1.146963 | Training constraint: -14.614024, duals [0.01]| lrm: 0.878876| num_tokens: 4,525
Step 00376/03096 | Training loss: 0.970385 | Training constraint: -22.037161, duals [0.01]| lrm: 0.878553| num_tokens: 1,290
Step 00377/03096 | Training loss: 0.885530 | Training constraint: -9.241416, duals [0.01]| lrm: 0.878230| num_tokens: 2,721
Step 00378/03096 | Training loss: 0.959478 | Training constraint: -9.167897, duals [0.01]| lrm: 0.877907| num_tokens: 3,998
Step 00379/03096 | Training loss: 1.107626 | Training constraint: -14.158970, duals [0.01]| lrm: 0.877584| num_tokens: 4,194
Step 00380/03096 | Training loss: 1.025027 | Training constraint: -8.255331, duals [0.01]| lrm: 0.877261| num_tokens: 6,352
Step 00381/03096 | Training loss: 1.002204 | Training constraint: -14.778036, duals [0.01]| lrm: 0.876938| num_tokens: 3,322
Step 00382/03096 | Training loss: 0.898016 | Training constraint: -11.177814, duals [0.01]| lrm: 0.876615| num_tokens: 2,381
Step 00383/03096 | Training loss: 1.142316 | Training constraint: -12.540858, duals [0.01]| lrm: 0.876292| num_tokens: 4,325
Step 00384/03096 | Training loss: 0.876701 | Training constraint: -2.497844, duals [0.01]| lrm: 0.875969| num_tokens: 4,998
Step 00385/03096 | Training loss: 1.087301 | Training constraint: -14.161076, duals [0.01]| lrm: 0.875646| num_tokens: 1,955
Step 00386/03096 | Training loss: 1.064460 | Training constraint: -14.871884, duals [0.01]| lrm: 0.875323| num_tokens: 2,830
Step 00387/03096 | Training loss: 1.087311 | Training constraint: -6.500538, duals [0.01]| lrm: 0.875000| num_tokens: 1,177
Step 00388/03096 | Training loss: 1.273347 | Training constraint: -6.585998, duals [0.01]| lrm: 0.874677| num_tokens: 4,420
Step 00389/03096 | Training loss: 1.085994 | Training constraint: -8.988524, duals [0.01]| lrm: 0.874354| num_tokens: 2,135
Step 00390/03096 | Training loss: 1.017559 | Training constraint: -14.026559, duals [0.01]| lrm: 0.874031| num_tokens: 3,869
Step 00391/03096 | Training loss: 1.144841 | Training constraint: -6.290569, duals [0.01]| lrm: 0.873708| num_tokens: 4,290
Step 00392/03096 | Training loss: 0.821576 | Training constraint: -8.232887, duals [0.01]| lrm: 0.873385| num_tokens: 1,717
Step 00393/03096 | Training loss: 0.962009 | Training constraint: -18.270477, duals [0.01]| lrm: 0.873062| num_tokens: 5,317
Step 00394/03096 | Training loss: 1.100775 | Training constraint: -12.670465, duals [0.01]| lrm: 0.872739| num_tokens: 2,625
Step 00395/03096 | Training loss: 1.144578 | Training constraint: -7.177299, duals [0.01]| lrm: 0.872416| num_tokens: 2,269
Step 00396/03096 | Training loss: 0.880235 | Training constraint: -4.507596, duals [0.01]| lrm: 0.872093| num_tokens: 2,808
Step 00397/03096 | Training loss: 0.859516 | Training constraint: -5.249710, duals [0.01]| lrm: 0.871770| num_tokens: 1,941
Step 00398/03096 | Training loss: 0.890699 | Training constraint: -12.384470, duals [0.01]| lrm: 0.871447| num_tokens: 1,631
Step 00399/03096 | Training loss: 0.942538 | Training constraint: -6.982337, duals [0.01]| lrm: 0.871124| num_tokens: 2,760
Step 00400 | Validation loss: 1.148544
2026-01-21 14:12:14,144 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:12:14,149 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:12:14,155 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:12:14,159 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:12:14,264 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:14,273 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:14,612 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:14,659 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:14,805 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:12:14,850 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:12:14,994 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:12:14,995 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 321/1024 (31.35%)
2026-01-21 14:12:15,643 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:12:15,643 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:12:15,647 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:12:15,648 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:12:15,759 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:15,763 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:15,879 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:15,899 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:15,995 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:12:16,016 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:12:16,121 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:12:16,136 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:12:16,234 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:12:16,253 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 352/1024 (34.38%)
Step 00400 | mmlu_acc: 0.313477, arc_easy_acc: 0.343750
Step 00400/03096 | Training loss: 1.250937 | Training constraint: -10.039199, duals [0.01]| lrm: 0.870801| num_tokens: 5,813
Step 00401/03096 | Training loss: 0.826369 | Training constraint: -14.085282, duals [0.01]| lrm: 0.870478| num_tokens: 3,842
Step 00402/03096 | Training loss: 0.985962 | Training constraint: -2.402284, duals [0.01]| lrm: 0.870155| num_tokens: 6,285
Step 00403/03096 | Training loss: 1.025840 | Training constraint: -9.620773, duals [0.01]| lrm: 0.869832| num_tokens: 6,080
Step 00404/03096 | Training loss: 1.029532 | Training constraint: -7.771610, duals [0.01]| lrm: 0.869509| num_tokens: 3,082
Step 00405/03096 | Training loss: 1.081157 | Training constraint: -17.871454, duals [0.01]| lrm: 0.869186| num_tokens: 4,078
Step 00406/03096 | Training loss: 1.059129 | Training constraint: -14.947226, duals [0.01]| lrm: 0.868863| num_tokens: 4,418
Step 00407/03096 | Training loss: 1.152095 | Training constraint: -14.982844, duals [0.01]| lrm: 0.868540| num_tokens: 3,456
Step 00408/03096 | Training loss: 1.070323 | Training constraint: -11.483690, duals [0.01]| lrm: 0.868217| num_tokens: 3,848
Step 00409/03096 | Training loss: 1.142539 | Training constraint: -7.195361, duals [0.01]| lrm: 0.867894| num_tokens: 2,872
Step 00410/03096 | Training loss: 0.976438 | Training constraint: -9.068021, duals [0.01]| lrm: 0.867571| num_tokens: 1,847
Step 00411/03096 | Training loss: 1.132912 | Training constraint: -16.007591, duals [0.01]| lrm: 0.867248| num_tokens: 2,925
Step 00412/03096 | Training loss: 0.910630 | Training constraint: -21.510597, duals [0.01]| lrm: 0.866925| num_tokens: 5,544
Step 00413/03096 | Training loss: 1.126699 | Training constraint: -18.279905, duals [0.01]| lrm: 0.866602| num_tokens: 5,167
Step 00414/03096 | Training loss: 1.266170 | Training constraint: -16.231201, duals [0.01]| lrm: 0.866279| num_tokens: 2,765
Step 00415/03096 | Training loss: 0.859331 | Training constraint: -9.060479, duals [0.01]| lrm: 0.865956| num_tokens: 2,586
Step 00416/03096 | Training loss: 1.070100 | Training constraint: -13.657813, duals [0.01]| lrm: 0.865633| num_tokens: 4,272
Step 00417/03096 | Training loss: 1.004127 | Training constraint: -11.350888, duals [0.01]| lrm: 0.865310| num_tokens: 1,592
Step 00418/03096 | Training loss: 0.934388 | Training constraint: -26.207886, duals [0.01]| lrm: 0.864987| num_tokens: 3,907
Step 00419/03096 | Training loss: 0.829521 | Training constraint: -16.451580, duals [0.01]| lrm: 0.864664| num_tokens: 4,423
Step 00420/03096 | Training loss: 0.991265 | Training constraint: -3.954834, duals [0.01]| lrm: 0.864341| num_tokens: 3,248
Step 00421/03096 | Training loss: 1.169693 | Training constraint: -7.573251, duals [0.01]| lrm: 0.864018| num_tokens: 4,838
Step 00422/03096 | Training loss: 0.959049 | Training constraint: -23.464462, duals [0.01]| lrm: 0.863695| num_tokens: 6,045
Step 00423/03096 | Training loss: 1.054354 | Training constraint: -16.847910, duals [0.01]| lrm: 0.863372| num_tokens: 4,185
Step 00424/03096 | Training loss: 1.180594 | Training constraint: -7.034836, duals [0.01]| lrm: 0.863049| num_tokens: 6,817
Step 00425/03096 | Training loss: 1.160143 | Training constraint: -10.058355, duals [0.01]| lrm: 0.862726| num_tokens: 4,672
Step 00426/03096 | Training loss: 1.081622 | Training constraint: -13.654801, duals [0.01]| lrm: 0.862403| num_tokens: 4,594
Step 00427/03096 | Training loss: 1.030690 | Training constraint: -20.534447, duals [0.01]| lrm: 0.862080| num_tokens: 5,277
Step 00428/03096 | Training loss: 0.878647 | Training constraint: -13.001722, duals [0.01]| lrm: 0.861757| num_tokens: 2,828
Step 00429/03096 | Training loss: 1.093137 | Training constraint: -14.466333, duals [0.01]| lrm: 0.861434| num_tokens: 3,225
Step 00430/03096 | Training loss: 1.357544 | Training constraint: -6.586626, duals [0.01]| lrm: 0.861111| num_tokens: 2,712
Step 00431/03096 | Training loss: 1.006574 | Training constraint: -15.298330, duals [0.01]| lrm: 0.860788| num_tokens: 3,491
Step 00432/03096 | Training loss: 1.115117 | Training constraint: -12.051844, duals [0.01]| lrm: 0.860465| num_tokens: 3,855
Step 00433/03096 | Training loss: 0.892834 | Training constraint: -28.229607, duals [0.01]| lrm: 0.860142| num_tokens: 4,685
Step 00434/03096 | Training loss: 1.225218 | Training constraint: -9.297937, duals [0.01]| lrm: 0.859819| num_tokens: 4,197
Step 00435/03096 | Training loss: 1.028093 | Training constraint: -15.712786, duals [0.01]| lrm: 0.859496| num_tokens: 612
Step 00436/03096 | Training loss: 1.112201 | Training constraint: -2.440761, duals [0.01]| lrm: 0.859173| num_tokens: 4,027
Step 00437/03096 | Training loss: 0.894987 | Training constraint: -15.061363, duals [0.01]| lrm: 0.858850| num_tokens: 3,460
Step 00438/03096 | Training loss: 0.755367 | Training constraint: -5.770555, duals [0.01]| lrm: 0.858527| num_tokens: 1,776
Step 00439/03096 | Training loss: 0.836387 | Training constraint: -11.445963, duals [0.01]| lrm: 0.858204| num_tokens: 4,337
Step 00440/03096 | Training loss: 0.990194 | Training constraint: -5.442248, duals [0.01]| lrm: 0.857881| num_tokens: 2,314
Step 00441/03096 | Training loss: 0.856644 | Training constraint: -18.659832, duals [0.01]| lrm: 0.857558| num_tokens: 2,881
Step 00442/03096 | Training loss: 0.810130 | Training constraint: -9.603400, duals [0.01]| lrm: 0.857235| num_tokens: 1,641
Step 00443/03096 | Training loss: 1.023587 | Training constraint: -18.771807, duals [0.01]| lrm: 0.856912| num_tokens: 3,612
Step 00444/03096 | Training loss: 1.081689 | Training constraint: -9.513535, duals [0.01]| lrm: 0.856589| num_tokens: 3,740
Step 00445/03096 | Training loss: 1.049340 | Training constraint: -8.783333, duals [0.01]| lrm: 0.856266| num_tokens: 1,684
Step 00446/03096 | Training loss: 1.176945 | Training constraint: -14.891109, duals [0.01]| lrm: 0.855943| num_tokens: 3,252
Step 00447/03096 | Training loss: 1.355853 | Training constraint: -1.624278, duals [0.01]| lrm: 0.855620| num_tokens: 2,356
Step 00448/03096 | Training loss: 0.934714 | Training constraint: -9.242710, duals [0.01]| lrm: 0.855297| num_tokens: 4,168
Step 00449/03096 | Training loss: 0.917365 | Training constraint: -9.788294, duals [0.01]| lrm: 0.854974| num_tokens: 5,108
Step 00450/03096 | Training loss: 1.045244 | Training constraint: -22.933453, duals [0.01]| lrm: 0.854651| num_tokens: 2,480
Step 00451/03096 | Training loss: 1.192009 | Training constraint: -14.902691, duals [0.01]| lrm: 0.854328| num_tokens: 567
Step 00452/03096 | Training loss: 0.945275 | Training constraint: -16.244114, duals [0.01]| lrm: 0.854005| num_tokens: 2,549
Step 00453/03096 | Training loss: 1.206404 | Training constraint: -4.716519, duals [0.01]| lrm: 0.853682| num_tokens: 2,541
Step 00454/03096 | Training loss: 1.126691 | Training constraint: -11.366356, duals [0.01]| lrm: 0.853359| num_tokens: 3,791
Step 00455/03096 | Training loss: 0.867829 | Training constraint: -13.012238, duals [0.01]| lrm: 0.853036| num_tokens: 2,574
Step 00456/03096 | Training loss: 0.694731 | Training constraint: -33.666088, duals [0.01]| lrm: 0.852713| num_tokens: 3,421
Step 00457/03096 | Training loss: 0.934873 | Training constraint: -15.118747, duals [0.01]| lrm: 0.852390| num_tokens: 4,407
Step 00458/03096 | Training loss: 1.137758 | Training constraint: -3.283989, duals [0.01]| lrm: 0.852067| num_tokens: 2,460
Step 00459/03096 | Training loss: 1.298363 | Training constraint: -6.552109, duals [0.01]| lrm: 0.851744| num_tokens: 5,377
Step 00460/03096 | Training loss: 0.935290 | Training constraint: -18.550997, duals [0.01]| lrm: 0.851421| num_tokens: 3,938
Step 00461/03096 | Training loss: 0.697284 | Training constraint: -14.454471, duals [0.01]| lrm: 0.851098| num_tokens: 3,291
Step 00462/03096 | Training loss: 1.031866 | Training constraint: -5.909730, duals [0.01]| lrm: 0.850775| num_tokens: 4,342
Step 00463/03096 | Training loss: 1.040457 | Training constraint: -5.472218, duals [0.01]| lrm: 0.850452| num_tokens: 3,133
Step 00464/03096 | Training loss: 0.808191 | Training constraint: -13.407808, duals [0.01]| lrm: 0.850129| num_tokens: 5,399
Step 00465/03096 | Training loss: 1.099909 | Training constraint: -7.344126, duals [0.01]| lrm: 0.849806| num_tokens: 1,691
Step 00466/03096 | Training loss: 1.047669 | Training constraint: -14.241877, duals [0.01]| lrm: 0.849483| num_tokens: 4,419
Step 00467/03096 | Training loss: 1.016812 | Training constraint: -14.804863, duals [0.01]| lrm: 0.849160| num_tokens: 4,370
Step 00468/03096 | Training loss: 1.339916 | Training constraint: -12.188542, duals [0.01]| lrm: 0.848837| num_tokens: 4,068
Step 00469/03096 | Training loss: 1.042031 | Training constraint: -8.015602, duals [0.01]| lrm: 0.848514| num_tokens: 1,997
Step 00470/03096 | Training loss: 0.793929 | Training constraint: -11.059009, duals [0.01]| lrm: 0.848191| num_tokens: 3,960
Step 00471/03096 | Training loss: 0.897749 | Training constraint: -11.123055, duals [0.01]| lrm: 0.847868| num_tokens: 1,641
Step 00472/03096 | Training loss: 0.791055 | Training constraint: -20.636288, duals [0.01]| lrm: 0.847545| num_tokens: 4,952
Step 00473/03096 | Training loss: 1.094156 | Training constraint: -9.731220, duals [0.01]| lrm: 0.847222| num_tokens: 4,089
Step 00474/03096 | Training loss: 1.099431 | Training constraint: -8.068246, duals [0.01]| lrm: 0.846899| num_tokens: 2,663
Step 00475/03096 | Training loss: 1.127466 | Training constraint: -15.153181, duals [0.01]| lrm: 0.846576| num_tokens: 1,797
Step 00476/03096 | Training loss: 1.058615 | Training constraint: -19.603716, duals [0.01]| lrm: 0.846253| num_tokens: 5,102
Step 00477/03096 | Training loss: 1.239351 | Training constraint: -13.050009, duals [0.01]| lrm: 0.845930| num_tokens: 3,516
Step 00478/03096 | Training loss: 1.099544 | Training constraint: -4.921733, duals [0.01]| lrm: 0.845607| num_tokens: 1,346
Step 00479/03096 | Training loss: 1.096174 | Training constraint: -14.425825, duals [0.01]| lrm: 0.845284| num_tokens: 3,041
Step 00480/03096 | Training loss: 0.771522 | Training constraint: -23.260365, duals [0.01]| lrm: 0.844961| num_tokens: 2,639
Step 00481/03096 | Training loss: 0.648300 | Training constraint: -10.154419, duals [0.01]| lrm: 0.844638| num_tokens: 2,154
Step 00482/03096 | Training loss: 1.076796 | Training constraint: -5.815734, duals [0.01]| lrm: 0.844315| num_tokens: 3,881
Step 00483/03096 | Training loss: 1.033615 | Training constraint: -10.972012, duals [0.01]| lrm: 0.843992| num_tokens: 3,296
Step 00484/03096 | Training loss: 1.093965 | Training constraint: -19.029419, duals [0.01]| lrm: 0.843669| num_tokens: 5,154
Step 00485/03096 | Training loss: 0.904881 | Training constraint: -14.793921, duals [0.01]| lrm: 0.843346| num_tokens: 4,857
Step 00486/03096 | Training loss: 1.022292 | Training constraint: -10.251779, duals [0.01]| lrm: 0.843023| num_tokens: 4,071
Step 00487/03096 | Training loss: 1.133053 | Training constraint: -2.576241, duals [0.01]| lrm: 0.842700| num_tokens: 5,070
Step 00488/03096 | Training loss: 0.998453 | Training constraint: -21.755199, duals [0.01]| lrm: 0.842377| num_tokens: 4,705
Step 00489/03096 | Training loss: 0.973727 | Training constraint: -4.294213, duals [0.01]| lrm: 0.842054| num_tokens: 3,512
Step 00490/03096 | Training loss: 0.999211 | Training constraint: -16.656446, duals [0.01]| lrm: 0.841731| num_tokens: 4,034
Step 00491/03096 | Training loss: 0.976912 | Training constraint: -12.843316, duals [0.01]| lrm: 0.841408| num_tokens: 3,554
Step 00492/03096 | Training loss: 1.085277 | Training constraint: -14.071684, duals [0.01]| lrm: 0.841085| num_tokens: 3,992
Step 00493/03096 | Training loss: 1.027542 | Training constraint: -8.721830, duals [0.01]| lrm: 0.840762| num_tokens: 3,434
Step 00494/03096 | Training loss: 0.809034 | Training constraint: -12.979081, duals [0.01]| lrm: 0.840439| num_tokens: 2,496
Step 00495/03096 | Training loss: 1.434511 | Training constraint: -15.576265, duals [0.01]| lrm: 0.840116| num_tokens: 3,886
Step 00496/03096 | Training loss: 1.189902 | Training constraint: -1.843137, duals [0.01]| lrm: 0.839793| num_tokens: 3,201
Step 00497/03096 | Training loss: 0.904514 | Training constraint: -12.386398, duals [0.01]| lrm: 0.839470| num_tokens: 2,403
Step 00498/03096 | Training loss: 1.065636 | Training constraint: -15.311934, duals [0.01]| lrm: 0.839147| num_tokens: 3,310
Step 00499/03096 | Training loss: 0.819127 | Training constraint: -9.798506, duals [0.01]| lrm: 0.838824| num_tokens: 2,142
Step 00500 | Validation loss: 1.149223
Step 00500/03096 | Training loss: 0.974313 | Training constraint: -7.881758, duals [0.01]| lrm: 0.838501| num_tokens: 3,950
Step 00501/03096 | Training loss: 1.010539 | Training constraint: -4.179518, duals [0.01]| lrm: 0.838178| num_tokens: 4,901
Step 00502/03096 | Training loss: 0.973966 | Training constraint: -14.381974, duals [0.01]| lrm: 0.837855| num_tokens: 2,662
Step 00503/03096 | Training loss: 0.875177 | Training constraint: -11.796501, duals [0.01]| lrm: 0.837532| num_tokens: 2,800
Step 00504/03096 | Training loss: 0.992670 | Training constraint: -7.247472, duals [0.01]| lrm: 0.837209| num_tokens: 4,025
Step 00505/03096 | Training loss: 1.081303 | Training constraint: -12.566825, duals [0.01]| lrm: 0.836886| num_tokens: 3,507
Step 00506/03096 | Training loss: 0.931480 | Training constraint: -4.434405, duals [0.01]| lrm: 0.836563| num_tokens: 3,663
Step 00507/03096 | Training loss: 1.073219 | Training constraint: -20.409616, duals [0.01]| lrm: 0.836240| num_tokens: 4,040
Step 00508/03096 | Training loss: 1.086637 | Training constraint: -13.819616, duals [0.01]| lrm: 0.835917| num_tokens: 4,727
Step 00509/03096 | Training loss: 0.880543 | Training constraint: -5.421355, duals [0.01]| lrm: 0.835594| num_tokens: 4,189
Step 00510/03096 | Training loss: 1.182527 | Training constraint: -11.192848, duals [0.01]| lrm: 0.835271| num_tokens: 3,963
Step 00511/03096 | Training loss: 0.858933 | Training constraint: -11.219905, duals [0.01]| lrm: 0.834948| num_tokens: 3,034
Step 00512/03096 | Training loss: 0.759375 | Training constraint: -14.446816, duals [0.01]| lrm: 0.834625| num_tokens: 5,198
Step 00513/03096 | Training loss: 1.002139 | Training constraint: -5.594290, duals [0.01]| lrm: 0.834302| num_tokens: 3,392
Step 00514/03096 | Training loss: 1.061589 | Training constraint: -19.140455, duals [0.01]| lrm: 0.833979| num_tokens: 1,683
Step 00515/03096 | Training loss: 0.914902 | Training constraint: -14.408240, duals [0.01]| lrm: 0.833656| num_tokens: 3,259
Step 00516/03096 | Training loss: 0.892608 | Training constraint: -12.451798, duals [0.01]| lrm: 0.833333| num_tokens: 3,223
Step 00517/03096 | Training loss: 1.049856 | Training constraint: -12.386241, duals [0.01]| lrm: 0.833010| num_tokens: 4,900
Step 00518/03096 | Training loss: 1.099205 | Training constraint: -15.364563, duals [0.01]| lrm: 0.832687| num_tokens: 6,229
Step 00519/03096 | Training loss: 0.880411 | Training constraint: -15.910534, duals [0.01]| lrm: 0.832364| num_tokens: 3,037
Step 00520/03096 | Training loss: 0.762812 | Training constraint: -17.421591, duals [0.01]| lrm: 0.832041| num_tokens: 4,367
Step 00521/03096 | Training loss: 0.832666 | Training constraint: -20.661802, duals [0.01]| lrm: 0.831718| num_tokens: 2,365
Step 00522/03096 | Training loss: 1.037637 | Training constraint: -11.964580, duals [0.01]| lrm: 0.831395| num_tokens: 3,990
Step 00523/03096 | Training loss: 0.965903 | Training constraint: -19.671804, duals [0.01]| lrm: 0.831072| num_tokens: 4,739
Step 00524/03096 | Training loss: 1.087769 | Training constraint: -10.339855, duals [0.01]| lrm: 0.830749| num_tokens: 3,212
Step 00525/03096 | Training loss: 0.839485 | Training constraint: -16.438986, duals [0.01]| lrm: 0.830426| num_tokens: 1,299
Step 00526/03096 | Training loss: 1.018572 | Training constraint: -14.434048, duals [0.01]| lrm: 0.830103| num_tokens: 3,202
Step 00527/03096 | Training loss: 0.903307 | Training constraint: -14.273785, duals [0.01]| lrm: 0.829780| num_tokens: 2,382
Step 00528/03096 | Training loss: 1.302875 | Training constraint: -18.402327, duals [0.01]| lrm: 0.829457| num_tokens: 3,903
Step 00529/03096 | Training loss: 1.018439 | Training constraint: -8.668458, duals [0.01]| lrm: 0.829134| num_tokens: 3,804
Step 00530/03096 | Training loss: 0.943321 | Training constraint: -8.352325, duals [0.01]| lrm: 0.828811| num_tokens: 5,604
Step 00531/03096 | Training loss: 1.070454 | Training constraint: -8.191864, duals [0.01]| lrm: 0.828488| num_tokens: 1,837
Step 00532/03096 | Training loss: 1.111806 | Training constraint: -5.462615, duals [0.01]| lrm: 0.828165| num_tokens: 1,864
Step 00533/03096 | Training loss: 0.976228 | Training constraint: -16.736618, duals [0.01]| lrm: 0.827842| num_tokens: 4,787
Step 00534/03096 | Training loss: 1.371144 | Training constraint: -18.438602, duals [0.01]| lrm: 0.827519| num_tokens: 3,447
Step 00535/03096 | Training loss: 1.102395 | Training constraint: -17.275414, duals [0.01]| lrm: 0.827196| num_tokens: 2,624
Step 00536/03096 | Training loss: 0.868856 | Training constraint: -18.772850, duals [0.01]| lrm: 0.826873| num_tokens: 4,122
Step 00537/03096 | Training loss: 0.943106 | Training constraint: -5.831769, duals [0.01]| lrm: 0.826550| num_tokens: 5,339
Step 00538/03096 | Training loss: 0.961128 | Training constraint: -12.573640, duals [0.01]| lrm: 0.826227| num_tokens: 2,036
Step 00539/03096 | Training loss: 1.248304 | Training constraint: -25.239517, duals [0.01]| lrm: 0.825904| num_tokens: 4,825
Step 00540/03096 | Training loss: 0.864109 | Training constraint: -17.732891, duals [0.01]| lrm: 0.825581| num_tokens: 2,218
Step 00541/03096 | Training loss: 0.853235 | Training constraint: -10.103107, duals [0.01]| lrm: 0.825258| num_tokens: 4,541
Step 00542/03096 | Training loss: 0.982807 | Training constraint: -25.397692, duals [0.01]| lrm: 0.824935| num_tokens: 3,566
Step 00543/03096 | Training loss: 0.760401 | Training constraint: -5.734610, duals [0.01]| lrm: 0.824612| num_tokens: 1,090
Step 00544/03096 | Training loss: 0.994800 | Training constraint: -12.249058, duals [0.01]| lrm: 0.824289| num_tokens: 1,432
Step 00545/03096 | Training loss: 1.038079 | Training constraint: -31.262684, duals [0.01]| lrm: 0.823966| num_tokens: 2,376
Step 00546/03096 | Training loss: 1.295739 | Training constraint: -5.170280, duals [0.01]| lrm: 0.823643| num_tokens: 4,515
Step 00547/03096 | Training loss: 0.979272 | Training constraint: -4.481687, duals [0.01]| lrm: 0.823320| num_tokens: 3,256
Step 00548/03096 | Training loss: 1.104445 | Training constraint: -5.537568, duals [0.01]| lrm: 0.822997| num_tokens: 2,204
Step 00549/03096 | Training loss: 1.091663 | Training constraint: -19.945747, duals [0.01]| lrm: 0.822674| num_tokens: 2,665
Step 00550/03096 | Training loss: 0.921133 | Training constraint: -8.152949, duals [0.01]| lrm: 0.822351| num_tokens: 3,335
Step 00551/03096 | Training loss: 1.080535 | Training constraint: -8.722965, duals [0.01]| lrm: 0.822028| num_tokens: 5,275
Step 00552/03096 | Training loss: 0.890854 | Training constraint: -11.493193, duals [0.01]| lrm: 0.821705| num_tokens: 3,635
Step 00553/03096 | Training loss: 0.979016 | Training constraint: -6.823351, duals [0.01]| lrm: 0.821382| num_tokens: 2,322
Step 00554/03096 | Training loss: 1.260805 | Training constraint: -9.524263, duals [0.01]| lrm: 0.821059| num_tokens: 2,424
Step 00555/03096 | Training loss: 0.939198 | Training constraint: -4.525965, duals [0.01]| lrm: 0.820736| num_tokens: 1,335
Step 00556/03096 | Training loss: 1.200802 | Training constraint: -7.539665, duals [0.01]| lrm: 0.820413| num_tokens: 2,980
Step 00557/03096 | Training loss: 1.029080 | Training constraint: -22.197346, duals [0.01]| lrm: 0.820090| num_tokens: 2,107
Step 00558/03096 | Training loss: 0.973208 | Training constraint: -13.165009, duals [0.01]| lrm: 0.819767| num_tokens: 1,437
Step 00559/03096 | Training loss: 0.977306 | Training constraint: -13.087363, duals [0.01]| lrm: 0.819444| num_tokens: 4,805
Step 00560/03096 | Training loss: 0.965655 | Training constraint: -10.164842, duals [0.01]| lrm: 0.819121| num_tokens: 2,456
Step 00561/03096 | Training loss: 1.060805 | Training constraint: -9.879141, duals [0.01]| lrm: 0.818798| num_tokens: 2,316
Step 00562/03096 | Training loss: 1.241575 | Training constraint: -10.241625, duals [0.01]| lrm: 0.818475| num_tokens: 2,440
Step 00563/03096 | Training loss: 0.883869 | Training constraint: -16.171700, duals [0.01]| lrm: 0.818152| num_tokens: 3,960
Step 00564/03096 | Training loss: 0.892490 | Training constraint: -17.308807, duals [0.01]| lrm: 0.817829| num_tokens: 4,278
Step 00565/03096 | Training loss: 1.152962 | Training constraint: -7.310453, duals [0.01]| lrm: 0.817506| num_tokens: 2,889
Step 00566/03096 | Training loss: 1.306829 | Training constraint: -9.075077, duals [0.01]| lrm: 0.817183| num_tokens: 3,168
Step 00567/03096 | Training loss: 1.081399 | Training constraint: -13.280445, duals [0.01]| lrm: 0.816860| num_tokens: 2,797
Step 00568/03096 | Training loss: 1.022253 | Training constraint: -24.174450, duals [0.01]| lrm: 0.816537| num_tokens: 2,014
Step 00569/03096 | Training loss: 1.037384 | Training constraint: -18.787722, duals [0.01]| lrm: 0.816214| num_tokens: 4,348
Step 00570/03096 | Training loss: 0.891748 | Training constraint: -9.956631, duals [0.01]| lrm: 0.815891| num_tokens: 2,383
Step 00571/03096 | Training loss: 1.211527 | Training constraint: -3.869767, duals [0.01]| lrm: 0.815568| num_tokens: 1,893
Step 00572/03096 | Training loss: 1.066146 | Training constraint: -14.958399, duals [0.01]| lrm: 0.815245| num_tokens: 4,392
Step 00573/03096 | Training loss: 1.173541 | Training constraint: -12.023920, duals [0.01]| lrm: 0.814922| num_tokens: 3,906
Step 00574/03096 | Training loss: 1.113057 | Training constraint: -5.017856, duals [0.01]| lrm: 0.814599| num_tokens: 4,038
Step 00575/03096 | Training loss: 1.213997 | Training constraint: -12.426948, duals [0.01]| lrm: 0.814276| num_tokens: 5,553
Step 00576/03096 | Training loss: 0.926113 | Training constraint: -4.218442, duals [0.01]| lrm: 0.813953| num_tokens: 5,294
Step 00577/03096 | Training loss: 0.915559 | Training constraint: -3.045395, duals [0.01]| lrm: 0.813630| num_tokens: 3,723
Step 00578/03096 | Training loss: 1.078215 | Training constraint: -13.157810, duals [0.01]| lrm: 0.813307| num_tokens: 2,069
Step 00579/03096 | Training loss: 1.012032 | Training constraint: -14.833170, duals [0.01]| lrm: 0.812984| num_tokens: 1,723
Step 00580/03096 | Training loss: 0.827712 | Training constraint: -25.153191, duals [0.01]| lrm: 0.812661| num_tokens: 3,837
Step 00581/03096 | Training loss: 1.116913 | Training constraint: -17.464705, duals [0.01]| lrm: 0.812339| num_tokens: 3,928
Step 00582/03096 | Training loss: 0.888345 | Training constraint: -7.975431, duals [0.01]| lrm: 0.812016| num_tokens: 1,146
Step 00583/03096 | Training loss: 1.123767 | Training constraint: -7.288416, duals [0.01]| lrm: 0.811693| num_tokens: 4,629
Step 00584/03096 | Training loss: 1.081745 | Training constraint: -9.754540, duals [0.01]| lrm: 0.811370| num_tokens: 4,978
Step 00585/03096 | Training loss: 0.992036 | Training constraint: -0.959565, duals [0.01]| lrm: 0.811047| num_tokens: 3,008
Step 00586/03096 | Training loss: 1.058372 | Training constraint: -14.078032, duals [0.01]| lrm: 0.810724| num_tokens: 3,886
Step 00587/03096 | Training loss: 1.163776 | Training constraint: -14.710030, duals [0.01]| lrm: 0.810401| num_tokens: 2,816
Step 00588/03096 | Training loss: 0.896175 | Training constraint: -11.438087, duals [0.01]| lrm: 0.810078| num_tokens: 4,834
Step 00589/03096 | Training loss: 0.840886 | Training constraint: -26.699081, duals [0.01]| lrm: 0.809755| num_tokens: 2,891
Step 00590/03096 | Training loss: 1.041187 | Training constraint: -2.006208, duals [0.01]| lrm: 0.809432| num_tokens: 3,879
Step 00591/03096 | Training loss: 0.976487 | Training constraint: -16.826967, duals [0.01]| lrm: 0.809109| num_tokens: 3,447
Step 00592/03096 | Training loss: 1.376298 | Training constraint: -0.185918, duals [0.01]| lrm: 0.808786| num_tokens: 6,335
Step 00593/03096 | Training loss: 0.783612 | Training constraint: -7.535899, duals [0.01]| lrm: 0.808463| num_tokens: 3,180
Step 00594/03096 | Training loss: 0.722750 | Training constraint: -15.363548, duals [0.01]| lrm: 0.808140| num_tokens: 4,009
Step 00595/03096 | Training loss: 1.305447 | Training constraint: -9.831138, duals [0.01]| lrm: 0.807817| num_tokens: 2,672
Step 00596/03096 | Training loss: 0.941231 | Training constraint: -7.709073, duals [0.01]| lrm: 0.807494| num_tokens: 1,775
Step 00597/03096 | Training loss: 1.048302 | Training constraint: -6.777986, duals [0.01]| lrm: 0.807171| num_tokens: 2,144
Step 00598/03096 | Training loss: 0.946057 | Training constraint: -27.228228, duals [0.01]| lrm: 0.806848| num_tokens: 4,198
Step 00599/03096 | Training loss: 1.070026 | Training constraint: -8.856031, duals [0.01]| lrm: 0.806525| num_tokens: 4,141
Step 00600 | Validation loss: 1.150073
2026-01-21 14:12:52,059 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:12:52,063 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:12:52,064 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:12:52,068 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:12:52,180 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:52,181 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:52,521 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:52,547 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:52,924 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:12:52,934 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:12:53,075 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:12:53,081 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 307/1024 (29.98%)
2026-01-21 14:12:53,668 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:12:53,669 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:12:53,672 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:12:53,673 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:12:53,785 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:53,786 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:53,903 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:53,909 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:12:54,019 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:12:54,025 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:12:54,149 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:12:54,151 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:12:54,264 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:12:54,267 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 355/1024 (34.67%)
Step 00600 | mmlu_acc: 0.299805, arc_easy_acc: 0.346680
Step 00600/03096 | Training loss: 0.836903 | Training constraint: -8.731465, duals [0.01]| lrm: 0.806202| num_tokens: 2,441
Step 00601/03096 | Training loss: 1.039023 | Training constraint: -15.771358, duals [0.01]| lrm: 0.805879| num_tokens: 2,567
Step 00602/03096 | Training loss: 1.119175 | Training constraint: -16.750996, duals [0.01]| lrm: 0.805556| num_tokens: 2,844
Step 00603/03096 | Training loss: 0.905937 | Training constraint: -21.930458, duals [0.01]| lrm: 0.805233| num_tokens: 2,223
Step 00604/03096 | Training loss: 0.974294 | Training constraint: -12.423895, duals [0.01]| lrm: 0.804910| num_tokens: 4,202
Step 00605/03096 | Training loss: 0.808671 | Training constraint: -13.803573, duals [0.01]| lrm: 0.804587| num_tokens: 4,068
Step 00606/03096 | Training loss: 1.147745 | Training constraint: -1.985836, duals [0.01]| lrm: 0.804264| num_tokens: 4,645
Step 00607/03096 | Training loss: 1.144466 | Training constraint: -14.650671, duals [0.01]| lrm: 0.803941| num_tokens: 2,188
Step 00608/03096 | Training loss: 0.904452 | Training constraint: -13.870014, duals [0.01]| lrm: 0.803618| num_tokens: 3,401
Step 00609/03096 | Training loss: 1.004694 | Training constraint: -14.139657, duals [0.01]| lrm: 0.803295| num_tokens: 5,748
Step 00610/03096 | Training loss: 0.967068 | Training constraint: -6.417702, duals [0.01]| lrm: 0.802972| num_tokens: 3,482
Step 00611/03096 | Training loss: 1.139525 | Training constraint: -12.501712, duals [0.01]| lrm: 0.802649| num_tokens: 6,717
Step 00612/03096 | Training loss: 1.078551 | Training constraint: -3.300441, duals [0.01]| lrm: 0.802326| num_tokens: 2,807
Step 00613/03096 | Training loss: 0.851775 | Training constraint: -12.286445, duals [0.01]| lrm: 0.802003| num_tokens: 2,311
Step 00614/03096 | Training loss: 1.041433 | Training constraint: -10.218540, duals [0.01]| lrm: 0.801680| num_tokens: 3,411
Step 00615/03096 | Training loss: 1.004917 | Training constraint: 0.821282, duals [0.1012513]| lrm: 0.801357| num_tokens: 1,008
Step 00616/03096 | Training loss: 0.885042 | Training constraint: -17.838589, duals [0.09114054]| lrm: 0.801034| num_tokens: 2,283
Step 00617/03096 | Training loss: 1.019388 | Training constraint: -4.495579, duals [0.08207268]| lrm: 0.800711| num_tokens: 3,767
Step 00618/03096 | Training loss: 1.066259 | Training constraint: -12.119737, duals [0.0738793]| lrm: 0.800388| num_tokens: 3,476
Step 00619/03096 | Training loss: 1.127558 | Training constraint: -16.927174, duals [0.06649943]| lrm: 0.800065| num_tokens: 4,323
Step 00620/03096 | Training loss: 0.960669 | Training constraint: -26.112774, duals [0.05985372]| lrm: 0.799742| num_tokens: 4,752
Step 00621/03096 | Training loss: 1.174131 | Training constraint: -14.010069, duals [0.05387474]| lrm: 0.799419| num_tokens: 4,121
Step 00622/03096 | Training loss: 0.961955 | Training constraint: -10.337765, duals [0.04849429]| lrm: 0.799096| num_tokens: 5,664
Step 00623/03096 | Training loss: 1.032047 | Training constraint: -8.844860, duals [0.0436515]| lrm: 0.798773| num_tokens: 5,064
Step 00624/03096 | Training loss: 0.961798 | Training constraint: -18.925850, duals [0.03928887]| lrm: 0.798450| num_tokens: 3,006
Step 00625/03096 | Training loss: 0.956609 | Training constraint: -13.398908, duals [0.03536286]| lrm: 0.798127| num_tokens: 3,289
Step 00626/03096 | Training loss: 1.137112 | Training constraint: -16.423546, duals [0.03182848]| lrm: 0.797804| num_tokens: 1,387
Step 00627/03096 | Training loss: 0.964367 | Training constraint: -5.852160, duals [0.02864996]| lrm: 0.797481| num_tokens: 2,995
Step 00628/03096 | Training loss: 1.155733 | Training constraint: -17.606028, duals [0.02578613]| lrm: 0.797158| num_tokens: 2,816
Step 00629/03096 | Training loss: 1.069238 | Training constraint: -14.101701, duals [0.02320869]| lrm: 0.796835| num_tokens: 4,310
Step 00630/03096 | Training loss: 1.014131 | Training constraint: -23.553825, duals [0.0208884]| lrm: 0.796512| num_tokens: 4,001
Step 00631/03096 | Training loss: 0.858867 | Training constraint: -14.460490, duals [0.01880031]| lrm: 0.796189| num_tokens: 3,696
Step 00632/03096 | Training loss: 0.885634 | Training constraint: -23.614450, duals [0.01692065]| lrm: 0.795866| num_tokens: 4,543
Step 00633/03096 | Training loss: 1.133895 | Training constraint: -14.303883, duals [0.01522909]| lrm: 0.795543| num_tokens: 2,308
Step 00634/03096 | Training loss: 0.711238 | Training constraint: -20.149136, duals [0.01370647]| lrm: 0.795220| num_tokens: 3,387
Step 00635/03096 | Training loss: 0.746911 | Training constraint: -24.020878, duals [0.01233602]| lrm: 0.794897| num_tokens: 3,878
Step 00636/03096 | Training loss: 0.884147 | Training constraint: -12.911495, duals [0.01110271]| lrm: 0.794574| num_tokens: 2,587
Step 00637/03096 | Training loss: 0.894597 | Training constraint: -8.855008, duals [0.01]| lrm: 0.794251| num_tokens: 3,420
Step 00638/03096 | Training loss: 0.855637 | Training constraint: -11.227201, duals [0.01]| lrm: 0.793928| num_tokens: 2,478
Step 00639/03096 | Training loss: 1.061709 | Training constraint: -17.874855, duals [0.01]| lrm: 0.793605| num_tokens: 2,439
Step 00640/03096 | Training loss: 1.125546 | Training constraint: -5.080050, duals [0.01]| lrm: 0.793282| num_tokens: 6,839
Step 00641/03096 | Training loss: 1.119613 | Training constraint: -12.160137, duals [0.01]| lrm: 0.792959| num_tokens: 5,122
Step 00642/03096 | Training loss: 1.146443 | Training constraint: -25.695908, duals [0.01]| lrm: 0.792636| num_tokens: 3,295
Step 00643/03096 | Training loss: 0.873320 | Training constraint: -5.832632, duals [0.01]| lrm: 0.792313| num_tokens: 1,880
Step 00644/03096 | Training loss: 0.967537 | Training constraint: -35.732918, duals [0.01]| lrm: 0.791990| num_tokens: 2,684
Step 00645/03096 | Training loss: 0.810294 | Training constraint: -16.985388, duals [0.01]| lrm: 0.791667| num_tokens: 1,033
Step 00646/03096 | Training loss: 1.005175 | Training constraint: -22.015955, duals [0.01]| lrm: 0.791344| num_tokens: 3,525
Step 00647/03096 | Training loss: 0.854849 | Training constraint: -20.562639, duals [0.01]| lrm: 0.791021| num_tokens: 3,670
Step 00648/03096 | Training loss: 0.955578 | Training constraint: -17.554256, duals [0.01]| lrm: 0.790698| num_tokens: 2,855
Step 00649/03096 | Training loss: 0.998345 | Training constraint: -16.197954, duals [0.01]| lrm: 0.790375| num_tokens: 5,234
Step 00650/03096 | Training loss: 1.043194 | Training constraint: -12.010234, duals [0.01]| lrm: 0.790052| num_tokens: 2,286
Step 00651/03096 | Training loss: 1.016522 | Training constraint: -27.306179, duals [0.01]| lrm: 0.789729| num_tokens: 4,650
Step 00652/03096 | Training loss: 1.036574 | Training constraint: -9.000116, duals [0.01]| lrm: 0.789406| num_tokens: 5,750
Step 00653/03096 | Training loss: 0.946245 | Training constraint: -22.484489, duals [0.01]| lrm: 0.789083| num_tokens: 4,224
Step 00654/03096 | Training loss: 0.932129 | Training constraint: -23.601810, duals [0.01]| lrm: 0.788760| num_tokens: 4,992
Step 00655/03096 | Training loss: 1.147584 | Training constraint: -8.215365, duals [0.01]| lrm: 0.788437| num_tokens: 2,840
Step 00656/03096 | Training loss: 0.848679 | Training constraint: -14.572617, duals [0.01]| lrm: 0.788114| num_tokens: 4,282
Step 00657/03096 | Training loss: 1.015978 | Training constraint: -13.218517, duals [0.01]| lrm: 0.787791| num_tokens: 1,343
Step 00658/03096 | Training loss: 0.806226 | Training constraint: -20.266605, duals [0.01]| lrm: 0.787468| num_tokens: 5,634
Step 00659/03096 | Training loss: 1.137854 | Training constraint: -16.787411, duals [0.01]| lrm: 0.787145| num_tokens: 3,401
Step 00660/03096 | Training loss: 0.812575 | Training constraint: -16.791046, duals [0.01]| lrm: 0.786822| num_tokens: 4,618
Step 00661/03096 | Training loss: 0.915554 | Training constraint: -22.488184, duals [0.01]| lrm: 0.786499| num_tokens: 3,829
Step 00662/03096 | Training loss: 1.245747 | Training constraint: -3.945873, duals [0.01]| lrm: 0.786176| num_tokens: 3,596
Step 00663/03096 | Training loss: 0.908471 | Training constraint: -23.842426, duals [0.01]| lrm: 0.785853| num_tokens: 1,662
Step 00664/03096 | Training loss: 1.113899 | Training constraint: -6.913312, duals [0.01]| lrm: 0.785530| num_tokens: 5,672
Step 00665/03096 | Training loss: 1.193874 | Training constraint: -14.943564, duals [0.01]| lrm: 0.785207| num_tokens: 3,778
Step 00666/03096 | Training loss: 1.072417 | Training constraint: -26.661579, duals [0.01]| lrm: 0.784884| num_tokens: 2,685
Step 00667/03096 | Training loss: 1.077230 | Training constraint: -11.865786, duals [0.01]| lrm: 0.784561| num_tokens: 4,606
Step 00668/03096 | Training loss: 0.832765 | Training constraint: -18.062162, duals [0.01]| lrm: 0.784238| num_tokens: 1,353
Step 00669/03096 | Training loss: 1.294636 | Training constraint: -19.417294, duals [0.01]| lrm: 0.783915| num_tokens: 4,970
Step 00670/03096 | Training loss: 1.089367 | Training constraint: -19.786434, duals [0.01]| lrm: 0.783592| num_tokens: 3,235
Step 00671/03096 | Training loss: 1.129843 | Training constraint: -37.046097, duals [0.01]| lrm: 0.783269| num_tokens: 3,619
Step 00672/03096 | Training loss: 0.970503 | Training constraint: -15.344809, duals [0.01]| lrm: 0.782946| num_tokens: 3,524
Step 00673/03096 | Training loss: 0.960581 | Training constraint: -18.905405, duals [0.01]| lrm: 0.782623| num_tokens: 5,287
Step 00674/03096 | Training loss: 1.078483 | Training constraint: -11.833821, duals [0.01]| lrm: 0.782300| num_tokens: 1,017
Step 00675/03096 | Training loss: 1.238430 | Training constraint: -34.415874, duals [0.01]| lrm: 0.781977| num_tokens: 3,636
Step 00676/03096 | Training loss: 1.074241 | Training constraint: -18.350733, duals [0.01]| lrm: 0.781654| num_tokens: 2,625
Step 00677/03096 | Training loss: 1.053267 | Training constraint: -8.734577, duals [0.01]| lrm: 0.781331| num_tokens: 4,921
Step 00678/03096 | Training loss: 1.214211 | Training constraint: -18.035610, duals [0.01]| lrm: 0.781008| num_tokens: 4,762
Step 00679/03096 | Training loss: 0.789509 | Training constraint: -20.838240, duals [0.01]| lrm: 0.780685| num_tokens: 3,636
Step 00680/03096 | Training loss: 1.277470 | Training constraint: -22.992092, duals [0.01]| lrm: 0.780362| num_tokens: 4,062
Step 00681/03096 | Training loss: 1.060526 | Training constraint: -10.971043, duals [0.01]| lrm: 0.780039| num_tokens: 2,340
Step 00682/03096 | Training loss: 0.836254 | Training constraint: -25.376272, duals [0.01]| lrm: 0.779716| num_tokens: 3,751
Step 00683/03096 | Training loss: 1.134033 | Training constraint: -37.701973, duals [0.01]| lrm: 0.779393| num_tokens: 4,835
Step 00684/03096 | Training loss: 0.920118 | Training constraint: -18.299160, duals [0.01]| lrm: 0.779070| num_tokens: 2,793
Step 00685/03096 | Training loss: 1.175387 | Training constraint: -19.291824, duals [0.01]| lrm: 0.778747| num_tokens: 3,619
Step 00686/03096 | Training loss: 1.119538 | Training constraint: -7.142553, duals [0.01]| lrm: 0.778424| num_tokens: 5,829
Step 00687/03096 | Training loss: 0.984636 | Training constraint: -11.152321, duals [0.01]| lrm: 0.778101| num_tokens: 2,153
Step 00688/03096 | Training loss: 1.267408 | Training constraint: -20.394096, duals [0.01]| lrm: 0.777778| num_tokens: 3,928
Step 00689/03096 | Training loss: 1.279863 | Training constraint: -11.979027, duals [0.01]| lrm: 0.777455| num_tokens: 2,868
Step 00690/03096 | Training loss: 1.136918 | Training constraint: -12.480569, duals [0.01]| lrm: 0.777132| num_tokens: 3,437
Step 00691/03096 | Training loss: 0.884285 | Training constraint: -11.805229, duals [0.01]| lrm: 0.776809| num_tokens: 3,321
Step 00692/03096 | Training loss: 1.106983 | Training constraint: -16.669621, duals [0.01]| lrm: 0.776486| num_tokens: 2,005
Step 00693/03096 | Training loss: 1.084711 | Training constraint: -15.237626, duals [0.01]| lrm: 0.776163| num_tokens: 3,957
Step 00694/03096 | Training loss: 0.912634 | Training constraint: -22.216436, duals [0.01]| lrm: 0.775840| num_tokens: 3,803
Step 00695/03096 | Training loss: 0.918484 | Training constraint: -14.352432, duals [0.01]| lrm: 0.775517| num_tokens: 4,387
Step 00696/03096 | Training loss: 1.080987 | Training constraint: -24.008600, duals [0.01]| lrm: 0.775194| num_tokens: 1,639
Step 00697/03096 | Training loss: 1.319900 | Training constraint: -13.021454, duals [0.01]| lrm: 0.774871| num_tokens: 3,519
Step 00698/03096 | Training loss: 1.129573 | Training constraint: -21.101036, duals [0.01]| lrm: 0.774548| num_tokens: 3,431
Step 00699/03096 | Training loss: 1.187228 | Training constraint: -15.666185, duals [0.01]| lrm: 0.774225| num_tokens: 2,824
Step 00700 | Validation loss: 1.151120
Step 00700/03096 | Training loss: 1.146116 | Training constraint: -21.600330, duals [0.01]| lrm: 0.773902| num_tokens: 2,815
Step 00701/03096 | Training loss: 1.028093 | Training constraint: -28.290241, duals [0.01]| lrm: 0.773579| num_tokens: 2,908
Step 00702/03096 | Training loss: 1.155632 | Training constraint: -17.604183, duals [0.01]| lrm: 0.773256| num_tokens: 2,793
Step 00703/03096 | Training loss: 0.947438 | Training constraint: -18.558235, duals [0.01]| lrm: 0.772933| num_tokens: 2,085
Step 00704/03096 | Training loss: 1.042127 | Training constraint: -7.882372, duals [0.01]| lrm: 0.772610| num_tokens: 4,465
Step 00705/03096 | Training loss: 1.003977 | Training constraint: -17.970406, duals [0.01]| lrm: 0.772287| num_tokens: 3,074
Step 00706/03096 | Training loss: 1.039279 | Training constraint: -11.506582, duals [0.01]| lrm: 0.771964| num_tokens: 1,830
Step 00707/03096 | Training loss: 1.297187 | Training constraint: -14.424986, duals [0.01]| lrm: 0.771641| num_tokens: 3,295
Step 00708/03096 | Training loss: 1.087229 | Training constraint: -35.957905, duals [0.01]| lrm: 0.771318| num_tokens: 5,776
Step 00709/03096 | Training loss: 1.000844 | Training constraint: -12.314467, duals [0.01]| lrm: 0.770995| num_tokens: 4,589
Step 00710/03096 | Training loss: 0.894019 | Training constraint: -10.663745, duals [0.01]| lrm: 0.770672| num_tokens: 2,685
Step 00711/03096 | Training loss: 0.875796 | Training constraint: -7.582240, duals [0.01]| lrm: 0.770349| num_tokens: 1,829
Step 00712/03096 | Training loss: 1.015053 | Training constraint: -14.359418, duals [0.01]| lrm: 0.770026| num_tokens: 2,601
Step 00713/03096 | Training loss: 1.012839 | Training constraint: -7.406700, duals [0.01]| lrm: 0.769703| num_tokens: 5,006
Step 00714/03096 | Training loss: 1.120115 | Training constraint: -15.196725, duals [0.01]| lrm: 0.769380| num_tokens: 4,517
Step 00715/03096 | Training loss: 1.124334 | Training constraint: -12.942620, duals [0.01]| lrm: 0.769057| num_tokens: 3,060
Step 00716/03096 | Training loss: 0.865142 | Training constraint: -16.208536, duals [0.01]| lrm: 0.768734| num_tokens: 1,974
Step 00717/03096 | Training loss: 1.104247 | Training constraint: -13.136993, duals [0.01]| lrm: 0.768411| num_tokens: 4,645
Step 00718/03096 | Training loss: 0.744398 | Training constraint: -19.886591, duals [0.01]| lrm: 0.768088| num_tokens: 3,807
Step 00719/03096 | Training loss: 1.025463 | Training constraint: -22.706526, duals [0.01]| lrm: 0.767765| num_tokens: 1,631
Step 00720/03096 | Training loss: 1.217443 | Training constraint: -17.944233, duals [0.01]| lrm: 0.767442| num_tokens: 4,339
Step 00721/03096 | Training loss: 0.990363 | Training constraint: -20.176889, duals [0.01]| lrm: 0.767119| num_tokens: 4,463
Step 00722/03096 | Training loss: 0.900454 | Training constraint: -17.976419, duals [0.01]| lrm: 0.766796| num_tokens: 4,750
Step 00723/03096 | Training loss: 0.853796 | Training constraint: -13.101515, duals [0.01]| lrm: 0.766473| num_tokens: 4,152
Step 00724/03096 | Training loss: 1.023597 | Training constraint: -14.241861, duals [0.01]| lrm: 0.766150| num_tokens: 2,189
Step 00725/03096 | Training loss: 1.003557 | Training constraint: -11.931832, duals [0.01]| lrm: 0.765827| num_tokens: 1,916
Step 00726/03096 | Training loss: 0.922087 | Training constraint: -22.059742, duals [0.01]| lrm: 0.765504| num_tokens: 6,079
Step 00727/03096 | Training loss: 0.818224 | Training constraint: -16.819332, duals [0.01]| lrm: 0.765181| num_tokens: 2,248
Step 00728/03096 | Training loss: 1.005889 | Training constraint: -10.845653, duals [0.01]| lrm: 0.764858| num_tokens: 3,815
Step 00729/03096 | Training loss: 1.075993 | Training constraint: -41.658524, duals [0.01]| lrm: 0.764535| num_tokens: 2,401
Step 00730/03096 | Training loss: 1.210304 | Training constraint: -20.580696, duals [0.01]| lrm: 0.764212| num_tokens: 3,452
Step 00731/03096 | Training loss: 1.145548 | Training constraint: -13.939931, duals [0.01]| lrm: 0.763889| num_tokens: 1,137
Step 00732/03096 | Training loss: 1.014618 | Training constraint: -12.158939, duals [0.01]| lrm: 0.763566| num_tokens: 4,658
Step 00733/03096 | Training loss: 1.017342 | Training constraint: -22.065222, duals [0.01]| lrm: 0.763243| num_tokens: 1,968
Step 00734/03096 | Training loss: 0.715858 | Training constraint: -24.273577, duals [0.01]| lrm: 0.762920| num_tokens: 4,147
Step 00735/03096 | Training loss: 1.186112 | Training constraint: -13.370033, duals [0.01]| lrm: 0.762597| num_tokens: 2,366
Step 00736/03096 | Training loss: 0.879449 | Training constraint: -16.557024, duals [0.01]| lrm: 0.762274| num_tokens: 4,477
Step 00737/03096 | Training loss: 1.101479 | Training constraint: -14.220886, duals [0.01]| lrm: 0.761951| num_tokens: 2,553
Step 00738/03096 | Training loss: 0.993802 | Training constraint: -14.079924, duals [0.01]| lrm: 0.761628| num_tokens: 4,286
Step 00739/03096 | Training loss: 1.067985 | Training constraint: -17.983822, duals [0.01]| lrm: 0.761305| num_tokens: 3,509
Step 00740/03096 | Training loss: 0.818845 | Training constraint: -12.842865, duals [0.01]| lrm: 0.760982| num_tokens: 1,827
Step 00741/03096 | Training loss: 0.942979 | Training constraint: -18.879055, duals [0.01]| lrm: 0.760659| num_tokens: 2,412
Step 00742/03096 | Training loss: 1.079897 | Training constraint: -20.502962, duals [0.01]| lrm: 0.760336| num_tokens: 1,602
Step 00743/03096 | Training loss: 1.306920 | Training constraint: -10.978365, duals [0.01]| lrm: 0.760013| num_tokens: 3,228
Step 00744/03096 | Training loss: 1.040951 | Training constraint: -16.049574, duals [0.01]| lrm: 0.759690| num_tokens: 4,201
Step 00745/03096 | Training loss: 0.765381 | Training constraint: -27.702629, duals [0.01]| lrm: 0.759367| num_tokens: 2,480
Step 00746/03096 | Training loss: 1.035732 | Training constraint: -18.128586, duals [0.01]| lrm: 0.759044| num_tokens: 1,989
Step 00747/03096 | Training loss: 1.075290 | Training constraint: -28.176130, duals [0.01]| lrm: 0.758721| num_tokens: 3,245
Step 00748/03096 | Training loss: 0.912248 | Training constraint: -13.510952, duals [0.01]| lrm: 0.758398| num_tokens: 1,791
Step 00749/03096 | Training loss: 1.051117 | Training constraint: -23.400715, duals [0.01]| lrm: 0.758075| num_tokens: 3,084
Step 00750/03096 | Training loss: 1.201755 | Training constraint: -32.491051, duals [0.01]| lrm: 0.757752| num_tokens: 3,641
Step 00751/03096 | Training loss: 0.834347 | Training constraint: -26.075037, duals [0.01]| lrm: 0.757429| num_tokens: 4,185
Step 00752/03096 | Training loss: 0.922004 | Training constraint: -20.414255, duals [0.01]| lrm: 0.757106| num_tokens: 3,607
Step 00753/03096 | Training loss: 1.021493 | Training constraint: -16.008139, duals [0.01]| lrm: 0.756783| num_tokens: 1,850
Step 00754/03096 | Training loss: 1.138317 | Training constraint: -16.449921, duals [0.01]| lrm: 0.756460| num_tokens: 2,675
Step 00755/03096 | Training loss: 1.015569 | Training constraint: -9.970567, duals [0.01]| lrm: 0.756137| num_tokens: 4,176
Step 00756/03096 | Training loss: 1.153094 | Training constraint: -16.887888, duals [0.01]| lrm: 0.755814| num_tokens: 5,529
Step 00757/03096 | Training loss: 0.846758 | Training constraint: -25.186661, duals [0.01]| lrm: 0.755491| num_tokens: 3,783
Step 00758/03096 | Training loss: 0.798908 | Training constraint: -21.346172, duals [0.01]| lrm: 0.755168| num_tokens: 3,154
Step 00759/03096 | Training loss: 1.134437 | Training constraint: -18.679447, duals [0.01]| lrm: 0.754845| num_tokens: 2,516
Step 00760/03096 | Training loss: 0.986070 | Training constraint: -26.891129, duals [0.01]| lrm: 0.754522| num_tokens: 3,369
Step 00761/03096 | Training loss: 1.060869 | Training constraint: -22.221443, duals [0.01]| lrm: 0.754199| num_tokens: 2,465
Step 00762/03096 | Training loss: 1.061863 | Training constraint: -12.865837, duals [0.01]| lrm: 0.753876| num_tokens: 3,693
Step 00763/03096 | Training loss: 0.997687 | Training constraint: -22.499313, duals [0.01]| lrm: 0.753553| num_tokens: 4,216
Step 00764/03096 | Training loss: 0.926754 | Training constraint: -10.207476, duals [0.01]| lrm: 0.753230| num_tokens: 3,625
Step 00765/03096 | Training loss: 1.176119 | Training constraint: -14.270300, duals [0.01]| lrm: 0.752907| num_tokens: 5,268
Step 00766/03096 | Training loss: 1.254692 | Training constraint: -26.371208, duals [0.01]| lrm: 0.752584| num_tokens: 5,033
Step 00767/03096 | Training loss: 0.856552 | Training constraint: -20.601826, duals [0.01]| lrm: 0.752261| num_tokens: 2,969
Step 00768/03096 | Training loss: 0.864740 | Training constraint: -20.684937, duals [0.01]| lrm: 0.751938| num_tokens: 3,153
Step 00769/03096 | Training loss: 0.961902 | Training constraint: -11.513037, duals [0.01]| lrm: 0.751615| num_tokens: 4,059
Step 00770/03096 | Training loss: 1.093148 | Training constraint: -30.266994, duals [0.01]| lrm: 0.751292| num_tokens: 3,671
Step 00771/03096 | Training loss: 1.036791 | Training constraint: -13.401594, duals [0.01]| lrm: 0.750969| num_tokens: 4,912
Step 00772/03096 | Training loss: 0.942333 | Training constraint: -31.213245, duals [0.01]| lrm: 0.750646| num_tokens: 1,904
Step 00773/03096 | Training loss: 1.065520 | Training constraint: -10.397941, duals [0.01]| lrm: 0.750323| num_tokens: 7,400
Step 00774/03096 | Training loss: 1.051157 | Training constraint: -18.718815, duals [0.01]| lrm: 0.750000| num_tokens: 4,580
Step 00775/03096 | Training loss: 0.987109 | Training constraint: -28.812319, duals [0.01]| lrm: 0.749677| num_tokens: 3,456
Step 00776/03096 | Training loss: 0.899058 | Training constraint: -8.410175, duals [0.01]| lrm: 0.749354| num_tokens: 1,423
Step 00777/03096 | Training loss: 1.027351 | Training constraint: -31.344940, duals [0.01]| lrm: 0.749031| num_tokens: 3,603
Step 00778/03096 | Training loss: 1.031059 | Training constraint: -14.596539, duals [0.01]| lrm: 0.748708| num_tokens: 2,859
Step 00779/03096 | Training loss: 1.100270 | Training constraint: -11.841991, duals [0.01]| lrm: 0.748385| num_tokens: 4,006
Step 00780/03096 | Training loss: 0.834704 | Training constraint: -11.129177, duals [0.01]| lrm: 0.748062| num_tokens: 2,276
Step 00781/03096 | Training loss: 1.077982 | Training constraint: -13.189379, duals [0.01]| lrm: 0.747739| num_tokens: 4,797
Step 00782/03096 | Training loss: 1.072405 | Training constraint: -24.168501, duals [0.01]| lrm: 0.747416| num_tokens: 3,340
Step 00783/03096 | Training loss: 1.316334 | Training constraint: -3.505344, duals [0.01]| lrm: 0.747093| num_tokens: 5,455
Step 00784/03096 | Training loss: 1.091789 | Training constraint: -13.269131, duals [0.01]| lrm: 0.746770| num_tokens: 1,372
Step 00785/03096 | Training loss: 0.931711 | Training constraint: -28.936157, duals [0.01]| lrm: 0.746447| num_tokens: 4,292
Step 00786/03096 | Training loss: 1.350440 | Training constraint: -19.027201, duals [0.01]| lrm: 0.746124| num_tokens: 2,444
Step 00787/03096 | Training loss: 0.570204 | Training constraint: -28.834257, duals [0.01]| lrm: 0.745801| num_tokens: 2,353
Step 00788/03096 | Training loss: 1.145432 | Training constraint: -8.669525, duals [0.01]| lrm: 0.745478| num_tokens: 1,234
Step 00789/03096 | Training loss: 1.125560 | Training constraint: -12.328909, duals [0.01]| lrm: 0.745155| num_tokens: 3,054
Step 00790/03096 | Training loss: 1.348793 | Training constraint: -15.752695, duals [0.01]| lrm: 0.744832| num_tokens: 3,687
Step 00791/03096 | Training loss: 1.257997 | Training constraint: -8.783869, duals [0.01]| lrm: 0.744509| num_tokens: 3,367
Step 00792/03096 | Training loss: 0.967044 | Training constraint: -21.382189, duals [0.01]| lrm: 0.744186| num_tokens: 1,827
Step 00793/03096 | Training loss: 0.892543 | Training constraint: -25.763206, duals [0.01]| lrm: 0.743863| num_tokens: 4,572
Step 00794/03096 | Training loss: 0.910578 | Training constraint: -35.224365, duals [0.01]| lrm: 0.743540| num_tokens: 4,792
Step 00795/03096 | Training loss: 1.069115 | Training constraint: -13.935584, duals [0.01]| lrm: 0.743217| num_tokens: 4,005
Step 00796/03096 | Training loss: 0.894010 | Training constraint: -24.887386, duals [0.01]| lrm: 0.742894| num_tokens: 3,711
Step 00797/03096 | Training loss: 0.973385 | Training constraint: -17.944826, duals [0.01]| lrm: 0.742571| num_tokens: 4,750
Step 00798/03096 | Training loss: 0.705755 | Training constraint: -28.979395, duals [0.01]| lrm: 0.742248| num_tokens: 2,860
Step 00799/03096 | Training loss: 1.057700 | Training constraint: -24.438021, duals [0.01]| lrm: 0.741925| num_tokens: 2,048
Step 00800 | Validation loss: 1.152194
2026-01-21 14:13:30,436 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:13:30,437 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:13:30,441 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:13:30,442 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:13:30,555 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:13:30,555 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:13:30,917 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:13:30,952 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:13:31,109 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:13:31,140 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:13:31,292 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:13:31,297 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 308/1024 (30.08%)
2026-01-21 14:13:31,889 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:13:31,893 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:13:31,897 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:13:31,906 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:13:32,009 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:13:32,023 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:13:32,134 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:13:32,140 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:13:32,249 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:13:32,256 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:13:32,379 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:13:32,381 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:13:32,494 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:13:32,571 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 352/1024 (34.38%)
Step 00800 | mmlu_acc: 0.300781, arc_easy_acc: 0.343750
Step 00800/03096 | Training loss: 0.859245 | Training constraint: -35.803665, duals [0.01]| lrm: 0.741602| num_tokens: 2,135
Step 00801/03096 | Training loss: 1.095269 | Training constraint: -13.758835, duals [0.01]| lrm: 0.741279| num_tokens: 6,281
Step 00802/03096 | Training loss: 1.078594 | Training constraint: -13.859672, duals [0.01]| lrm: 0.740956| num_tokens: 3,007
Step 00803/03096 | Training loss: 0.876827 | Training constraint: -13.386643, duals [0.01]| lrm: 0.740633| num_tokens: 4,006
Step 00804/03096 | Training loss: 0.970296 | Training constraint: -27.513044, duals [0.01]| lrm: 0.740310| num_tokens: 3,641
Step 00805/03096 | Training loss: 0.823660 | Training constraint: -41.593563, duals [0.01]| lrm: 0.739987| num_tokens: 3,027
Step 00806/03096 | Training loss: 1.134961 | Training constraint: -17.240555, duals [0.01]| lrm: 0.739664| num_tokens: 4,284
Step 00807/03096 | Training loss: 0.833182 | Training constraint: -19.602808, duals [0.01]| lrm: 0.739341| num_tokens: 3,409
Step 00808/03096 | Training loss: 0.895278 | Training constraint: -17.655355, duals [0.01]| lrm: 0.739018| num_tokens: 5,102
Step 00809/03096 | Training loss: 0.986105 | Training constraint: -32.085388, duals [0.01]| lrm: 0.738695| num_tokens: 683
Step 00810/03096 | Training loss: 1.012959 | Training constraint: -19.715401, duals [0.01]| lrm: 0.738372| num_tokens: 3,684
Step 00811/03096 | Training loss: 0.984740 | Training constraint: -33.316628, duals [0.01]| lrm: 0.738049| num_tokens: 3,124
Step 00812/03096 | Training loss: 1.031397 | Training constraint: -21.888056, duals [0.01]| lrm: 0.737726| num_tokens: 3,314
Step 00813/03096 | Training loss: 1.251199 | Training constraint: -35.381107, duals [0.01]| lrm: 0.737403| num_tokens: 1,425
Step 00814/03096 | Training loss: 0.962976 | Training constraint: -13.615128, duals [0.01]| lrm: 0.737080| num_tokens: 4,542
Step 00815/03096 | Training loss: 1.077784 | Training constraint: -22.523592, duals [0.01]| lrm: 0.736757| num_tokens: 3,262
Step 00816/03096 | Training loss: 1.008526 | Training constraint: -13.608812, duals [0.01]| lrm: 0.736434| num_tokens: 3,817
Step 00817/03096 | Training loss: 1.040461 | Training constraint: -10.122250, duals [0.01]| lrm: 0.736111| num_tokens: 1,531
Step 00818/03096 | Training loss: 0.991702 | Training constraint: -11.759340, duals [0.01]| lrm: 0.735788| num_tokens: 4,590
Step 00819/03096 | Training loss: 0.893197 | Training constraint: -23.005787, duals [0.01]| lrm: 0.735465| num_tokens: 2,146
Step 00820/03096 | Training loss: 1.050668 | Training constraint: -22.458849, duals [0.01]| lrm: 0.735142| num_tokens: 4,384
Step 00821/03096 | Training loss: 0.963334 | Training constraint: -11.249874, duals [0.01]| lrm: 0.734819| num_tokens: 3,320
Step 00822/03096 | Training loss: 1.001105 | Training constraint: -9.352934, duals [0.01]| lrm: 0.734496| num_tokens: 4,764
Step 00823/03096 | Training loss: 0.894901 | Training constraint: -8.855422, duals [0.01]| lrm: 0.734173| num_tokens: 3,843
Step 00824/03096 | Training loss: 1.093589 | Training constraint: -7.052564, duals [0.01]| lrm: 0.733850| num_tokens: 2,723
Step 00825/03096 | Training loss: 1.143059 | Training constraint: -8.231852, duals [0.01]| lrm: 0.733527| num_tokens: 5,926
Step 00826/03096 | Training loss: 0.606949 | Training constraint: -0.439202, duals [0.01]| lrm: 0.733204| num_tokens: 3,800
Step 00827/03096 | Training loss: 1.141454 | Training constraint: -15.780136, duals [0.01]| lrm: 0.732881| num_tokens: 5,024
Step 00828/03096 | Training loss: 1.224398 | Training constraint: -11.364818, duals [0.01]| lrm: 0.732558| num_tokens: 1,336
Step 00829/03096 | Training loss: 1.006208 | Training constraint: -12.342607, duals [0.01]| lrm: 0.732235| num_tokens: 2,811
Step 00830/03096 | Training loss: 0.986922 | Training constraint: -26.937971, duals [0.01]| lrm: 0.731912| num_tokens: 4,602
Step 00831/03096 | Training loss: 1.132427 | Training constraint: -18.556690, duals [0.01]| lrm: 0.731589| num_tokens: 919
Step 00832/03096 | Training loss: 0.971202 | Training constraint: -52.552399, duals [0.01]| lrm: 0.731266| num_tokens: 1,558
Step 00833/03096 | Training loss: 1.113502 | Training constraint: -13.162947, duals [0.01]| lrm: 0.730943| num_tokens: 1,800
Step 00834/03096 | Training loss: 0.904298 | Training constraint: -17.243494, duals [0.01]| lrm: 0.730620| num_tokens: 6,760
Step 00835/03096 | Training loss: 1.299547 | Training constraint: -15.630183, duals [0.01]| lrm: 0.730297| num_tokens: 4,155
Step 00836/03096 | Training loss: 1.297161 | Training constraint: -18.119867, duals [0.01]| lrm: 0.729974| num_tokens: 2,490
Step 00837/03096 | Training loss: 1.021866 | Training constraint: -18.783119, duals [0.01]| lrm: 0.729651| num_tokens: 5,723
Step 00838/03096 | Training loss: 1.162853 | Training constraint: -25.732513, duals [0.01]| lrm: 0.729328| num_tokens: 3,536
Step 00839/03096 | Training loss: 1.019722 | Training constraint: -5.280573, duals [0.01]| lrm: 0.729005| num_tokens: 5,044
Step 00840/03096 | Training loss: 0.948425 | Training constraint: -26.485607, duals [0.01]| lrm: 0.728682| num_tokens: 2,218
Step 00841/03096 | Training loss: 1.137029 | Training constraint: -17.320345, duals [0.01]| lrm: 0.728359| num_tokens: 4,929
Step 00842/03096 | Training loss: 1.139912 | Training constraint: -19.492985, duals [0.01]| lrm: 0.728036| num_tokens: 4,484
Step 00843/03096 | Training loss: 1.161533 | Training constraint: -30.447931, duals [0.01]| lrm: 0.727713| num_tokens: 3,208
Step 00844/03096 | Training loss: 1.032816 | Training constraint: -19.660484, duals [0.01]| lrm: 0.727390| num_tokens: 2,589
Step 00845/03096 | Training loss: 1.153872 | Training constraint: -20.088564, duals [0.01]| lrm: 0.727067| num_tokens: 3,456
Step 00846/03096 | Training loss: 1.350126 | Training constraint: -8.914766, duals [0.01]| lrm: 0.726744| num_tokens: 3,922
Step 00847/03096 | Training loss: 1.109129 | Training constraint: -15.798978, duals [0.01]| lrm: 0.726421| num_tokens: 4,770
Step 00848/03096 | Training loss: 0.975172 | Training constraint: -35.122860, duals [0.01]| lrm: 0.726098| num_tokens: 3,228
Step 00849/03096 | Training loss: 1.271519 | Training constraint: -26.185400, duals [0.01]| lrm: 0.725775| num_tokens: 2,793
Step 00850/03096 | Training loss: 1.063076 | Training constraint: -26.189947, duals [0.01]| lrm: 0.725452| num_tokens: 4,334
Step 00851/03096 | Training loss: 0.965530 | Training constraint: -7.113786, duals [0.01]| lrm: 0.725129| num_tokens: 3,265
Step 00852/03096 | Training loss: 1.051930 | Training constraint: -24.160101, duals [0.01]| lrm: 0.724806| num_tokens: 5,528
Step 00853/03096 | Training loss: 1.074013 | Training constraint: -11.631134, duals [0.01]| lrm: 0.724483| num_tokens: 3,106
Step 00854/03096 | Training loss: 0.932025 | Training constraint: -20.088530, duals [0.01]| lrm: 0.724160| num_tokens: 1,486
Step 00855/03096 | Training loss: 0.684977 | Training constraint: -21.006586, duals [0.01]| lrm: 0.723837| num_tokens: 4,352
Step 00856/03096 | Training loss: 0.844817 | Training constraint: -15.730165, duals [0.01]| lrm: 0.723514| num_tokens: 5,538
Step 00857/03096 | Training loss: 1.333916 | Training constraint: -19.943686, duals [0.01]| lrm: 0.723191| num_tokens: 5,277
Step 00858/03096 | Training loss: 1.033074 | Training constraint: -26.733877, duals [0.01]| lrm: 0.722868| num_tokens: 2,607
Step 00859/03096 | Training loss: 0.805736 | Training constraint: -22.085426, duals [0.01]| lrm: 0.722545| num_tokens: 1,981
Step 00860/03096 | Training loss: 1.278855 | Training constraint: -19.548771, duals [0.01]| lrm: 0.722222| num_tokens: 5,118
Step 00861/03096 | Training loss: 0.953725 | Training constraint: -38.914959, duals [0.01]| lrm: 0.721899| num_tokens: 1,418
Step 00862/03096 | Training loss: 1.054638 | Training constraint: -19.651596, duals [0.01]| lrm: 0.721576| num_tokens: 4,362
Step 00863/03096 | Training loss: 1.208532 | Training constraint: -22.281773, duals [0.01]| lrm: 0.721253| num_tokens: 3,065
Step 00864/03096 | Training loss: 0.902369 | Training constraint: -32.047199, duals [0.01]| lrm: 0.720930| num_tokens: 3,081
Step 00865/03096 | Training loss: 0.979188 | Training constraint: -20.090464, duals [0.01]| lrm: 0.720607| num_tokens: 5,423
Step 00866/03096 | Training loss: 1.411949 | Training constraint: -11.016958, duals [0.01]| lrm: 0.720284| num_tokens: 5,917
Step 00867/03096 | Training loss: 0.771712 | Training constraint: -20.995581, duals [0.01]| lrm: 0.719961| num_tokens: 2,279
Step 00868/03096 | Training loss: 0.964928 | Training constraint: -24.654814, duals [0.01]| lrm: 0.719638| num_tokens: 2,203
Step 00869/03096 | Training loss: 0.840422 | Training constraint: -20.882254, duals [0.01]| lrm: 0.719315| num_tokens: 6,166
Step 00870/03096 | Training loss: 1.370200 | Training constraint: -21.778566, duals [0.01]| lrm: 0.718992| num_tokens: 1,947
Step 00871/03096 | Training loss: 0.774514 | Training constraint: -26.353394, duals [0.01]| lrm: 0.718669| num_tokens: 1,895
Step 00872/03096 | Training loss: 1.117676 | Training constraint: -21.427650, duals [0.01]| lrm: 0.718346| num_tokens: 1,087
Step 00873/03096 | Training loss: 1.244308 | Training constraint: -10.832437, duals [0.01]| lrm: 0.718023| num_tokens: 1,964
Step 00874/03096 | Training loss: 0.968476 | Training constraint: -21.818752, duals [0.01]| lrm: 0.717700| num_tokens: 997
Step 00875/03096 | Training loss: 1.186445 | Training constraint: -9.587202, duals [0.01]| lrm: 0.717377| num_tokens: 3,109
Step 00876/03096 | Training loss: 0.918773 | Training constraint: -16.503679, duals [0.01]| lrm: 0.717054| num_tokens: 3,399
Step 00877/03096 | Training loss: 0.896742 | Training constraint: -29.858171, duals [0.01]| lrm: 0.716731| num_tokens: 1,475
Step 00878/03096 | Training loss: 1.000762 | Training constraint: -36.769260, duals [0.01]| lrm: 0.716408| num_tokens: 4,800
Step 00879/03096 | Training loss: 0.876043 | Training constraint: -15.336489, duals [0.01]| lrm: 0.716085| num_tokens: 2,949
Step 00880/03096 | Training loss: 0.858628 | Training constraint: -21.817062, duals [0.01]| lrm: 0.715762| num_tokens: 3,025
Step 00881/03096 | Training loss: 1.247927 | Training constraint: -16.684351, duals [0.01]| lrm: 0.715439| num_tokens: 4,767
Step 00882/03096 | Training loss: 0.807673 | Training constraint: -30.665661, duals [0.01]| lrm: 0.715116| num_tokens: 2,268
Step 00883/03096 | Training loss: 0.977136 | Training constraint: -24.167667, duals [0.01]| lrm: 0.714793| num_tokens: 3,993
Step 00884/03096 | Training loss: 1.092098 | Training constraint: -27.256382, duals [0.01]| lrm: 0.714470| num_tokens: 2,379
Step 00885/03096 | Training loss: 1.101541 | Training constraint: -5.554287, duals [0.01]| lrm: 0.714147| num_tokens: 2,050
Step 00886/03096 | Training loss: 0.943721 | Training constraint: -29.943176, duals [0.01]| lrm: 0.713824| num_tokens: 4,735
Step 00887/03096 | Training loss: 1.268986 | Training constraint: -21.979759, duals [0.01]| lrm: 0.713501| num_tokens: 3,055
Step 00888/03096 | Training loss: 0.900207 | Training constraint: -30.063156, duals [0.01]| lrm: 0.713178| num_tokens: 2,853
Step 00889/03096 | Training loss: 0.893629 | Training constraint: -26.804085, duals [0.01]| lrm: 0.712855| num_tokens: 1,928
Step 00890/03096 | Training loss: 1.123684 | Training constraint: -18.564154, duals [0.01]| lrm: 0.712532| num_tokens: 2,638
Step 00891/03096 | Training loss: 0.777203 | Training constraint: -35.178749, duals [0.01]| lrm: 0.712209| num_tokens: 2,715
Step 00892/03096 | Training loss: 0.974449 | Training constraint: -18.290470, duals [0.01]| lrm: 0.711886| num_tokens: 3,394
Step 00893/03096 | Training loss: 1.221713 | Training constraint: -20.385719, duals [0.01]| lrm: 0.711563| num_tokens: 3,378
Step 00894/03096 | Training loss: 0.956176 | Training constraint: -16.144745, duals [0.01]| lrm: 0.711240| num_tokens: 3,018
Step 00895/03096 | Training loss: 1.154621 | Training constraint: -33.650238, duals [0.01]| lrm: 0.710917| num_tokens: 2,778
Step 00896/03096 | Training loss: 1.146838 | Training constraint: -19.800781, duals [0.01]| lrm: 0.710594| num_tokens: 2,895
Step 00897/03096 | Training loss: 1.121375 | Training constraint: -33.466339, duals [0.01]| lrm: 0.710271| num_tokens: 2,259
Step 00898/03096 | Training loss: 0.977906 | Training constraint: -20.868565, duals [0.01]| lrm: 0.709948| num_tokens: 3,827
Step 00899/03096 | Training loss: 1.130437 | Training constraint: -33.449211, duals [0.01]| lrm: 0.709625| num_tokens: 3,956
Step 00900 | Validation loss: 1.153630
Step 00900/03096 | Training loss: 0.911787 | Training constraint: -29.732977, duals [0.01]| lrm: 0.709302| num_tokens: 1,224
Step 00901/03096 | Training loss: 1.040012 | Training constraint: -27.866949, duals [0.01]| lrm: 0.708979| num_tokens: 1,950
Step 00902/03096 | Training loss: 1.104416 | Training constraint: -15.700317, duals [0.01]| lrm: 0.708656| num_tokens: 6,806
Step 00903/03096 | Training loss: 1.128991 | Training constraint: -17.851778, duals [0.01]| lrm: 0.708333| num_tokens: 3,961
Step 00904/03096 | Training loss: 1.095608 | Training constraint: -15.348344, duals [0.01]| lrm: 0.708010| num_tokens: 3,119
Step 00905/03096 | Training loss: 1.058952 | Training constraint: -28.619007, duals [0.01]| lrm: 0.707687| num_tokens: 3,383
Step 00906/03096 | Training loss: 1.245624 | Training constraint: -32.146935, duals [0.01]| lrm: 0.707364| num_tokens: 4,898
Step 00907/03096 | Training loss: 0.719241 | Training constraint: -29.464727, duals [0.01]| lrm: 0.707041| num_tokens: 3,510
Step 00908/03096 | Training loss: 0.778396 | Training constraint: -23.681019, duals [0.01]| lrm: 0.706718| num_tokens: 2,431
Step 00909/03096 | Training loss: 0.928036 | Training constraint: -20.757750, duals [0.01]| lrm: 0.706395| num_tokens: 2,496
Step 00910/03096 | Training loss: 1.110250 | Training constraint: -28.236612, duals [0.01]| lrm: 0.706072| num_tokens: 5,672
Step 00911/03096 | Training loss: 1.204773 | Training constraint: -26.796230, duals [0.01]| lrm: 0.705749| num_tokens: 4,988
Step 00912/03096 | Training loss: 1.037451 | Training constraint: -20.668264, duals [0.01]| lrm: 0.705426| num_tokens: 7,060
Step 00913/03096 | Training loss: 1.003527 | Training constraint: -25.836693, duals [0.01]| lrm: 0.705103| num_tokens: 6,402
Step 00914/03096 | Training loss: 0.891682 | Training constraint: -21.058842, duals [0.01]| lrm: 0.704780| num_tokens: 2,358
Step 00915/03096 | Training loss: 1.107574 | Training constraint: -23.145939, duals [0.01]| lrm: 0.704457| num_tokens: 4,250
Step 00916/03096 | Training loss: 0.907230 | Training constraint: -19.212057, duals [0.01]| lrm: 0.704134| num_tokens: 3,925
Step 00917/03096 | Training loss: 0.838708 | Training constraint: -35.557251, duals [0.01]| lrm: 0.703811| num_tokens: 4,661
Step 00918/03096 | Training loss: 0.901965 | Training constraint: -28.041328, duals [0.01]| lrm: 0.703488| num_tokens: 2,156
Step 00919/03096 | Training loss: 0.834567 | Training constraint: -33.334309, duals [0.01]| lrm: 0.703165| num_tokens: 2,740
Step 00920/03096 | Training loss: 0.998887 | Training constraint: -38.849285, duals [0.01]| lrm: 0.702842| num_tokens: 2,951
Step 00921/03096 | Training loss: 1.034234 | Training constraint: -9.221139, duals [0.01]| lrm: 0.702519| num_tokens: 2,524
Step 00922/03096 | Training loss: 0.866069 | Training constraint: -29.746872, duals [0.01]| lrm: 0.702196| num_tokens: 928
Step 00923/03096 | Training loss: 1.029328 | Training constraint: -23.287706, duals [0.01]| lrm: 0.701873| num_tokens: 2,693
Step 00924/03096 | Training loss: 0.843902 | Training constraint: -13.675618, duals [0.01]| lrm: 0.701550| num_tokens: 1,271
Step 00925/03096 | Training loss: 1.082317 | Training constraint: -27.534718, duals [0.01]| lrm: 0.701227| num_tokens: 5,020
Step 00926/03096 | Training loss: 0.888948 | Training constraint: -11.627058, duals [0.01]| lrm: 0.700904| num_tokens: 2,271
Step 00927/03096 | Training loss: 1.170964 | Training constraint: -14.270753, duals [0.01]| lrm: 0.700581| num_tokens: 2,965
Step 00928/03096 | Training loss: 0.994449 | Training constraint: -25.856966, duals [0.01]| lrm: 0.700258| num_tokens: 2,096
Step 00929/03096 | Training loss: 1.083416 | Training constraint: -28.104412, duals [0.01]| lrm: 0.699935| num_tokens: 2,499
Step 00930/03096 | Training loss: 0.977258 | Training constraint: -25.910061, duals [0.01]| lrm: 0.699612| num_tokens: 1,907
Step 00931/03096 | Training loss: 1.119270 | Training constraint: -36.899063, duals [0.01]| lrm: 0.699289| num_tokens: 2,155
Step 00932/03096 | Training loss: 1.064166 | Training constraint: -38.209789, duals [0.01]| lrm: 0.698966| num_tokens: 3,094
Step 00933/03096 | Training loss: 0.940303 | Training constraint: -37.488285, duals [0.01]| lrm: 0.698643| num_tokens: 5,338
Step 00934/03096 | Training loss: 1.040816 | Training constraint: -23.826427, duals [0.01]| lrm: 0.698320| num_tokens: 5,214
Step 00935/03096 | Training loss: 1.119929 | Training constraint: -17.303379, duals [0.01]| lrm: 0.697997| num_tokens: 3,680
Step 00936/03096 | Training loss: 0.972758 | Training constraint: -53.560200, duals [0.01]| lrm: 0.697674| num_tokens: 4,775
Step 00937/03096 | Training loss: 1.032416 | Training constraint: -22.777523, duals [0.01]| lrm: 0.697351| num_tokens: 3,167
Step 00938/03096 | Training loss: 0.946458 | Training constraint: -27.124577, duals [0.01]| lrm: 0.697028| num_tokens: 5,837
Step 00939/03096 | Training loss: 1.031878 | Training constraint: -22.856838, duals [0.01]| lrm: 0.696705| num_tokens: 1,337
Step 00940/03096 | Training loss: 0.765491 | Training constraint: -38.498314, duals [0.01]| lrm: 0.696382| num_tokens: 2,394
Step 00941/03096 | Training loss: 1.056929 | Training constraint: -37.485184, duals [0.01]| lrm: 0.696059| num_tokens: 1,245
Step 00942/03096 | Training loss: 0.835117 | Training constraint: -29.840374, duals [0.01]| lrm: 0.695736| num_tokens: 2,165
Step 00943/03096 | Training loss: 1.084445 | Training constraint: -37.264420, duals [0.01]| lrm: 0.695413| num_tokens: 4,034
Step 00944/03096 | Training loss: 0.982598 | Training constraint: -40.050415, duals [0.01]| lrm: 0.695090| num_tokens: 2,730
Step 00945/03096 | Training loss: 1.224822 | Training constraint: -26.914974, duals [0.01]| lrm: 0.694767| num_tokens: 2,104
Step 00946/03096 | Training loss: 1.141567 | Training constraint: -21.179243, duals [0.01]| lrm: 0.694444| num_tokens: 2,392
Step 00947/03096 | Training loss: 1.121036 | Training constraint: -32.980873, duals [0.01]| lrm: 0.694121| num_tokens: 1,502
Step 00948/03096 | Training loss: 1.216676 | Training constraint: -38.883804, duals [0.01]| lrm: 0.693798| num_tokens: 4,454
Step 00949/03096 | Training loss: 0.707089 | Training constraint: -37.539516, duals [0.01]| lrm: 0.693475| num_tokens: 4,012
Step 00950/03096 | Training loss: 1.036645 | Training constraint: -38.529861, duals [0.01]| lrm: 0.693152| num_tokens: 2,439
Step 00951/03096 | Training loss: 0.980836 | Training constraint: -31.446423, duals [0.01]| lrm: 0.692829| num_tokens: 1,578
Step 00952/03096 | Training loss: 1.113092 | Training constraint: -57.980141, duals [0.01]| lrm: 0.692506| num_tokens: 2,567
Step 00953/03096 | Training loss: 1.038784 | Training constraint: -29.463436, duals [0.01]| lrm: 0.692183| num_tokens: 3,045
Step 00954/03096 | Training loss: 1.042327 | Training constraint: -49.180931, duals [0.01]| lrm: 0.691860| num_tokens: 3,161
Step 00955/03096 | Training loss: 1.020877 | Training constraint: -22.908031, duals [0.01]| lrm: 0.691537| num_tokens: 2,990
Step 00956/03096 | Training loss: 1.204116 | Training constraint: -66.008263, duals [0.01]| lrm: 0.691214| num_tokens: 1,320
Step 00957/03096 | Training loss: 1.186870 | Training constraint: -57.523483, duals [0.01]| lrm: 0.690891| num_tokens: 3,517
Step 00958/03096 | Training loss: 1.144537 | Training constraint: -22.757313, duals [0.01]| lrm: 0.690568| num_tokens: 3,934
Step 00959/03096 | Training loss: 1.026126 | Training constraint: -42.693230, duals [0.01]| lrm: 0.690245| num_tokens: 1,689
Step 00960/03096 | Training loss: 1.086799 | Training constraint: -43.668728, duals [0.01]| lrm: 0.689922| num_tokens: 979
Step 00961/03096 | Training loss: 1.192454 | Training constraint: -41.959160, duals [0.01]| lrm: 0.689599| num_tokens: 3,798
Step 00962/03096 | Training loss: 1.386315 | Training constraint: -47.249138, duals [0.01]| lrm: 0.689276| num_tokens: 3,429
Step 00963/03096 | Training loss: 1.192603 | Training constraint: -62.311096, duals [0.01]| lrm: 0.688953| num_tokens: 2,339
Step 00964/03096 | Training loss: 1.020079 | Training constraint: -63.530739, duals [0.01]| lrm: 0.688630| num_tokens: 2,807
Step 00965/03096 | Training loss: 0.883608 | Training constraint: -33.912262, duals [0.01]| lrm: 0.688307| num_tokens: 2,406
Step 00966/03096 | Training loss: 1.132913 | Training constraint: -41.300438, duals [0.01]| lrm: 0.687984| num_tokens: 2,891
Step 00967/03096 | Training loss: 1.159406 | Training constraint: -51.697468, duals [0.01]| lrm: 0.687661| num_tokens: 4,888
Step 00968/03096 | Training loss: 1.278894 | Training constraint: -58.971458, duals [0.01]| lrm: 0.687339| num_tokens: 1,028
Step 00969/03096 | Training loss: 0.790806 | Training constraint: -75.216644, duals [0.01]| lrm: 0.687016| num_tokens: 2,083
Step 00970/03096 | Training loss: 0.926939 | Training constraint: -62.661003, duals [0.01]| lrm: 0.686693| num_tokens: 2,744
Step 00971/03096 | Training loss: 1.212351 | Training constraint: -77.205795, duals [0.01]| lrm: 0.686370| num_tokens: 6,190
Step 00972/03096 | Training loss: 1.197327 | Training constraint: -84.448860, duals [0.01]| lrm: 0.686047| num_tokens: 3,215
Step 00973/03096 | Training loss: 0.949306 | Training constraint: -38.993286, duals [0.01]| lrm: 0.685724| num_tokens: 2,002
Step 00974/03096 | Training loss: 1.109650 | Training constraint: -20.028782, duals [0.01]| lrm: 0.685401| num_tokens: 2,114
Step 00975/03096 | Training loss: 1.315256 | Training constraint: -112.807343, duals [0.01]| lrm: 0.685078| num_tokens: 3,323
Step 00976/03096 | Training loss: 1.185897 | Training constraint: -46.350430, duals [0.01]| lrm: 0.684755| num_tokens: 3,350
Step 00977/03096 | Training loss: 0.823602 | Training constraint: -60.407814, duals [0.01]| lrm: 0.684432| num_tokens: 2,305
Step 00978/03096 | Training loss: 1.002534 | Training constraint: -66.070419, duals [0.01]| lrm: 0.684109| num_tokens: 3,973
Step 00979/03096 | Training loss: 1.293506 | Training constraint: -109.610786, duals [0.01]| lrm: 0.683786| num_tokens: 2,796
Step 00980/03096 | Training loss: 1.007696 | Training constraint: -68.834885, duals [0.01]| lrm: 0.683463| num_tokens: 3,580
Step 00981/03096 | Training loss: 0.900317 | Training constraint: -71.024956, duals [0.01]| lrm: 0.683140| num_tokens: 3,842
Step 00982/03096 | Training loss: 0.945163 | Training constraint: -76.685150, duals [0.01]| lrm: 0.682817| num_tokens: 4,320
Step 00983/03096 | Training loss: 0.680421 | Training constraint: -42.453186, duals [0.01]| lrm: 0.682494| num_tokens: 2,160
Step 00984/03096 | Training loss: 1.185108 | Training constraint: -86.735809, duals [0.01]| lrm: 0.682171| num_tokens: 2,453
Step 00985/03096 | Training loss: 1.229062 | Training constraint: -121.333191, duals [0.01]| lrm: 0.681848| num_tokens: 3,416
Step 00986/03096 | Training loss: 0.996230 | Training constraint: -88.097626, duals [0.01]| lrm: 0.681525| num_tokens: 3,264
Step 00987/03096 | Training loss: 1.107304 | Training constraint: -99.465981, duals [0.01]| lrm: 0.681202| num_tokens: 3,916
Step 00988/03096 | Training loss: 1.325767 | Training constraint: -68.199577, duals [0.01]| lrm: 0.680879| num_tokens: 2,779
Step 00989/03096 | Training loss: 0.948515 | Training constraint: -65.444519, duals [0.01]| lrm: 0.680556| num_tokens: 5,273
Step 00990/03096 | Training loss: 1.010885 | Training constraint: -97.005058, duals [0.01]| lrm: 0.680233| num_tokens: 4,013
Step 00991/03096 | Training loss: 1.097660 | Training constraint: -75.576202, duals [0.01]| lrm: 0.679910| num_tokens: 617
Step 00992/03096 | Training loss: 0.968438 | Training constraint: -113.809372, duals [0.01]| lrm: 0.679587| num_tokens: 3,260
Step 00993/03096 | Training loss: 1.042155 | Training constraint: -40.908596, duals [0.01]| lrm: 0.679264| num_tokens: 1,213
Step 00994/03096 | Training loss: 1.211228 | Training constraint: -117.755066, duals [0.01]| lrm: 0.678941| num_tokens: 4,123
Step 00995/03096 | Training loss: 1.239611 | Training constraint: -118.629059, duals [0.01]| lrm: 0.678618| num_tokens: 3,850
Step 00996/03096 | Training loss: 0.931757 | Training constraint: -127.640793, duals [0.01]| lrm: 0.678295| num_tokens: 2,596
Step 00997/03096 | Training loss: 1.155834 | Training constraint: -60.282055, duals [0.01]| lrm: 0.677972| num_tokens: 3,633
Step 00998/03096 | Training loss: 0.780736 | Training constraint: -155.641556, duals [0.01]| lrm: 0.677649| num_tokens: 3,807
Step 00999/03096 | Training loss: 0.991005 | Training constraint: -60.942295, duals [0.01]| lrm: 0.677326| num_tokens: 1,828
Step 01000 | Validation loss: 1.155121
2026-01-21 14:14:08,397 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:14:08,398 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:14:08,402 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:14:08,403 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:14:08,519 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:08,519 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:08,869 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:08,879 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:09,062 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:14:09,070 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:14:09,207 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:14:09,217 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 315/1024 (30.76%)
2026-01-21 14:14:09,835 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:14:09,839 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:14:09,840 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:14:09,842 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:14:09,954 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:09,960 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:10,074 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:10,079 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:10,191 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:14:10,197 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:14:10,320 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:14:10,379 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:14:10,435 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:14:10,493 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 354/1024 (34.57%)
Step 01000 | mmlu_acc: 0.307617, arc_easy_acc: 0.345703
Step 01000/03096 | Training loss: 0.853806 | Training constraint: -111.905762, duals [0.01]| lrm: 0.677003| num_tokens: 2,045
Step 01001/03096 | Training loss: 0.960579 | Training constraint: -181.735321, duals [0.01]| lrm: 0.676680| num_tokens: 3,911
Step 01002/03096 | Training loss: 1.087785 | Training constraint: -85.338470, duals [0.01]| lrm: 0.676357| num_tokens: 2,561
Step 01003/03096 | Training loss: 1.084163 | Training constraint: -169.182571, duals [0.01]| lrm: 0.676034| num_tokens: 2,406
Step 01004/03096 | Training loss: 1.051931 | Training constraint: -65.253143, duals [0.01]| lrm: 0.675711| num_tokens: 2,773
Step 01005/03096 | Training loss: 1.188655 | Training constraint: -161.368683, duals [0.01]| lrm: 0.675388| num_tokens: 3,823
Step 01006/03096 | Training loss: 1.134942 | Training constraint: -133.857208, duals [0.01]| lrm: 0.675065| num_tokens: 2,959
Step 01007/03096 | Training loss: 0.971753 | Training constraint: -148.588898, duals [0.01]| lrm: 0.674742| num_tokens: 2,885
Step 01008/03096 | Training loss: 1.007508 | Training constraint: -80.596176, duals [0.01]| lrm: 0.674419| num_tokens: 3,530
Step 01009/03096 | Training loss: 1.191147 | Training constraint: -96.344048, duals [0.01]| lrm: 0.674096| num_tokens: 4,410
Step 01010/03096 | Training loss: 0.844399 | Training constraint: -141.991699, duals [0.01]| lrm: 0.673773| num_tokens: 3,698
Step 01011/03096 | Training loss: 1.090691 | Training constraint: -67.863144, duals [0.01]| lrm: 0.673450| num_tokens: 1,307
Step 01012/03096 | Training loss: 0.937680 | Training constraint: -126.457321, duals [0.01]| lrm: 0.673127| num_tokens: 4,645
Step 01013/03096 | Training loss: 1.020566 | Training constraint: -159.478470, duals [0.01]| lrm: 0.672804| num_tokens: 2,351
Step 01014/03096 | Training loss: 1.247014 | Training constraint: -111.152054, duals [0.01]| lrm: 0.672481| num_tokens: 693
Step 01015/03096 | Training loss: 0.822143 | Training constraint: -61.343414, duals [0.01]| lrm: 0.672158| num_tokens: 3,760
Step 01016/03096 | Training loss: 1.340801 | Training constraint: -163.982285, duals [0.01]| lrm: 0.671835| num_tokens: 2,316
Step 01017/03096 | Training loss: 1.128651 | Training constraint: -141.435028, duals [0.01]| lrm: 0.671512| num_tokens: 2,314
Step 01018/03096 | Training loss: 1.002534 | Training constraint: -239.233597, duals [0.01]| lrm: 0.671189| num_tokens: 4,754
Step 01019/03096 | Training loss: 1.161633 | Training constraint: -185.779114, duals [0.01]| lrm: 0.670866| num_tokens: 2,517
Step 01020/03096 | Training loss: 0.870466 | Training constraint: -142.834503, duals [0.01]| lrm: 0.670543| num_tokens: 4,728
Step 01021/03096 | Training loss: 1.018748 | Training constraint: -189.985367, duals [0.01]| lrm: 0.670220| num_tokens: 3,759
Step 01022/03096 | Training loss: 0.883467 | Training constraint: -245.667068, duals [0.01]| lrm: 0.669897| num_tokens: 5,527
Step 01023/03096 | Training loss: 1.196383 | Training constraint: -123.348953, duals [0.01]| lrm: 0.669574| num_tokens: 4,482
Step 01024/03096 | Training loss: 1.042203 | Training constraint: -129.544586, duals [0.01]| lrm: 0.669251| num_tokens: 3,156
Step 01025/03096 | Training loss: 1.004262 | Training constraint: -181.531540, duals [0.01]| lrm: 0.668928| num_tokens: 3,660
Step 01026/03096 | Training loss: 1.094679 | Training constraint: -163.611984, duals [0.01]| lrm: 0.668605| num_tokens: 1,988
Step 01027/03096 | Training loss: 1.041441 | Training constraint: -83.753487, duals [0.01]| lrm: 0.668282| num_tokens: 6,164
Step 01028/03096 | Training loss: 0.917661 | Training constraint: -179.030762, duals [0.01]| lrm: 0.667959| num_tokens: 4,033
Step 01029/03096 | Training loss: 1.157230 | Training constraint: -152.845001, duals [0.01]| lrm: 0.667636| num_tokens: 3,982
Step 01030/03096 | Training loss: 1.265997 | Training constraint: -253.053329, duals [0.01]| lrm: 0.667313| num_tokens: 3,087
Step 01031/03096 | Training loss: 1.141245 | Training constraint: -148.972427, duals [0.01]| lrm: 0.666990| num_tokens: 3,950
Step 01032/03096 | Training loss: 0.719157 | Training constraint: -126.594276, duals [0.01]| lrm: 0.666667| num_tokens: 5,185
Step 01033/03096 | Training loss: 1.069740 | Training constraint: -151.509903, duals [0.01]| lrm: 0.666344| num_tokens: 3,921
Step 01034/03096 | Training loss: 1.033102 | Training constraint: -152.228271, duals [0.01]| lrm: 0.666021| num_tokens: 2,539
Step 01035/03096 | Training loss: 0.918785 | Training constraint: -169.929855, duals [0.01]| lrm: 0.665698| num_tokens: 3,838
Step 01036/03096 | Training loss: 0.969613 | Training constraint: -217.788895, duals [0.01]| lrm: 0.665375| num_tokens: 1,556
Step 01037/03096 | Training loss: 1.214640 | Training constraint: -292.039978, duals [0.01]| lrm: 0.665052| num_tokens: 2,790
Step 01038/03096 | Training loss: 1.089631 | Training constraint: -150.852524, duals [0.01]| lrm: 0.664729| num_tokens: 2,795
Step 01039/03096 | Training loss: 1.035478 | Training constraint: -130.071259, duals [0.01]| lrm: 0.664406| num_tokens: 2,329
Step 01040/03096 | Training loss: 0.991202 | Training constraint: -112.223801, duals [0.01]| lrm: 0.664083| num_tokens: 2,620
Step 01041/03096 | Training loss: 0.958091 | Training constraint: -312.637634, duals [0.01]| lrm: 0.663760| num_tokens: 4,957
Step 01042/03096 | Training loss: 0.964831 | Training constraint: -140.485947, duals [0.01]| lrm: 0.663437| num_tokens: 3,906
Step 01043/03096 | Training loss: 1.141065 | Training constraint: -212.541580, duals [0.01]| lrm: 0.663114| num_tokens: 2,580
Step 01044/03096 | Training loss: 0.924406 | Training constraint: -200.587143, duals [0.01]| lrm: 0.662791| num_tokens: 4,438
Step 01045/03096 | Training loss: 0.890542 | Training constraint: -143.945023, duals [0.01]| lrm: 0.662468| num_tokens: 2,865
Step 01046/03096 | Training loss: 1.080765 | Training constraint: -225.096725, duals [0.01]| lrm: 0.662145| num_tokens: 2,826
Step 01047/03096 | Training loss: 1.132079 | Training constraint: -221.087494, duals [0.01]| lrm: 0.661822| num_tokens: 2,518
Step 01048/03096 | Training loss: 1.285727 | Training constraint: -308.907959, duals [0.01]| lrm: 0.661499| num_tokens: 4,900
Step 01049/03096 | Training loss: 0.996545 | Training constraint: -126.451820, duals [0.01]| lrm: 0.661176| num_tokens: 4,599
Step 01050/03096 | Training loss: 1.030701 | Training constraint: -343.704193, duals [0.01]| lrm: 0.660853| num_tokens: 3,639
Step 01051/03096 | Training loss: 0.932631 | Training constraint: -207.635483, duals [0.01]| lrm: 0.660530| num_tokens: 1,366
Step 01052/03096 | Training loss: 1.064484 | Training constraint: -166.393433, duals [0.01]| lrm: 0.660207| num_tokens: 727
Step 01053/03096 | Training loss: 0.954992 | Training constraint: -230.938629, duals [0.01]| lrm: 0.659884| num_tokens: 4,519
Step 01054/03096 | Training loss: 0.782924 | Training constraint: -155.435516, duals [0.01]| lrm: 0.659561| num_tokens: 1,701
Step 01055/03096 | Training loss: 0.996401 | Training constraint: -280.772430, duals [0.01]| lrm: 0.659238| num_tokens: 3,456
Step 01056/03096 | Training loss: 1.371287 | Training constraint: -316.791718, duals [0.01]| lrm: 0.658915| num_tokens: 4,693
Step 01057/03096 | Training loss: 0.613338 | Training constraint: -324.201538, duals [0.01]| lrm: 0.658592| num_tokens: 2,923
Step 01058/03096 | Training loss: 1.047553 | Training constraint: -298.031677, duals [0.01]| lrm: 0.658269| num_tokens: 2,833
Step 01059/03096 | Training loss: 0.926108 | Training constraint: -157.078644, duals [0.01]| lrm: 0.657946| num_tokens: 5,814
Step 01060/03096 | Training loss: 0.861596 | Training constraint: -159.012787, duals [0.01]| lrm: 0.657623| num_tokens: 3,102
Step 01061/03096 | Training loss: 1.182694 | Training constraint: -211.395447, duals [0.01]| lrm: 0.657300| num_tokens: 5,361
Step 01062/03096 | Training loss: 0.816445 | Training constraint: -337.954681, duals [0.01]| lrm: 0.656977| num_tokens: 3,925
Step 01063/03096 | Training loss: 0.947528 | Training constraint: -172.505432, duals [0.01]| lrm: 0.656654| num_tokens: 3,255
Step 01064/03096 | Training loss: 1.127104 | Training constraint: -339.645721, duals [0.01]| lrm: 0.656331| num_tokens: 4,127
Step 01065/03096 | Training loss: 0.995664 | Training constraint: -313.755676, duals [0.01]| lrm: 0.656008| num_tokens: 4,517
Step 01066/03096 | Training loss: 1.013287 | Training constraint: -166.944336, duals [0.01]| lrm: 0.655685| num_tokens: 2,556
Step 01067/03096 | Training loss: 0.964479 | Training constraint: -139.273376, duals [0.01]| lrm: 0.655362| num_tokens: 2,391
Step 01068/03096 | Training loss: 0.893052 | Training constraint: -249.696564, duals [0.01]| lrm: 0.655039| num_tokens: 2,241
Step 01069/03096 | Training loss: 0.722124 | Training constraint: -128.284164, duals [0.01]| lrm: 0.654716| num_tokens: 980
Step 01070/03096 | Training loss: 1.077107 | Training constraint: -182.425034, duals [0.01]| lrm: 0.654393| num_tokens: 1,449
Step 01071/03096 | Training loss: 0.949599 | Training constraint: -185.286423, duals [0.01]| lrm: 0.654070| num_tokens: 2,386
Step 01072/03096 | Training loss: 1.032451 | Training constraint: -239.343781, duals [0.01]| lrm: 0.653747| num_tokens: 4,468
Step 01073/03096 | Training loss: 1.063498 | Training constraint: -248.256073, duals [0.01]| lrm: 0.653424| num_tokens: 5,630
Step 01074/03096 | Training loss: 1.234666 | Training constraint: -207.610321, duals [0.01]| lrm: 0.653101| num_tokens: 3,746
Step 01075/03096 | Training loss: 1.077015 | Training constraint: -280.740906, duals [0.01]| lrm: 0.652778| num_tokens: 4,035
Step 01076/03096 | Training loss: 1.167283 | Training constraint: -141.958115, duals [0.01]| lrm: 0.652455| num_tokens: 3,710
Step 01077/03096 | Training loss: 0.903361 | Training constraint: -261.751526, duals [0.01]| lrm: 0.652132| num_tokens: 2,458
Step 01078/03096 | Training loss: 0.744110 | Training constraint: -242.627502, duals [0.01]| lrm: 0.651809| num_tokens: 4,161
Step 01079/03096 | Training loss: 1.134715 | Training constraint: -286.493652, duals [0.01]| lrm: 0.651486| num_tokens: 4,844
Step 01080/03096 | Training loss: 0.901510 | Training constraint: -240.780273, duals [0.01]| lrm: 0.651163| num_tokens: 4,854
Step 01081/03096 | Training loss: 1.228083 | Training constraint: -132.639847, duals [0.01]| lrm: 0.650840| num_tokens: 443
Step 01082/03096 | Training loss: 0.974507 | Training constraint: -302.991302, duals [0.01]| lrm: 0.650517| num_tokens: 3,286
Step 01083/03096 | Training loss: 1.161137 | Training constraint: -234.024323, duals [0.01]| lrm: 0.650194| num_tokens: 2,598
Step 01084/03096 | Training loss: 1.153937 | Training constraint: -95.707802, duals [0.01]| lrm: 0.649871| num_tokens: 2,461
Step 01085/03096 | Training loss: 1.039336 | Training constraint: -196.236847, duals [0.01]| lrm: 0.649548| num_tokens: 3,205
Step 01086/03096 | Training loss: 0.920038 | Training constraint: -163.148331, duals [0.01]| lrm: 0.649225| num_tokens: 2,364
Step 01087/03096 | Training loss: 1.275481 | Training constraint: -254.146225, duals [0.01]| lrm: 0.648902| num_tokens: 3,318
Step 01088/03096 | Training loss: 0.969432 | Training constraint: -357.626709, duals [0.01]| lrm: 0.648579| num_tokens: 2,689
Step 01089/03096 | Training loss: 0.901389 | Training constraint: -238.867264, duals [0.01]| lrm: 0.648256| num_tokens: 3,744
Step 01090/03096 | Training loss: 1.185125 | Training constraint: -322.233582, duals [0.01]| lrm: 0.647933| num_tokens: 3,256
Step 01091/03096 | Training loss: 1.070219 | Training constraint: -212.182434, duals [0.01]| lrm: 0.647610| num_tokens: 4,948
Step 01092/03096 | Training loss: 0.992666 | Training constraint: -330.432831, duals [0.01]| lrm: 0.647287| num_tokens: 3,541
Step 01093/03096 | Training loss: 1.269053 | Training constraint: -217.647919, duals [0.01]| lrm: 0.646964| num_tokens: 3,694
Step 01094/03096 | Training loss: 1.089358 | Training constraint: -256.366425, duals [0.01]| lrm: 0.646641| num_tokens: 3,327
Step 01095/03096 | Training loss: 0.966606 | Training constraint: -194.124283, duals [0.01]| lrm: 0.646318| num_tokens: 3,436
Step 01096/03096 | Training loss: 0.825399 | Training constraint: -338.326782, duals [0.01]| lrm: 0.645995| num_tokens: 3,330
Step 01097/03096 | Training loss: 0.861793 | Training constraint: -219.709335, duals [0.01]| lrm: 0.645672| num_tokens: 1,987
Step 01098/03096 | Training loss: 0.869975 | Training constraint: -93.100060, duals [0.01]| lrm: 0.645349| num_tokens: 3,832
Step 01099/03096 | Training loss: 0.711446 | Training constraint: -437.797943, duals [0.01]| lrm: 0.645026| num_tokens: 2,229
Step 01100 | Validation loss: 1.156641
Step 01100/03096 | Training loss: 1.003168 | Training constraint: -161.002136, duals [0.01]| lrm: 0.644703| num_tokens: 5,503
Step 01101/03096 | Training loss: 1.089654 | Training constraint: -247.234497, duals [0.01]| lrm: 0.644380| num_tokens: 2,806
Step 01102/03096 | Training loss: 1.049745 | Training constraint: -135.044403, duals [0.01]| lrm: 0.644057| num_tokens: 3,078
Step 01103/03096 | Training loss: 1.181853 | Training constraint: -186.837692, duals [0.01]| lrm: 0.643734| num_tokens: 3,553
Step 01104/03096 | Training loss: 0.915560 | Training constraint: -233.935608, duals [0.01]| lrm: 0.643411| num_tokens: 4,403
Step 01105/03096 | Training loss: 0.820238 | Training constraint: -163.256195, duals [0.01]| lrm: 0.643088| num_tokens: 4,347
Step 01106/03096 | Training loss: 0.991171 | Training constraint: -211.790054, duals [0.01]| lrm: 0.642765| num_tokens: 2,736
Step 01107/03096 | Training loss: 1.109400 | Training constraint: -176.800461, duals [0.01]| lrm: 0.642442| num_tokens: 1,329
Step 01108/03096 | Training loss: 0.834049 | Training constraint: -206.715454, duals [0.01]| lrm: 0.642119| num_tokens: 1,103
Step 01109/03096 | Training loss: 0.959308 | Training constraint: -312.376801, duals [0.01]| lrm: 0.641796| num_tokens: 2,675
Step 01110/03096 | Training loss: 0.930260 | Training constraint: -382.504730, duals [0.01]| lrm: 0.641473| num_tokens: 3,848
Step 01111/03096 | Training loss: 1.133607 | Training constraint: -243.428177, duals [0.01]| lrm: 0.641150| num_tokens: 2,578
Step 01112/03096 | Training loss: 1.074264 | Training constraint: -165.004196, duals [0.01]| lrm: 0.640827| num_tokens: 4,678
Step 01113/03096 | Training loss: 0.955999 | Training constraint: -212.960190, duals [0.01]| lrm: 0.640504| num_tokens: 3,680
Step 01114/03096 | Training loss: 1.298031 | Training constraint: -212.084473, duals [0.01]| lrm: 0.640181| num_tokens: 2,612
Step 01115/03096 | Training loss: 0.753573 | Training constraint: -139.003571, duals [0.01]| lrm: 0.639858| num_tokens: 5,685
Step 01116/03096 | Training loss: 0.888887 | Training constraint: -286.844971, duals [0.01]| lrm: 0.639535| num_tokens: 3,061
Step 01117/03096 | Training loss: 0.746093 | Training constraint: -129.291779, duals [0.01]| lrm: 0.639212| num_tokens: 1,141
Step 01118/03096 | Training loss: 1.039725 | Training constraint: -246.341217, duals [0.01]| lrm: 0.638889| num_tokens: 1,874
Step 01119/03096 | Training loss: 1.129243 | Training constraint: -261.371826, duals [0.01]| lrm: 0.638566| num_tokens: 3,848
Step 01120/03096 | Training loss: 0.969919 | Training constraint: -129.852814, duals [0.01]| lrm: 0.638243| num_tokens: 1,110
Step 01121/03096 | Training loss: 1.218503 | Training constraint: -240.626831, duals [0.01]| lrm: 0.637920| num_tokens: 3,894
Step 01122/03096 | Training loss: 0.865883 | Training constraint: -268.757843, duals [0.01]| lrm: 0.637597| num_tokens: 1,770
Step 01123/03096 | Training loss: 0.860542 | Training constraint: -260.527008, duals [0.01]| lrm: 0.637274| num_tokens: 2,169
Step 01124/03096 | Training loss: 0.751044 | Training constraint: -421.273254, duals [0.01]| lrm: 0.636951| num_tokens: 3,578
Step 01125/03096 | Training loss: 0.716761 | Training constraint: -422.643890, duals [0.01]| lrm: 0.636628| num_tokens: 3,068
Step 01126/03096 | Training loss: 0.914450 | Training constraint: -194.333527, duals [0.01]| lrm: 0.636305| num_tokens: 732
Step 01127/03096 | Training loss: 0.883965 | Training constraint: -227.206802, duals [0.01]| lrm: 0.635982| num_tokens: 3,419
Step 01128/03096 | Training loss: 1.380473 | Training constraint: -193.098679, duals [0.01]| lrm: 0.635659| num_tokens: 4,768
Step 01129/03096 | Training loss: 0.888370 | Training constraint: -203.049988, duals [0.01]| lrm: 0.635336| num_tokens: 4,308
Step 01130/03096 | Training loss: 1.111700 | Training constraint: -250.308899, duals [0.01]| lrm: 0.635013| num_tokens: 5,250
Step 01131/03096 | Training loss: 0.954473 | Training constraint: -286.268494, duals [0.01]| lrm: 0.634690| num_tokens: 5,334
Step 01132/03096 | Training loss: 1.069740 | Training constraint: -348.011017, duals [0.01]| lrm: 0.634367| num_tokens: 3,276
Step 01133/03096 | Training loss: 0.964271 | Training constraint: -262.079193, duals [0.01]| lrm: 0.634044| num_tokens: 2,955
Step 01134/03096 | Training loss: 0.969598 | Training constraint: -297.671356, duals [0.01]| lrm: 0.633721| num_tokens: 3,822
Step 01135/03096 | Training loss: 1.011009 | Training constraint: -214.876877, duals [0.01]| lrm: 0.633398| num_tokens: 5,095
Step 01136/03096 | Training loss: 0.866205 | Training constraint: -370.951508, duals [0.01]| lrm: 0.633075| num_tokens: 2,857
Step 01137/03096 | Training loss: 1.103058 | Training constraint: -259.265717, duals [0.01]| lrm: 0.632752| num_tokens: 5,137
Step 01138/03096 | Training loss: 1.018501 | Training constraint: -245.429581, duals [0.01]| lrm: 0.632429| num_tokens: 4,344
Step 01139/03096 | Training loss: 0.858863 | Training constraint: -345.704712, duals [0.01]| lrm: 0.632106| num_tokens: 3,444
Step 01140/03096 | Training loss: 0.975795 | Training constraint: -298.033081, duals [0.01]| lrm: 0.631783| num_tokens: 3,611
Step 01141/03096 | Training loss: 1.134847 | Training constraint: -316.673248, duals [0.01]| lrm: 0.631460| num_tokens: 3,512
Step 01142/03096 | Training loss: 1.118254 | Training constraint: -259.797943, duals [0.01]| lrm: 0.631137| num_tokens: 5,517
Step 01143/03096 | Training loss: 0.986320 | Training constraint: -139.604797, duals [0.01]| lrm: 0.630814| num_tokens: 4,403
Step 01144/03096 | Training loss: 0.865359 | Training constraint: -173.957855, duals [0.01]| lrm: 0.630491| num_tokens: 4,757
Step 01145/03096 | Training loss: 1.088472 | Training constraint: -223.288452, duals [0.01]| lrm: 0.630168| num_tokens: 3,768
Step 01146/03096 | Training loss: 0.942650 | Training constraint: -292.063782, duals [0.01]| lrm: 0.629845| num_tokens: 2,151
Step 01147/03096 | Training loss: 0.756791 | Training constraint: -171.925537, duals [0.01]| lrm: 0.629522| num_tokens: 5,785
Step 01148/03096 | Training loss: 1.035872 | Training constraint: -325.302582, duals [0.01]| lrm: 0.629199| num_tokens: 2,248
Step 01149/03096 | Training loss: 1.436256 | Training constraint: -401.748718, duals [0.01]| lrm: 0.628876| num_tokens: 2,175
Step 01150/03096 | Training loss: 0.985314 | Training constraint: -292.387268, duals [0.01]| lrm: 0.628553| num_tokens: 2,767
Step 01151/03096 | Training loss: 1.292290 | Training constraint: -400.044312, duals [0.01]| lrm: 0.628230| num_tokens: 6,209
Step 01152/03096 | Training loss: 0.968745 | Training constraint: -353.077179, duals [0.01]| lrm: 0.627907| num_tokens: 2,503
Step 01153/03096 | Training loss: 1.059804 | Training constraint: -394.565399, duals [0.01]| lrm: 0.627584| num_tokens: 1,654
Step 01154/03096 | Training loss: 1.273900 | Training constraint: -198.119263, duals [0.01]| lrm: 0.627261| num_tokens: 2,355
Step 01155/03096 | Training loss: 0.998739 | Training constraint: -208.600601, duals [0.01]| lrm: 0.626938| num_tokens: 4,506
Step 01156/03096 | Training loss: 0.926743 | Training constraint: -194.660416, duals [0.01]| lrm: 0.626615| num_tokens: 4,415
Step 01157/03096 | Training loss: 1.175699 | Training constraint: -277.282806, duals [0.01]| lrm: 0.626292| num_tokens: 3,385
Step 01158/03096 | Training loss: 0.758783 | Training constraint: -441.386688, duals [0.01]| lrm: 0.625969| num_tokens: 2,058
Step 01159/03096 | Training loss: 0.744554 | Training constraint: -189.781464, duals [0.01]| lrm: 0.625646| num_tokens: 3,949
Step 01160/03096 | Training loss: 0.934001 | Training constraint: -288.874969, duals [0.01]| lrm: 0.625323| num_tokens: 3,735
Step 01161/03096 | Training loss: 1.049796 | Training constraint: -574.437195, duals [0.01]| lrm: 0.625000| num_tokens: 5,880
Step 01162/03096 | Training loss: 1.131221 | Training constraint: -292.383667, duals [0.01]| lrm: 0.624677| num_tokens: 3,750
Step 01163/03096 | Training loss: 1.517395 | Training constraint: -364.283661, duals [0.01]| lrm: 0.624354| num_tokens: 2,219
Step 01164/03096 | Training loss: 0.865992 | Training constraint: -250.205704, duals [0.01]| lrm: 0.624031| num_tokens: 2,307
Step 01165/03096 | Training loss: 1.120283 | Training constraint: -184.656036, duals [0.01]| lrm: 0.623708| num_tokens: 2,182
Step 01166/03096 | Training loss: 0.804913 | Training constraint: -183.207214, duals [0.01]| lrm: 0.623385| num_tokens: 1,666
Step 01167/03096 | Training loss: 1.007990 | Training constraint: -262.129242, duals [0.01]| lrm: 0.623062| num_tokens: 4,834
Step 01168/03096 | Training loss: 0.973292 | Training constraint: -265.559509, duals [0.01]| lrm: 0.622739| num_tokens: 2,926
Step 01169/03096 | Training loss: 0.877972 | Training constraint: -336.885010, duals [0.01]| lrm: 0.622416| num_tokens: 5,681
Step 01170/03096 | Training loss: 1.095153 | Training constraint: -294.230530, duals [0.01]| lrm: 0.622093| num_tokens: 3,279
Step 01171/03096 | Training loss: 0.879566 | Training constraint: -257.927307, duals [0.01]| lrm: 0.621770| num_tokens: 2,046
Step 01172/03096 | Training loss: 0.923784 | Training constraint: -412.929810, duals [0.01]| lrm: 0.621447| num_tokens: 2,939
Step 01173/03096 | Training loss: 1.037990 | Training constraint: -194.416763, duals [0.01]| lrm: 0.621124| num_tokens: 3,566
Step 01174/03096 | Training loss: 0.728631 | Training constraint: -455.023590, duals [0.01]| lrm: 0.620801| num_tokens: 1,839
Step 01175/03096 | Training loss: 0.878662 | Training constraint: -177.060989, duals [0.01]| lrm: 0.620478| num_tokens: 5,820
Step 01176/03096 | Training loss: 1.039562 | Training constraint: -307.106873, duals [0.01]| lrm: 0.620155| num_tokens: 2,136
Step 01177/03096 | Training loss: 1.043296 | Training constraint: -433.637390, duals [0.01]| lrm: 0.619832| num_tokens: 2,272
Step 01178/03096 | Training loss: 1.100824 | Training constraint: -297.426270, duals [0.01]| lrm: 0.619509| num_tokens: 4,673
Step 01179/03096 | Training loss: 0.949296 | Training constraint: -298.707214, duals [0.01]| lrm: 0.619186| num_tokens: 3,604
Step 01180/03096 | Training loss: 1.005759 | Training constraint: -317.754272, duals [0.01]| lrm: 0.618863| num_tokens: 2,284
Step 01181/03096 | Training loss: 1.232223 | Training constraint: -400.313660, duals [0.01]| lrm: 0.618540| num_tokens: 3,024
Step 01182/03096 | Training loss: 1.012174 | Training constraint: -318.352783, duals [0.01]| lrm: 0.618217| num_tokens: 4,006
Step 01183/03096 | Training loss: 0.775233 | Training constraint: -141.443558, duals [0.01]| lrm: 0.617894| num_tokens: 1,013
Step 01184/03096 | Training loss: 1.021226 | Training constraint: -447.689209, duals [0.01]| lrm: 0.617571| num_tokens: 3,354
Step 01185/03096 | Training loss: 1.050495 | Training constraint: -196.998199, duals [0.01]| lrm: 0.617248| num_tokens: 2,987
Step 01186/03096 | Training loss: 0.968819 | Training constraint: -255.460098, duals [0.01]| lrm: 0.616925| num_tokens: 732
Step 01187/03096 | Training loss: 0.839246 | Training constraint: -185.104919, duals [0.01]| lrm: 0.616602| num_tokens: 3,484
Step 01188/03096 | Training loss: 1.293970 | Training constraint: -321.696381, duals [0.01]| lrm: 0.616279| num_tokens: 2,419
Step 01189/03096 | Training loss: 1.222415 | Training constraint: -282.848816, duals [0.01]| lrm: 0.615956| num_tokens: 2,546
Step 01190/03096 | Training loss: 0.961224 | Training constraint: -314.734589, duals [0.01]| lrm: 0.615633| num_tokens: 3,476
Step 01191/03096 | Training loss: 1.290939 | Training constraint: -424.792023, duals [0.01]| lrm: 0.615310| num_tokens: 2,226
Step 01192/03096 | Training loss: 0.927473 | Training constraint: -190.315292, duals [0.01]| lrm: 0.614987| num_tokens: 3,920
Step 01193/03096 | Training loss: 0.794940 | Training constraint: -223.751968, duals [0.01]| lrm: 0.614664| num_tokens: 3,986
Step 01194/03096 | Training loss: 0.783958 | Training constraint: -220.057556, duals [0.01]| lrm: 0.614341| num_tokens: 1,162
Step 01195/03096 | Training loss: 1.047518 | Training constraint: -391.549438, duals [0.01]| lrm: 0.614018| num_tokens: 4,157
Step 01196/03096 | Training loss: 0.894372 | Training constraint: -440.960815, duals [0.01]| lrm: 0.613695| num_tokens: 2,790
Step 01197/03096 | Training loss: 1.219826 | Training constraint: -276.349945, duals [0.01]| lrm: 0.613372| num_tokens: 2,473
Step 01198/03096 | Training loss: 0.766687 | Training constraint: -289.987183, duals [0.01]| lrm: 0.613049| num_tokens: 5,052
Step 01199/03096 | Training loss: 1.153704 | Training constraint: -71.853104, duals [0.01]| lrm: 0.612726| num_tokens: 3,004
Step 01200 | Validation loss: 1.158169
2026-01-21 14:14:45,887 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:14:45,892 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:14:45,908 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:14:45,914 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:14:46,012 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:46,027 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:46,361 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:46,379 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:46,751 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:14:46,767 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:14:46,937 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:14:46,937 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 311/1024 (30.37%)
2026-01-21 14:14:47,579 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:14:47,584 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:14:47,613 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:14:47,617 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:14:47,699 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:47,728 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:47,815 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:47,848 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:14:47,935 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:14:47,966 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:14:48,058 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:14:48,089 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:14:48,201 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:14:48,236 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 353/1024 (34.47%)
Step 01200 | mmlu_acc: 0.303711, arc_easy_acc: 0.344727
Step 01200/03096 | Training loss: 0.844043 | Training constraint: -299.239563, duals [0.01]| lrm: 0.612403| num_tokens: 1,750
Step 01201/03096 | Training loss: 0.901746 | Training constraint: -271.376068, duals [0.01]| lrm: 0.612080| num_tokens: 2,260
Step 01202/03096 | Training loss: 1.151298 | Training constraint: -334.483521, duals [0.01]| lrm: 0.611757| num_tokens: 2,741
Step 01203/03096 | Training loss: 0.964535 | Training constraint: -286.562927, duals [0.01]| lrm: 0.611434| num_tokens: 3,503
Step 01204/03096 | Training loss: 0.854341 | Training constraint: -211.622589, duals [0.01]| lrm: 0.611111| num_tokens: 4,514
Step 01205/03096 | Training loss: 0.941389 | Training constraint: -521.895142, duals [0.01]| lrm: 0.610788| num_tokens: 5,313
Step 01206/03096 | Training loss: 0.988365 | Training constraint: -159.312927, duals [0.01]| lrm: 0.610465| num_tokens: 2,239
Step 01207/03096 | Training loss: 1.167651 | Training constraint: -155.713501, duals [0.01]| lrm: 0.610142| num_tokens: 3,218
Step 01208/03096 | Training loss: 1.035213 | Training constraint: -230.980301, duals [0.01]| lrm: 0.609819| num_tokens: 4,701
Step 01209/03096 | Training loss: 1.019160 | Training constraint: -298.821442, duals [0.01]| lrm: 0.609496| num_tokens: 3,206
Step 01210/03096 | Training loss: 0.774576 | Training constraint: -308.114502, duals [0.01]| lrm: 0.609173| num_tokens: 1,359
Step 01211/03096 | Training loss: 1.009659 | Training constraint: -264.677094, duals [0.01]| lrm: 0.608850| num_tokens: 3,355
Step 01212/03096 | Training loss: 0.739755 | Training constraint: -199.417923, duals [0.01]| lrm: 0.608527| num_tokens: 2,572
Step 01213/03096 | Training loss: 1.068371 | Training constraint: -285.445679, duals [0.01]| lrm: 0.608204| num_tokens: 1,720
Step 01214/03096 | Training loss: 0.981241 | Training constraint: -398.585266, duals [0.01]| lrm: 0.607881| num_tokens: 2,660
Step 01215/03096 | Training loss: 0.910605 | Training constraint: -162.205200, duals [0.01]| lrm: 0.607558| num_tokens: 3,072
Step 01216/03096 | Training loss: 1.026541 | Training constraint: -184.308945, duals [0.01]| lrm: 0.607235| num_tokens: 2,627
Step 01217/03096 | Training loss: 1.127491 | Training constraint: -383.795288, duals [0.01]| lrm: 0.606912| num_tokens: 5,185
Step 01218/03096 | Training loss: 0.745293 | Training constraint: -340.770874, duals [0.01]| lrm: 0.606589| num_tokens: 2,369
Step 01219/03096 | Training loss: 0.928313 | Training constraint: -388.602356, duals [0.01]| lrm: 0.606266| num_tokens: 809
Step 01220/03096 | Training loss: 0.944931 | Training constraint: -309.971741, duals [0.01]| lrm: 0.605943| num_tokens: 3,752
Step 01221/03096 | Training loss: 0.680060 | Training constraint: -308.147522, duals [0.01]| lrm: 0.605620| num_tokens: 4,108
Step 01222/03096 | Training loss: 1.276647 | Training constraint: -438.924683, duals [0.01]| lrm: 0.605297| num_tokens: 3,328
Step 01223/03096 | Training loss: 1.091232 | Training constraint: -338.024597, duals [0.01]| lrm: 0.604974| num_tokens: 3,853
Step 01224/03096 | Training loss: 1.112450 | Training constraint: -334.269745, duals [0.01]| lrm: 0.604651| num_tokens: 3,936
Step 01225/03096 | Training loss: 1.202778 | Training constraint: -207.950821, duals [0.01]| lrm: 0.604328| num_tokens: 4,662
Step 01226/03096 | Training loss: 0.982007 | Training constraint: -357.311523, duals [0.01]| lrm: 0.604005| num_tokens: 3,154
Step 01227/03096 | Training loss: 0.793637 | Training constraint: -308.101196, duals [0.01]| lrm: 0.603682| num_tokens: 4,293
Step 01228/03096 | Training loss: 1.108866 | Training constraint: -511.134735, duals [0.01]| lrm: 0.603359| num_tokens: 4,502
Step 01229/03096 | Training loss: 0.987513 | Training constraint: -318.002502, duals [0.01]| lrm: 0.603036| num_tokens: 3,964
Step 01230/03096 | Training loss: 1.271792 | Training constraint: -331.031494, duals [0.01]| lrm: 0.602713| num_tokens: 4,276
Step 01231/03096 | Training loss: 0.951412 | Training constraint: -340.842987, duals [0.01]| lrm: 0.602390| num_tokens: 1,152
Step 01232/03096 | Training loss: 1.122325 | Training constraint: -300.299072, duals [0.01]| lrm: 0.602067| num_tokens: 3,752
Step 01233/03096 | Training loss: 0.995735 | Training constraint: -296.350403, duals [0.01]| lrm: 0.601744| num_tokens: 1,297
Step 01234/03096 | Training loss: 0.732740 | Training constraint: -229.619156, duals [0.01]| lrm: 0.601421| num_tokens: 4,643
Step 01235/03096 | Training loss: 0.955170 | Training constraint: -276.875916, duals [0.01]| lrm: 0.601098| num_tokens: 6,185
Step 01236/03096 | Training loss: 1.232026 | Training constraint: -492.943848, duals [0.01]| lrm: 0.600775| num_tokens: 3,137
Step 01237/03096 | Training loss: 1.083076 | Training constraint: -342.166016, duals [0.01]| lrm: 0.600452| num_tokens: 6,330
Step 01238/03096 | Training loss: 1.033333 | Training constraint: -512.588196, duals [0.01]| lrm: 0.600129| num_tokens: 4,333
Step 01239/03096 | Training loss: 1.025809 | Training constraint: -199.924438, duals [0.01]| lrm: 0.599806| num_tokens: 5,165
Step 01240/03096 | Training loss: 1.137172 | Training constraint: -141.406586, duals [0.01]| lrm: 0.599483| num_tokens: 2,567
Step 01241/03096 | Training loss: 1.127916 | Training constraint: -263.978821, duals [0.01]| lrm: 0.599160| num_tokens: 3,948
Step 01242/03096 | Training loss: 0.938779 | Training constraint: -167.795746, duals [0.01]| lrm: 0.598837| num_tokens: 4,455
Step 01243/03096 | Training loss: 1.088710 | Training constraint: -329.494904, duals [0.01]| lrm: 0.598514| num_tokens: 1,482
Step 01244/03096 | Training loss: 1.050599 | Training constraint: -323.870178, duals [0.01]| lrm: 0.598191| num_tokens: 2,974
Step 01245/03096 | Training loss: 0.966225 | Training constraint: -264.231293, duals [0.01]| lrm: 0.597868| num_tokens: 3,930
Step 01246/03096 | Training loss: 1.010340 | Training constraint: -348.854279, duals [0.01]| lrm: 0.597545| num_tokens: 5,169
Step 01247/03096 | Training loss: 0.904042 | Training constraint: -132.145432, duals [0.01]| lrm: 0.597222| num_tokens: 2,159
Step 01248/03096 | Training loss: 0.875959 | Training constraint: -293.589447, duals [0.01]| lrm: 0.596899| num_tokens: 2,577
Step 01249/03096 | Training loss: 0.782937 | Training constraint: -285.447449, duals [0.01]| lrm: 0.596576| num_tokens: 3,608
Step 01250/03096 | Training loss: 1.150180 | Training constraint: -176.883667, duals [0.01]| lrm: 0.596253| num_tokens: 3,576
Step 01251/03096 | Training loss: 0.941599 | Training constraint: -194.489014, duals [0.01]| lrm: 0.595930| num_tokens: 3,041
Step 01252/03096 | Training loss: 1.206177 | Training constraint: -413.342194, duals [0.01]| lrm: 0.595607| num_tokens: 4,683
Step 01253/03096 | Training loss: 0.976866 | Training constraint: -246.474609, duals [0.01]| lrm: 0.595284| num_tokens: 3,768
Step 01254/03096 | Training loss: 1.006441 | Training constraint: -353.528595, duals [0.01]| lrm: 0.594961| num_tokens: 2,928
Step 01255/03096 | Training loss: 1.289256 | Training constraint: -393.698730, duals [0.01]| lrm: 0.594638| num_tokens: 4,746
Step 01256/03096 | Training loss: 0.801217 | Training constraint: -265.195892, duals [0.01]| lrm: 0.594315| num_tokens: 4,128
Step 01257/03096 | Training loss: 1.190646 | Training constraint: -343.052490, duals [0.01]| lrm: 0.593992| num_tokens: 2,271
Step 01258/03096 | Training loss: 0.839694 | Training constraint: -188.371521, duals [0.01]| lrm: 0.593669| num_tokens: 4,687
Step 01259/03096 | Training loss: 1.292873 | Training constraint: -125.086090, duals [0.01]| lrm: 0.593346| num_tokens: 6,009
Step 01260/03096 | Training loss: 1.074328 | Training constraint: -251.691177, duals [0.01]| lrm: 0.593023| num_tokens: 3,410
Step 01261/03096 | Training loss: 0.998891 | Training constraint: -285.771210, duals [0.01]| lrm: 0.592700| num_tokens: 2,841
Step 01262/03096 | Training loss: 1.277819 | Training constraint: -445.726135, duals [0.01]| lrm: 0.592377| num_tokens: 2,153
Step 01263/03096 | Training loss: 1.158425 | Training constraint: -257.227722, duals [0.01]| lrm: 0.592054| num_tokens: 2,956
Step 01264/03096 | Training loss: 1.012889 | Training constraint: -353.230865, duals [0.01]| lrm: 0.591731| num_tokens: 3,488
Step 01265/03096 | Training loss: 0.931816 | Training constraint: -430.754211, duals [0.01]| lrm: 0.591408| num_tokens: 4,149
Step 01266/03096 | Training loss: 0.903729 | Training constraint: -179.853363, duals [0.01]| lrm: 0.591085| num_tokens: 1,050
Step 01267/03096 | Training loss: 0.932990 | Training constraint: -305.413849, duals [0.01]| lrm: 0.590762| num_tokens: 3,408
Step 01268/03096 | Training loss: 1.164854 | Training constraint: -420.637756, duals [0.01]| lrm: 0.590439| num_tokens: 4,135
Step 01269/03096 | Training loss: 1.069706 | Training constraint: -392.239563, duals [0.01]| lrm: 0.590116| num_tokens: 4,610
Step 01270/03096 | Training loss: 1.083609 | Training constraint: -247.170868, duals [0.01]| lrm: 0.589793| num_tokens: 3,883
Step 01271/03096 | Training loss: 0.965662 | Training constraint: -436.168121, duals [0.01]| lrm: 0.589470| num_tokens: 5,616
Step 01272/03096 | Training loss: 1.194908 | Training constraint: -198.838074, duals [0.01]| lrm: 0.589147| num_tokens: 3,607
Step 01273/03096 | Training loss: 0.796475 | Training constraint: -191.404175, duals [0.01]| lrm: 0.588824| num_tokens: 4,109
Step 01274/03096 | Training loss: 0.884907 | Training constraint: -111.854050, duals [0.01]| lrm: 0.588501| num_tokens: 3,051
Step 01275/03096 | Training loss: 1.073171 | Training constraint: -286.293945, duals [0.01]| lrm: 0.588178| num_tokens: 5,012
Step 01276/03096 | Training loss: 0.676384 | Training constraint: -428.027710, duals [0.01]| lrm: 0.587855| num_tokens: 1,721
Step 01277/03096 | Training loss: 1.078650 | Training constraint: -401.158081, duals [0.01]| lrm: 0.587532| num_tokens: 3,843
Step 01278/03096 | Training loss: 0.920121 | Training constraint: -433.585999, duals [0.01]| lrm: 0.587209| num_tokens: 1,946
Step 01279/03096 | Training loss: 1.158939 | Training constraint: -392.116425, duals [0.01]| lrm: 0.586886| num_tokens: 3,674
Step 01280/03096 | Training loss: 1.187071 | Training constraint: -243.905502, duals [0.01]| lrm: 0.586563| num_tokens: 6,016
Step 01281/03096 | Training loss: 0.886060 | Training constraint: -432.370850, duals [0.01]| lrm: 0.586240| num_tokens: 4,138
Step 01282/03096 | Training loss: 1.016180 | Training constraint: -293.007202, duals [0.01]| lrm: 0.585917| num_tokens: 2,883
Step 01283/03096 | Training loss: 0.834708 | Training constraint: -208.595978, duals [0.01]| lrm: 0.585594| num_tokens: 2,991
Step 01284/03096 | Training loss: 1.165705 | Training constraint: -201.934418, duals [0.01]| lrm: 0.585271| num_tokens: 2,631
Step 01285/03096 | Training loss: 0.845360 | Training constraint: -325.276306, duals [0.01]| lrm: 0.584948| num_tokens: 1,407
Step 01286/03096 | Training loss: 1.127438 | Training constraint: -369.831726, duals [0.01]| lrm: 0.584625| num_tokens: 4,601
Step 01287/03096 | Training loss: 1.087231 | Training constraint: -164.608414, duals [0.01]| lrm: 0.584302| num_tokens: 6,505
Step 01288/03096 | Training loss: 1.134651 | Training constraint: -319.913452, duals [0.01]| lrm: 0.583979| num_tokens: 1,148
Step 01289/03096 | Training loss: 1.070693 | Training constraint: -195.308411, duals [0.01]| lrm: 0.583656| num_tokens: 4,802
Step 01290/03096 | Training loss: 1.114471 | Training constraint: -305.069489, duals [0.01]| lrm: 0.583333| num_tokens: 4,179
Step 01291/03096 | Training loss: 1.100568 | Training constraint: -328.061371, duals [0.01]| lrm: 0.583010| num_tokens: 2,948
Step 01292/03096 | Training loss: 0.955847 | Training constraint: -363.872375, duals [0.01]| lrm: 0.582687| num_tokens: 3,513
Step 01293/03096 | Training loss: 0.967953 | Training constraint: -290.952148, duals [0.01]| lrm: 0.582364| num_tokens: 6,376
Step 01294/03096 | Training loss: 0.766851 | Training constraint: -435.941742, duals [0.01]| lrm: 0.582041| num_tokens: 3,065
Step 01295/03096 | Training loss: 1.175878 | Training constraint: -278.874481, duals [0.01]| lrm: 0.581718| num_tokens: 4,381
Step 01296/03096 | Training loss: 1.101194 | Training constraint: -264.700928, duals [0.01]| lrm: 0.581395| num_tokens: 4,717
Step 01297/03096 | Training loss: 1.117957 | Training constraint: -382.906158, duals [0.01]| lrm: 0.581072| num_tokens: 5,113
Step 01298/03096 | Training loss: 0.764088 | Training constraint: -461.012115, duals [0.01]| lrm: 0.580749| num_tokens: 4,257
Step 01299/03096 | Training loss: 1.016032 | Training constraint: -548.335876, duals [0.01]| lrm: 0.580426| num_tokens: 4,247
Step 01300 | Validation loss: 1.159739
Step 01300/03096 | Training loss: 0.810641 | Training constraint: -178.281754, duals [0.01]| lrm: 0.580103| num_tokens: 3,355
Step 01301/03096 | Training loss: 0.881539 | Training constraint: -394.821259, duals [0.01]| lrm: 0.579780| num_tokens: 624
Step 01302/03096 | Training loss: 1.077827 | Training constraint: -446.844543, duals [0.01]| lrm: 0.579457| num_tokens: 3,906
Step 01303/03096 | Training loss: 0.919070 | Training constraint: -233.514954, duals [0.01]| lrm: 0.579134| num_tokens: 5,551
Step 01304/03096 | Training loss: 1.185019 | Training constraint: -239.255753, duals [0.01]| lrm: 0.578811| num_tokens: 5,117
Step 01305/03096 | Training loss: 0.829232 | Training constraint: -240.601212, duals [0.01]| lrm: 0.578488| num_tokens: 1,228
Step 01306/03096 | Training loss: 1.111178 | Training constraint: -262.892365, duals [0.01]| lrm: 0.578165| num_tokens: 5,369
Step 01307/03096 | Training loss: 0.669112 | Training constraint: -101.643379, duals [0.01]| lrm: 0.577842| num_tokens: 1,936
Step 01308/03096 | Training loss: 0.995888 | Training constraint: -190.891052, duals [0.01]| lrm: 0.577519| num_tokens: 1,389
Step 01309/03096 | Training loss: 1.072758 | Training constraint: -266.417175, duals [0.01]| lrm: 0.577196| num_tokens: 2,469
Step 01310/03096 | Training loss: 0.881503 | Training constraint: -321.899109, duals [0.01]| lrm: 0.576873| num_tokens: 2,074
Step 01311/03096 | Training loss: 1.368613 | Training constraint: -352.403137, duals [0.01]| lrm: 0.576550| num_tokens: 3,810
Step 01312/03096 | Training loss: 0.927305 | Training constraint: -393.418549, duals [0.01]| lrm: 0.576227| num_tokens: 7,031
Step 01313/03096 | Training loss: 1.227310 | Training constraint: -374.266174, duals [0.01]| lrm: 0.575904| num_tokens: 3,959
Step 01314/03096 | Training loss: 0.911799 | Training constraint: -279.872162, duals [0.01]| lrm: 0.575581| num_tokens: 1,520
Step 01315/03096 | Training loss: 0.965317 | Training constraint: -414.781860, duals [0.01]| lrm: 0.575258| num_tokens: 5,590
Step 01316/03096 | Training loss: 1.003833 | Training constraint: -297.328644, duals [0.01]| lrm: 0.574935| num_tokens: 5,094
Step 01317/03096 | Training loss: 0.798845 | Training constraint: -461.222107, duals [0.01]| lrm: 0.574612| num_tokens: 1,915
Step 01318/03096 | Training loss: 0.887674 | Training constraint: -364.399567, duals [0.01]| lrm: 0.574289| num_tokens: 3,830
Step 01319/03096 | Training loss: 0.850616 | Training constraint: -433.084595, duals [0.01]| lrm: 0.573966| num_tokens: 3,972
Step 01320/03096 | Training loss: 1.065065 | Training constraint: -223.175308, duals [0.01]| lrm: 0.573643| num_tokens: 2,110
Step 01321/03096 | Training loss: 0.934655 | Training constraint: -227.071396, duals [0.01]| lrm: 0.573320| num_tokens: 1,578
Step 01322/03096 | Training loss: 0.984356 | Training constraint: -358.070740, duals [0.01]| lrm: 0.572997| num_tokens: 5,133
Step 01323/03096 | Training loss: 1.056514 | Training constraint: -233.457367, duals [0.01]| lrm: 0.572674| num_tokens: 2,023
Step 01324/03096 | Training loss: 1.208989 | Training constraint: -381.858337, duals [0.01]| lrm: 0.572351| num_tokens: 2,675
Step 01325/03096 | Training loss: 0.959485 | Training constraint: -372.773499, duals [0.01]| lrm: 0.572028| num_tokens: 4,332
Step 01326/03096 | Training loss: 1.003207 | Training constraint: -247.971710, duals [0.01]| lrm: 0.571705| num_tokens: 2,716
Step 01327/03096 | Training loss: 0.715652 | Training constraint: -407.905853, duals [0.01]| lrm: 0.571382| num_tokens: 1,716
Step 01328/03096 | Training loss: 0.889255 | Training constraint: -452.999573, duals [0.01]| lrm: 0.571059| num_tokens: 3,140
Step 01329/03096 | Training loss: 1.115751 | Training constraint: -427.290985, duals [0.01]| lrm: 0.570736| num_tokens: 2,299
Step 01330/03096 | Training loss: 1.223079 | Training constraint: -466.452332, duals [0.01]| lrm: 0.570413| num_tokens: 2,667
Step 01331/03096 | Training loss: 1.044866 | Training constraint: -303.029419, duals [0.01]| lrm: 0.570090| num_tokens: 3,947
Step 01332/03096 | Training loss: 1.164576 | Training constraint: -346.966370, duals [0.01]| lrm: 0.569767| num_tokens: 3,572
Step 01333/03096 | Training loss: 0.966240 | Training constraint: -194.165802, duals [0.01]| lrm: 0.569444| num_tokens: 4,227
Step 01334/03096 | Training loss: 0.853263 | Training constraint: -303.286469, duals [0.01]| lrm: 0.569121| num_tokens: 3,722
Step 01335/03096 | Training loss: 1.146267 | Training constraint: -288.126648, duals [0.01]| lrm: 0.568798| num_tokens: 5,143
Step 01336/03096 | Training loss: 0.805394 | Training constraint: -93.059113, duals [0.01]| lrm: 0.568475| num_tokens: 3,458
Step 01337/03096 | Training loss: 0.925948 | Training constraint: -315.721069, duals [0.01]| lrm: 0.568152| num_tokens: 2,875
Step 01338/03096 | Training loss: 0.999913 | Training constraint: -369.960907, duals [0.01]| lrm: 0.567829| num_tokens: 2,718
Step 01339/03096 | Training loss: 1.281497 | Training constraint: -409.863312, duals [0.01]| lrm: 0.567506| num_tokens: 2,352
Step 01340/03096 | Training loss: 0.940439 | Training constraint: -263.851746, duals [0.01]| lrm: 0.567183| num_tokens: 3,044
Step 01341/03096 | Training loss: 0.801567 | Training constraint: -286.334229, duals [0.01]| lrm: 0.566860| num_tokens: 2,441
Step 01342/03096 | Training loss: 0.807547 | Training constraint: -367.024719, duals [0.01]| lrm: 0.566537| num_tokens: 2,678
Step 01343/03096 | Training loss: 1.097458 | Training constraint: -358.132629, duals [0.01]| lrm: 0.566214| num_tokens: 4,955
Step 01344/03096 | Training loss: 1.090479 | Training constraint: -254.748032, duals [0.01]| lrm: 0.565891| num_tokens: 1,831
Step 01345/03096 | Training loss: 1.228879 | Training constraint: -260.741028, duals [0.01]| lrm: 0.565568| num_tokens: 1,597
Step 01346/03096 | Training loss: 1.083674 | Training constraint: -188.045959, duals [0.01]| lrm: 0.565245| num_tokens: 2,358
Step 01347/03096 | Training loss: 0.911779 | Training constraint: -351.950653, duals [0.01]| lrm: 0.564922| num_tokens: 2,813
Step 01348/03096 | Training loss: 1.173205 | Training constraint: -246.364120, duals [0.01]| lrm: 0.564599| num_tokens: 1,749
Step 01349/03096 | Training loss: 1.252967 | Training constraint: -250.555786, duals [0.01]| lrm: 0.564276| num_tokens: 3,678
Step 01350/03096 | Training loss: 1.091054 | Training constraint: -472.395721, duals [0.01]| lrm: 0.563953| num_tokens: 3,877
Step 01351/03096 | Training loss: 0.838675 | Training constraint: -534.293762, duals [0.01]| lrm: 0.563630| num_tokens: 3,606
Step 01352/03096 | Training loss: 0.908196 | Training constraint: -333.202881, duals [0.01]| lrm: 0.563307| num_tokens: 3,163
Step 01353/03096 | Training loss: 1.092892 | Training constraint: -359.555786, duals [0.01]| lrm: 0.562984| num_tokens: 3,102
Step 01354/03096 | Training loss: 1.319134 | Training constraint: -551.437012, duals [0.01]| lrm: 0.562661| num_tokens: 1,970
Step 01355/03096 | Training loss: 1.015537 | Training constraint: -192.474457, duals [0.01]| lrm: 0.562339| num_tokens: 2,689
Step 01356/03096 | Training loss: 1.010858 | Training constraint: -357.312073, duals [0.01]| lrm: 0.562016| num_tokens: 2,597
Step 01357/03096 | Training loss: 0.904280 | Training constraint: -376.331604, duals [0.01]| lrm: 0.561693| num_tokens: 2,566
Step 01358/03096 | Training loss: 0.700618 | Training constraint: -296.940918, duals [0.01]| lrm: 0.561370| num_tokens: 1,044
Step 01359/03096 | Training loss: 0.602491 | Training constraint: -218.282074, duals [0.01]| lrm: 0.561047| num_tokens: 3,267
Step 01360/03096 | Training loss: 1.010419 | Training constraint: -293.771362, duals [0.01]| lrm: 0.560724| num_tokens: 2,710
Step 01361/03096 | Training loss: 1.064679 | Training constraint: -311.360474, duals [0.01]| lrm: 0.560401| num_tokens: 3,131
Step 01362/03096 | Training loss: 0.739232 | Training constraint: -252.838440, duals [0.01]| lrm: 0.560078| num_tokens: 2,899
Step 01363/03096 | Training loss: 1.320323 | Training constraint: -297.369080, duals [0.01]| lrm: 0.559755| num_tokens: 4,339
Step 01364/03096 | Training loss: 1.247206 | Training constraint: -270.354980, duals [0.01]| lrm: 0.559432| num_tokens: 3,027
Step 01365/03096 | Training loss: 1.086435 | Training constraint: -258.598358, duals [0.01]| lrm: 0.559109| num_tokens: 4,652
Step 01366/03096 | Training loss: 0.861575 | Training constraint: -442.434143, duals [0.01]| lrm: 0.558786| num_tokens: 3,545
Step 01367/03096 | Training loss: 0.655102 | Training constraint: -276.304626, duals [0.01]| lrm: 0.558463| num_tokens: 2,680
Step 01368/03096 | Training loss: 0.920800 | Training constraint: -180.020325, duals [0.01]| lrm: 0.558140| num_tokens: 4,450
Step 01369/03096 | Training loss: 0.980582 | Training constraint: -444.609497, duals [0.01]| lrm: 0.557817| num_tokens: 2,290
Step 01370/03096 | Training loss: 1.045438 | Training constraint: -433.927155, duals [0.01]| lrm: 0.557494| num_tokens: 3,418
Step 01371/03096 | Training loss: 1.082294 | Training constraint: -332.262543, duals [0.01]| lrm: 0.557171| num_tokens: 3,092
Step 01372/03096 | Training loss: 0.825131 | Training constraint: -79.826286, duals [0.01]| lrm: 0.556848| num_tokens: 5,013
Step 01373/03096 | Training loss: 0.961427 | Training constraint: -320.317719, duals [0.01]| lrm: 0.556525| num_tokens: 2,938
Step 01374/03096 | Training loss: 1.020594 | Training constraint: -276.639404, duals [0.01]| lrm: 0.556202| num_tokens: 3,383
Step 01375/03096 | Training loss: 1.113507 | Training constraint: -288.830841, duals [0.01]| lrm: 0.555879| num_tokens: 6,055
Step 01376/03096 | Training loss: 1.109449 | Training constraint: -228.066452, duals [0.01]| lrm: 0.555556| num_tokens: 4,897
Step 01377/03096 | Training loss: 0.939478 | Training constraint: -271.128754, duals [0.01]| lrm: 0.555233| num_tokens: 4,044
Step 01378/03096 | Training loss: 0.995979 | Training constraint: -548.281616, duals [0.01]| lrm: 0.554910| num_tokens: 2,563
Step 01379/03096 | Training loss: 1.126868 | Training constraint: -342.367920, duals [0.01]| lrm: 0.554587| num_tokens: 2,666
Step 01380/03096 | Training loss: 1.403892 | Training constraint: -291.702209, duals [0.01]| lrm: 0.554264| num_tokens: 3,173
Step 01381/03096 | Training loss: 1.129363 | Training constraint: -255.134659, duals [0.01]| lrm: 0.553941| num_tokens: 3,292
Step 01382/03096 | Training loss: 1.100569 | Training constraint: -305.666382, duals [0.01]| lrm: 0.553618| num_tokens: 2,435
Step 01383/03096 | Training loss: 0.930784 | Training constraint: -261.917175, duals [0.01]| lrm: 0.553295| num_tokens: 4,566
Step 01384/03096 | Training loss: 1.127342 | Training constraint: -276.505371, duals [0.01]| lrm: 0.552972| num_tokens: 4,272
Step 01385/03096 | Training loss: 0.895193 | Training constraint: -243.659760, duals [0.01]| lrm: 0.552649| num_tokens: 2,660
Step 01386/03096 | Training loss: 1.083787 | Training constraint: -295.916229, duals [0.01]| lrm: 0.552326| num_tokens: 4,438
Step 01387/03096 | Training loss: 0.904213 | Training constraint: -219.162399, duals [0.01]| lrm: 0.552003| num_tokens: 1,391
Step 01388/03096 | Training loss: 1.010402 | Training constraint: -308.657257, duals [0.01]| lrm: 0.551680| num_tokens: 2,506
Step 01389/03096 | Training loss: 0.973807 | Training constraint: -334.042023, duals [0.01]| lrm: 0.551357| num_tokens: 1,881
Step 01390/03096 | Training loss: 0.902632 | Training constraint: -409.218567, duals [0.01]| lrm: 0.551034| num_tokens: 4,222
Step 01391/03096 | Training loss: 0.999782 | Training constraint: -456.907471, duals [0.01]| lrm: 0.550711| num_tokens: 4,785
Step 01392/03096 | Training loss: 1.031985 | Training constraint: -125.800873, duals [0.01]| lrm: 0.550388| num_tokens: 3,491
Step 01393/03096 | Training loss: 0.805697 | Training constraint: -470.674744, duals [0.01]| lrm: 0.550065| num_tokens: 4,021
Step 01394/03096 | Training loss: 1.017614 | Training constraint: -171.551758, duals [0.01]| lrm: 0.549742| num_tokens: 3,066
Step 01395/03096 | Training loss: 0.979781 | Training constraint: -234.588486, duals [0.01]| lrm: 0.549419| num_tokens: 1,528
Step 01396/03096 | Training loss: 0.777441 | Training constraint: -275.622467, duals [0.01]| lrm: 0.549096| num_tokens: 2,300
Step 01397/03096 | Training loss: 0.757032 | Training constraint: -289.629883, duals [0.01]| lrm: 0.548773| num_tokens: 3,986
Step 01398/03096 | Training loss: 1.146516 | Training constraint: -365.012634, duals [0.01]| lrm: 0.548450| num_tokens: 3,019
Step 01399/03096 | Training loss: 0.989537 | Training constraint: -212.732452, duals [0.01]| lrm: 0.548127| num_tokens: 4,432
Step 01400 | Validation loss: 1.161249
2026-01-21 14:15:23,765 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:15:23,766 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:15:23,769 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:15:23,770 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:15:23,883 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:15:23,884 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:15:24,237 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:15:24,427 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:15:24,574 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:15:27,197 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:15:27,340 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 308/1024 (30.08%)
2026-01-21 14:15:27,931 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:15:27,935 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:15:27,937 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:15:27,939 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:15:28,048 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:15:28,050 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:15:28,166 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:15:28,287 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:15:28,399 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:15:28,414 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:15:28,515 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:15:28,533 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:15:28,639 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:15:28,755 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 356/1024 (34.77%)
Step 01400 | mmlu_acc: 0.300781, arc_easy_acc: 0.347656
Step 01400/03096 | Training loss: 1.181064 | Training constraint: -519.741272, duals [0.01]| lrm: 0.547804| num_tokens: 5,746
Step 01401/03096 | Training loss: 0.969364 | Training constraint: -249.875641, duals [0.01]| lrm: 0.547481| num_tokens: 3,326
Step 01402/03096 | Training loss: 0.834018 | Training constraint: -372.765778, duals [0.01]| lrm: 0.547158| num_tokens: 2,241
Step 01403/03096 | Training loss: 0.921072 | Training constraint: -535.220276, duals [0.01]| lrm: 0.546835| num_tokens: 2,301
Step 01404/03096 | Training loss: 1.007097 | Training constraint: -343.132294, duals [0.01]| lrm: 0.546512| num_tokens: 2,825
Step 01405/03096 | Training loss: 0.961669 | Training constraint: -187.232208, duals [0.01]| lrm: 0.546189| num_tokens: 2,137
Step 01406/03096 | Training loss: 1.278826 | Training constraint: -107.173843, duals [0.01]| lrm: 0.545866| num_tokens: 4,459
Step 01407/03096 | Training loss: 1.094254 | Training constraint: -400.703888, duals [0.01]| lrm: 0.545543| num_tokens: 3,586
Step 01408/03096 | Training loss: 1.024758 | Training constraint: -325.800354, duals [0.01]| lrm: 0.545220| num_tokens: 2,865
Step 01409/03096 | Training loss: 0.892076 | Training constraint: -475.012268, duals [0.01]| lrm: 0.544897| num_tokens: 2,903
Step 01410/03096 | Training loss: 0.988420 | Training constraint: -252.757004, duals [0.01]| lrm: 0.544574| num_tokens: 1,453
Step 01411/03096 | Training loss: 1.017686 | Training constraint: -312.372284, duals [0.01]| lrm: 0.544251| num_tokens: 4,993
Step 01412/03096 | Training loss: 0.889694 | Training constraint: -231.888901, duals [0.01]| lrm: 0.543928| num_tokens: 2,117
Step 01413/03096 | Training loss: 1.155388 | Training constraint: -345.733948, duals [0.01]| lrm: 0.543605| num_tokens: 1,923
Step 01414/03096 | Training loss: 0.939259 | Training constraint: -336.727386, duals [0.01]| lrm: 0.543282| num_tokens: 4,394
Step 01415/03096 | Training loss: 0.996037 | Training constraint: -407.520599, duals [0.01]| lrm: 0.542959| num_tokens: 2,336
Step 01416/03096 | Training loss: 0.999074 | Training constraint: -167.937286, duals [0.01]| lrm: 0.542636| num_tokens: 4,144
Step 01417/03096 | Training loss: 0.977644 | Training constraint: -260.000916, duals [0.01]| lrm: 0.542313| num_tokens: 3,010
Step 01418/03096 | Training loss: 0.918088 | Training constraint: -341.288422, duals [0.01]| lrm: 0.541990| num_tokens: 4,441
Step 01419/03096 | Training loss: 1.125391 | Training constraint: -181.275177, duals [0.01]| lrm: 0.541667| num_tokens: 3,161
Step 01420/03096 | Training loss: 1.135942 | Training constraint: -265.114960, duals [0.01]| lrm: 0.541344| num_tokens: 2,750
Step 01421/03096 | Training loss: 1.150898 | Training constraint: -332.290588, duals [0.01]| lrm: 0.541021| num_tokens: 2,707
Step 01422/03096 | Training loss: 1.080486 | Training constraint: -197.803909, duals [0.01]| lrm: 0.540698| num_tokens: 3,262
Step 01423/03096 | Training loss: 1.185526 | Training constraint: -398.626953, duals [0.01]| lrm: 0.540375| num_tokens: 2,658
Step 01424/03096 | Training loss: 0.967001 | Training constraint: -289.426758, duals [0.01]| lrm: 0.540052| num_tokens: 4,034
Step 01425/03096 | Training loss: 0.792364 | Training constraint: -203.768555, duals [0.01]| lrm: 0.539729| num_tokens: 5,060
Step 01426/03096 | Training loss: 0.921138 | Training constraint: -388.051270, duals [0.01]| lrm: 0.539406| num_tokens: 3,768
Step 01427/03096 | Training loss: 1.228739 | Training constraint: -300.969238, duals [0.01]| lrm: 0.539083| num_tokens: 1,879
Step 01428/03096 | Training loss: 1.096682 | Training constraint: -420.838013, duals [0.01]| lrm: 0.538760| num_tokens: 2,356
Step 01429/03096 | Training loss: 0.648851 | Training constraint: -141.994949, duals [0.01]| lrm: 0.538437| num_tokens: 5,688
Step 01430/03096 | Training loss: 0.927215 | Training constraint: -270.383820, duals [0.01]| lrm: 0.538114| num_tokens: 2,718
Step 01431/03096 | Training loss: 0.934977 | Training constraint: -165.876953, duals [0.01]| lrm: 0.537791| num_tokens: 4,520
Step 01432/03096 | Training loss: 1.012967 | Training constraint: -342.993408, duals [0.01]| lrm: 0.537468| num_tokens: 2,979
Step 01433/03096 | Training loss: 1.084525 | Training constraint: -214.439682, duals [0.01]| lrm: 0.537145| num_tokens: 3,272
Step 01434/03096 | Training loss: 0.791382 | Training constraint: -211.399185, duals [0.01]| lrm: 0.536822| num_tokens: 4,009
Step 01435/03096 | Training loss: 1.054743 | Training constraint: -223.203415, duals [0.01]| lrm: 0.536499| num_tokens: 3,473
Step 01436/03096 | Training loss: 0.978645 | Training constraint: -140.486679, duals [0.01]| lrm: 0.536176| num_tokens: 845
Step 01437/03096 | Training loss: 1.076092 | Training constraint: -257.327850, duals [0.01]| lrm: 0.535853| num_tokens: 4,459
Step 01438/03096 | Training loss: 1.102787 | Training constraint: -414.485992, duals [0.01]| lrm: 0.535530| num_tokens: 2,921
Step 01439/03096 | Training loss: 1.118532 | Training constraint: -174.072052, duals [0.01]| lrm: 0.535207| num_tokens: 3,053
Step 01440/03096 | Training loss: 0.985009 | Training constraint: -443.945496, duals [0.01]| lrm: 0.534884| num_tokens: 2,507
Step 01441/03096 | Training loss: 1.254405 | Training constraint: -383.492188, duals [0.01]| lrm: 0.534561| num_tokens: 4,442
Step 01442/03096 | Training loss: 0.950268 | Training constraint: -321.251556, duals [0.01]| lrm: 0.534238| num_tokens: 3,253
Step 01443/03096 | Training loss: 0.926518 | Training constraint: -164.328537, duals [0.01]| lrm: 0.533915| num_tokens: 5,586
Step 01444/03096 | Training loss: 1.091878 | Training constraint: -398.096497, duals [0.01]| lrm: 0.533592| num_tokens: 3,779
Step 01445/03096 | Training loss: 1.002684 | Training constraint: -385.623047, duals [0.01]| lrm: 0.533269| num_tokens: 2,305
Step 01446/03096 | Training loss: 1.035974 | Training constraint: -304.583557, duals [0.01]| lrm: 0.532946| num_tokens: 2,340
Step 01447/03096 | Training loss: 1.231543 | Training constraint: -240.970535, duals [0.01]| lrm: 0.532623| num_tokens: 3,909
Step 01448/03096 | Training loss: 0.659872 | Training constraint: -414.626923, duals [0.01]| lrm: 0.532300| num_tokens: 3,970
Step 01449/03096 | Training loss: 1.177038 | Training constraint: -453.785736, duals [0.01]| lrm: 0.531977| num_tokens: 1,705
Step 01450/03096 | Training loss: 1.000870 | Training constraint: -407.136902, duals [0.01]| lrm: 0.531654| num_tokens: 2,917
Step 01451/03096 | Training loss: 0.753531 | Training constraint: -302.200958, duals [0.01]| lrm: 0.531331| num_tokens: 2,618
Step 01452/03096 | Training loss: 1.065690 | Training constraint: -293.693451, duals [0.01]| lrm: 0.531008| num_tokens: 5,116
Step 01453/03096 | Training loss: 0.987001 | Training constraint: -327.150085, duals [0.01]| lrm: 0.530685| num_tokens: 4,412
Step 01454/03096 | Training loss: 1.106729 | Training constraint: -365.500092, duals [0.01]| lrm: 0.530362| num_tokens: 3,097
Step 01455/03096 | Training loss: 0.893793 | Training constraint: -314.187164, duals [0.01]| lrm: 0.530039| num_tokens: 2,283
Step 01456/03096 | Training loss: 1.249985 | Training constraint: -248.762909, duals [0.01]| lrm: 0.529716| num_tokens: 1,053
Step 01457/03096 | Training loss: 0.929837 | Training constraint: -416.412048, duals [0.01]| lrm: 0.529393| num_tokens: 2,413
Step 01458/03096 | Training loss: 1.254978 | Training constraint: -435.196564, duals [0.01]| lrm: 0.529070| num_tokens: 5,108
Step 01459/03096 | Training loss: 0.939274 | Training constraint: -223.752121, duals [0.01]| lrm: 0.528747| num_tokens: 3,156
Step 01460/03096 | Training loss: 1.211944 | Training constraint: -403.052521, duals [0.01]| lrm: 0.528424| num_tokens: 3,016
Step 01461/03096 | Training loss: 0.835550 | Training constraint: -348.085236, duals [0.01]| lrm: 0.528101| num_tokens: 3,776
Step 01462/03096 | Training loss: 1.169144 | Training constraint: -134.472107, duals [0.01]| lrm: 0.527778| num_tokens: 3,054
Step 01463/03096 | Training loss: 1.099026 | Training constraint: -279.593811, duals [0.01]| lrm: 0.527455| num_tokens: 1,516
Step 01464/03096 | Training loss: 1.073355 | Training constraint: -293.748108, duals [0.01]| lrm: 0.527132| num_tokens: 4,364
Step 01465/03096 | Training loss: 0.980205 | Training constraint: -379.414185, duals [0.01]| lrm: 0.526809| num_tokens: 2,422
Step 01466/03096 | Training loss: 0.997660 | Training constraint: -446.482971, duals [0.01]| lrm: 0.526486| num_tokens: 3,106
Step 01467/03096 | Training loss: 1.289294 | Training constraint: -325.403717, duals [0.01]| lrm: 0.526163| num_tokens: 3,541
Step 01468/03096 | Training loss: 0.908934 | Training constraint: -131.956573, duals [0.01]| lrm: 0.525840| num_tokens: 1,981
Step 01469/03096 | Training loss: 1.163227 | Training constraint: -390.265503, duals [0.01]| lrm: 0.525517| num_tokens: 3,101
Step 01470/03096 | Training loss: 0.787306 | Training constraint: -217.042404, duals [0.01]| lrm: 0.525194| num_tokens: 2,611
Step 01471/03096 | Training loss: 0.618953 | Training constraint: -266.510254, duals [0.01]| lrm: 0.524871| num_tokens: 3,529
Step 01472/03096 | Training loss: 1.006201 | Training constraint: -118.330780, duals [0.01]| lrm: 0.524548| num_tokens: 4,717
Step 01473/03096 | Training loss: 0.809668 | Training constraint: -423.727448, duals [0.01]| lrm: 0.524225| num_tokens: 2,287
Step 01474/03096 | Training loss: 1.016518 | Training constraint: -602.873535, duals [0.01]| lrm: 0.523902| num_tokens: 3,860
Step 01475/03096 | Training loss: 0.646987 | Training constraint: -308.918243, duals [0.01]| lrm: 0.523579| num_tokens: 3,601
Step 01476/03096 | Training loss: 1.229889 | Training constraint: -446.435944, duals [0.01]| lrm: 0.523256| num_tokens: 2,827
Step 01477/03096 | Training loss: 0.870167 | Training constraint: -184.439941, duals [0.01]| lrm: 0.522933| num_tokens: 1,766
Step 01478/03096 | Training loss: 1.083196 | Training constraint: -381.008484, duals [0.01]| lrm: 0.522610| num_tokens: 3,006
Step 01479/03096 | Training loss: 1.263422 | Training constraint: -329.571564, duals [0.01]| lrm: 0.522287| num_tokens: 2,013
Step 01480/03096 | Training loss: 1.165476 | Training constraint: -201.192703, duals [0.01]| lrm: 0.521964| num_tokens: 3,103
Step 01481/03096 | Training loss: 0.989911 | Training constraint: -203.352051, duals [0.01]| lrm: 0.521641| num_tokens: 639
Step 01482/03096 | Training loss: 0.880206 | Training constraint: -360.219604, duals [0.01]| lrm: 0.521318| num_tokens: 1,762
Step 01483/03096 | Training loss: 1.183950 | Training constraint: -386.346466, duals [0.01]| lrm: 0.520995| num_tokens: 4,195
Step 01484/03096 | Training loss: 1.171691 | Training constraint: -215.303757, duals [0.01]| lrm: 0.520672| num_tokens: 2,608
Step 01485/03096 | Training loss: 0.885854 | Training constraint: -332.390320, duals [0.01]| lrm: 0.520349| num_tokens: 4,337
Step 01486/03096 | Training loss: 1.231021 | Training constraint: -381.320343, duals [0.01]| lrm: 0.520026| num_tokens: 3,877
Step 01487/03096 | Training loss: 0.917116 | Training constraint: -233.652649, duals [0.01]| lrm: 0.519703| num_tokens: 5,267
Step 01488/03096 | Training loss: 0.753098 | Training constraint: -402.201172, duals [0.01]| lrm: 0.519380| num_tokens: 2,492
Step 01489/03096 | Training loss: 0.945134 | Training constraint: -274.470825, duals [0.01]| lrm: 0.519057| num_tokens: 1,752
Step 01490/03096 | Training loss: 0.870126 | Training constraint: -387.414673, duals [0.01]| lrm: 0.518734| num_tokens: 4,398
Step 01491/03096 | Training loss: 1.327152 | Training constraint: -270.552917, duals [0.01]| lrm: 0.518411| num_tokens: 1,484
Step 01492/03096 | Training loss: 1.067637 | Training constraint: -308.777405, duals [0.01]| lrm: 0.518088| num_tokens: 4,111
Step 01493/03096 | Training loss: 0.634750 | Training constraint: -155.768051, duals [0.01]| lrm: 0.517765| num_tokens: 3,065
Step 01494/03096 | Training loss: 0.958259 | Training constraint: -240.006317, duals [0.01]| lrm: 0.517442| num_tokens: 6,292
Step 01495/03096 | Training loss: 1.057980 | Training constraint: -254.940308, duals [0.01]| lrm: 0.517119| num_tokens: 5,574
Step 01496/03096 | Training loss: 0.944972 | Training constraint: -285.383423, duals [0.01]| lrm: 0.516796| num_tokens: 3,810
Step 01497/03096 | Training loss: 0.781708 | Training constraint: -325.112732, duals [0.01]| lrm: 0.516473| num_tokens: 1,678
Step 01498/03096 | Training loss: 1.187443 | Training constraint: -384.060730, duals [0.01]| lrm: 0.516150| num_tokens: 3,772
Step 01499/03096 | Training loss: 0.952669 | Training constraint: -231.884293, duals [0.01]| lrm: 0.515827| num_tokens: 3,669
Step 01500 | Validation loss: 1.162714
Step 01500/03096 | Training loss: 1.086248 | Training constraint: -164.250839, duals [0.01]| lrm: 0.515504| num_tokens: 3,256
Step 01501/03096 | Training loss: 1.222303 | Training constraint: -301.582886, duals [0.01]| lrm: 0.515181| num_tokens: 1,675
Step 01502/03096 | Training loss: 1.020435 | Training constraint: -389.554352, duals [0.01]| lrm: 0.514858| num_tokens: 3,660
Step 01503/03096 | Training loss: 0.813974 | Training constraint: -263.300232, duals [0.01]| lrm: 0.514535| num_tokens: 4,156
Step 01504/03096 | Training loss: 0.877047 | Training constraint: -247.665497, duals [0.01]| lrm: 0.514212| num_tokens: 3,742
Step 01505/03096 | Training loss: 0.885717 | Training constraint: -317.721771, duals [0.01]| lrm: 0.513889| num_tokens: 5,263
Step 01506/03096 | Training loss: 1.113537 | Training constraint: -242.092804, duals [0.01]| lrm: 0.513566| num_tokens: 3,430
Step 01507/03096 | Training loss: 0.888257 | Training constraint: -213.560120, duals [0.01]| lrm: 0.513243| num_tokens: 4,058
Step 01508/03096 | Training loss: 1.203999 | Training constraint: -377.658600, duals [0.01]| lrm: 0.512920| num_tokens: 1,977
Step 01509/03096 | Training loss: 1.120015 | Training constraint: -339.690735, duals [0.01]| lrm: 0.512597| num_tokens: 3,739
Step 01510/03096 | Training loss: 1.274961 | Training constraint: -224.951645, duals [0.01]| lrm: 0.512274| num_tokens: 4,763
Step 01511/03096 | Training loss: 0.906549 | Training constraint: -377.644775, duals [0.01]| lrm: 0.511951| num_tokens: 3,146
Step 01512/03096 | Training loss: 1.039110 | Training constraint: -474.033142, duals [0.01]| lrm: 0.511628| num_tokens: 3,274
Step 01513/03096 | Training loss: 0.759405 | Training constraint: -240.470917, duals [0.01]| lrm: 0.511305| num_tokens: 3,154
Step 01514/03096 | Training loss: 0.792760 | Training constraint: -217.620667, duals [0.01]| lrm: 0.510982| num_tokens: 2,317
Step 01515/03096 | Training loss: 0.894343 | Training constraint: -294.760803, duals [0.01]| lrm: 0.510659| num_tokens: 2,254
Step 01516/03096 | Training loss: 1.180628 | Training constraint: -262.623169, duals [0.01]| lrm: 0.510336| num_tokens: 4,357
Step 01517/03096 | Training loss: 0.983978 | Training constraint: -285.207672, duals [0.01]| lrm: 0.510013| num_tokens: 3,554
Step 01518/03096 | Training loss: 1.044952 | Training constraint: -405.759796, duals [0.01]| lrm: 0.509690| num_tokens: 2,026
Step 01519/03096 | Training loss: 0.904624 | Training constraint: -222.896759, duals [0.01]| lrm: 0.509367| num_tokens: 3,644
Step 01520/03096 | Training loss: 1.209061 | Training constraint: -302.010132, duals [0.01]| lrm: 0.509044| num_tokens: 5,592
Step 01521/03096 | Training loss: 0.791535 | Training constraint: -324.323639, duals [0.01]| lrm: 0.508721| num_tokens: 4,397
Step 01522/03096 | Training loss: 1.114131 | Training constraint: -389.902466, duals [0.01]| lrm: 0.508398| num_tokens: 2,884
Step 01523/03096 | Training loss: 0.954925 | Training constraint: -472.025513, duals [0.01]| lrm: 0.508075| num_tokens: 3,256
Step 01524/03096 | Training loss: 1.141669 | Training constraint: -359.747772, duals [0.01]| lrm: 0.507752| num_tokens: 3,492
Step 01525/03096 | Training loss: 0.972573 | Training constraint: -333.084412, duals [0.01]| lrm: 0.507429| num_tokens: 2,760
Step 01526/03096 | Training loss: 0.883338 | Training constraint: -377.431610, duals [0.01]| lrm: 0.507106| num_tokens: 5,528
Step 01527/03096 | Training loss: 0.991861 | Training constraint: -356.422852, duals [0.01]| lrm: 0.506783| num_tokens: 4,627
Step 01528/03096 | Training loss: 1.328307 | Training constraint: -347.289856, duals [0.01]| lrm: 0.506460| num_tokens: 2,550
Step 01529/03096 | Training loss: 1.180738 | Training constraint: -261.736145, duals [0.01]| lrm: 0.506137| num_tokens: 3,213
Step 01530/03096 | Training loss: 0.836815 | Training constraint: -227.746246, duals [0.01]| lrm: 0.505814| num_tokens: 2,096
Step 01531/03096 | Training loss: 0.810739 | Training constraint: -349.996826, duals [0.01]| lrm: 0.505491| num_tokens: 3,441
Step 01532/03096 | Training loss: 1.088367 | Training constraint: -323.469391, duals [0.01]| lrm: 0.505168| num_tokens: 2,948
Step 01533/03096 | Training loss: 0.916524 | Training constraint: -254.984116, duals [0.01]| lrm: 0.504845| num_tokens: 4,514
Step 01534/03096 | Training loss: 1.012155 | Training constraint: -436.373566, duals [0.01]| lrm: 0.504522| num_tokens: 2,608
Step 01535/03096 | Training loss: 0.949211 | Training constraint: -364.225708, duals [0.01]| lrm: 0.504199| num_tokens: 3,609
Step 01536/03096 | Training loss: 0.853173 | Training constraint: -210.506897, duals [0.01]| lrm: 0.503876| num_tokens: 4,414
Step 01537/03096 | Training loss: 1.020877 | Training constraint: -361.705780, duals [0.01]| lrm: 0.503553| num_tokens: 3,007
Step 01538/03096 | Training loss: 0.883618 | Training constraint: -248.605652, duals [0.01]| lrm: 0.503230| num_tokens: 2,547
Step 01539/03096 | Training loss: 1.130745 | Training constraint: -376.021912, duals [0.01]| lrm: 0.502907| num_tokens: 4,538
Step 01540/03096 | Training loss: 0.997405 | Training constraint: -449.511749, duals [0.01]| lrm: 0.502584| num_tokens: 5,548
Step 01541/03096 | Training loss: 1.004008 | Training constraint: -273.944672, duals [0.01]| lrm: 0.502261| num_tokens: 2,365
Step 01542/03096 | Training loss: 1.188867 | Training constraint: -510.142487, duals [0.01]| lrm: 0.501938| num_tokens: 2,281
Step 01543/03096 | Training loss: 0.747906 | Training constraint: -289.286682, duals [0.01]| lrm: 0.501615| num_tokens: 2,931
Step 01544/03096 | Training loss: 0.859631 | Training constraint: -352.200653, duals [0.01]| lrm: 0.501292| num_tokens: 3,434
Step 01545/03096 | Training loss: 0.869908 | Training constraint: -364.403809, duals [0.01]| lrm: 0.500969| num_tokens: 4,348
Step 01546/03096 | Training loss: 1.073034 | Training constraint: -254.969650, duals [0.01]| lrm: 0.500646| num_tokens: 3,088
Step 01547/03096 | Training loss: 0.934211 | Training constraint: -360.412018, duals [0.01]| lrm: 0.500323| num_tokens: 2,777
Step 01548/03096 | Training loss: 0.883773 | Training constraint: -212.576263, duals [0.01]| lrm: 0.500000| num_tokens: 2,847
Step 01549/03096 | Training loss: 0.948557 | Training constraint: -453.166077, duals [0.01]| lrm: 0.499677| num_tokens: 2,847
Step 01550/03096 | Training loss: 0.952496 | Training constraint: -275.707001, duals [0.01]| lrm: 0.499354| num_tokens: 1,890
Step 01551/03096 | Training loss: 0.987094 | Training constraint: -290.669342, duals [0.01]| lrm: 0.499031| num_tokens: 4,941
Step 01552/03096 | Training loss: 0.991101 | Training constraint: -296.964081, duals [0.01]| lrm: 0.498708| num_tokens: 2,547
Step 01553/03096 | Training loss: 0.711592 | Training constraint: -476.407501, duals [0.01]| lrm: 0.498385| num_tokens: 3,471
Step 01554/03096 | Training loss: 0.904457 | Training constraint: -207.737762, duals [0.01]| lrm: 0.498062| num_tokens: 2,063
Step 01555/03096 | Training loss: 1.011207 | Training constraint: -384.590118, duals [0.01]| lrm: 0.497739| num_tokens: 3,569
Step 01556/03096 | Training loss: 1.029467 | Training constraint: -174.691330, duals [0.01]| lrm: 0.497416| num_tokens: 2,584
Step 01557/03096 | Training loss: 0.979062 | Training constraint: -376.958649, duals [0.01]| lrm: 0.497093| num_tokens: 3,101
Step 01558/03096 | Training loss: 0.908322 | Training constraint: -301.308441, duals [0.01]| lrm: 0.496770| num_tokens: 4,298
Step 01559/03096 | Training loss: 0.917444 | Training constraint: -334.866486, duals [0.01]| lrm: 0.496447| num_tokens: 3,711
Step 01560/03096 | Training loss: 1.032854 | Training constraint: -255.552536, duals [0.01]| lrm: 0.496124| num_tokens: 2,060
Step 01561/03096 | Training loss: 1.249611 | Training constraint: -422.909454, duals [0.01]| lrm: 0.495801| num_tokens: 2,847
Step 01562/03096 | Training loss: 0.997159 | Training constraint: -277.563232, duals [0.01]| lrm: 0.495478| num_tokens: 5,497
Step 01563/03096 | Training loss: 1.071006 | Training constraint: -343.739868, duals [0.01]| lrm: 0.495155| num_tokens: 5,301
Step 01564/03096 | Training loss: 0.979740 | Training constraint: -203.534286, duals [0.01]| lrm: 0.494832| num_tokens: 5,492
Step 01565/03096 | Training loss: 1.065817 | Training constraint: -269.863739, duals [0.01]| lrm: 0.494509| num_tokens: 3,180
Step 01566/03096 | Training loss: 1.031437 | Training constraint: -360.857361, duals [0.01]| lrm: 0.494186| num_tokens: 4,480
Step 01567/03096 | Training loss: 1.461993 | Training constraint: -454.914703, duals [0.01]| lrm: 0.493863| num_tokens: 4,577
Step 01568/03096 | Training loss: 0.923250 | Training constraint: -241.046310, duals [0.01]| lrm: 0.493540| num_tokens: 2,993
Step 01569/03096 | Training loss: 0.769946 | Training constraint: -405.311279, duals [0.01]| lrm: 0.493217| num_tokens: 5,674
Step 01570/03096 | Training loss: 0.946577 | Training constraint: -242.820374, duals [0.01]| lrm: 0.492894| num_tokens: 5,425
Step 01571/03096 | Training loss: 1.048832 | Training constraint: -413.001068, duals [0.01]| lrm: 0.492571| num_tokens: 2,094
Step 01572/03096 | Training loss: 1.085399 | Training constraint: -234.552933, duals [0.01]| lrm: 0.492248| num_tokens: 3,384
Step 01573/03096 | Training loss: 0.837171 | Training constraint: -203.295837, duals [0.01]| lrm: 0.491925| num_tokens: 6,060
Step 01574/03096 | Training loss: 0.924013 | Training constraint: -334.658569, duals [0.01]| lrm: 0.491602| num_tokens: 5,245
Step 01575/03096 | Training loss: 0.906807 | Training constraint: -243.080170, duals [0.01]| lrm: 0.491279| num_tokens: 1,623
Step 01576/03096 | Training loss: 0.761437 | Training constraint: -360.904236, duals [0.01]| lrm: 0.490956| num_tokens: 2,522
Step 01577/03096 | Training loss: 1.009726 | Training constraint: -337.993866, duals [0.01]| lrm: 0.490633| num_tokens: 3,424
Step 01578/03096 | Training loss: 1.144752 | Training constraint: -700.121704, duals [0.01]| lrm: 0.490310| num_tokens: 3,329
Step 01579/03096 | Training loss: 1.169356 | Training constraint: -201.436523, duals [0.01]| lrm: 0.489987| num_tokens: 4,627
Step 01580/03096 | Training loss: 0.952385 | Training constraint: -490.408020, duals [0.01]| lrm: 0.489664| num_tokens: 3,398
Step 01581/03096 | Training loss: 1.151108 | Training constraint: -348.388245, duals [0.01]| lrm: 0.489341| num_tokens: 1,498
Step 01582/03096 | Training loss: 0.939890 | Training constraint: -161.783905, duals [0.01]| lrm: 0.489018| num_tokens: 4,867
Step 01583/03096 | Training loss: 1.006318 | Training constraint: -281.797546, duals [0.01]| lrm: 0.488695| num_tokens: 2,053
Step 01584/03096 | Training loss: 1.024656 | Training constraint: -307.107788, duals [0.01]| lrm: 0.488372| num_tokens: 4,045
Step 01585/03096 | Training loss: 0.920194 | Training constraint: -237.834610, duals [0.01]| lrm: 0.488049| num_tokens: 1,662
Step 01586/03096 | Training loss: 1.173736 | Training constraint: -306.580597, duals [0.01]| lrm: 0.487726| num_tokens: 5,011
Step 01587/03096 | Training loss: 1.021709 | Training constraint: -201.480377, duals [0.01]| lrm: 0.487403| num_tokens: 2,621
Step 01588/03096 | Training loss: 1.070236 | Training constraint: -234.419495, duals [0.01]| lrm: 0.487080| num_tokens: 1,140
Step 01589/03096 | Training loss: 1.056059 | Training constraint: -462.942871, duals [0.01]| lrm: 0.486757| num_tokens: 4,902
Step 01590/03096 | Training loss: 0.987187 | Training constraint: -181.168915, duals [0.01]| lrm: 0.486434| num_tokens: 2,162
Step 01591/03096 | Training loss: 1.006716 | Training constraint: -422.462799, duals [0.01]| lrm: 0.486111| num_tokens: 4,002
Step 01592/03096 | Training loss: 1.022032 | Training constraint: -498.181335, duals [0.01]| lrm: 0.485788| num_tokens: 2,743
Step 01593/03096 | Training loss: 0.840394 | Training constraint: -286.306061, duals [0.01]| lrm: 0.485465| num_tokens: 3,976
Step 01594/03096 | Training loss: 1.186109 | Training constraint: -415.059509, duals [0.01]| lrm: 0.485142| num_tokens: 4,309
Step 01595/03096 | Training loss: 1.144233 | Training constraint: -576.333984, duals [0.01]| lrm: 0.484819| num_tokens: 1,397
Step 01596/03096 | Training loss: 0.711393 | Training constraint: -375.199829, duals [0.01]| lrm: 0.484496| num_tokens: 2,706
Step 01597/03096 | Training loss: 1.090370 | Training constraint: -223.483231, duals [0.01]| lrm: 0.484173| num_tokens: 5,388
Step 01598/03096 | Training loss: 1.276654 | Training constraint: -310.069916, duals [0.01]| lrm: 0.483850| num_tokens: 3,282
Step 01599/03096 | Training loss: 1.224856 | Training constraint: -564.379517, duals [0.01]| lrm: 0.483527| num_tokens: 2,758
Step 01600 | Validation loss: 1.164106
2026-01-21 14:16:04,355 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:16:04,359 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:16:04,361 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:16:04,365 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:16:04,474 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:04,478 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:04,837 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:04,858 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:05,030 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:16:05,053 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:16:05,237 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:16:05,278 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 306/1024 (29.88%)
2026-01-21 14:16:05,866 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:16:05,867 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:16:05,870 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:16:05,872 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:16:05,984 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:05,989 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:06,102 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:06,112 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:06,219 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:16:06,228 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:16:06,343 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:16:06,353 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:16:06,457 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:16:06,468 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 354/1024 (34.57%)
Step 01600 | mmlu_acc: 0.298828, arc_easy_acc: 0.345703
Step 01600/03096 | Training loss: 0.893177 | Training constraint: -393.385437, duals [0.01]| lrm: 0.483204| num_tokens: 3,219
Step 01601/03096 | Training loss: 1.050139 | Training constraint: -261.443481, duals [0.01]| lrm: 0.482881| num_tokens: 5,484
Step 01602/03096 | Training loss: 0.816084 | Training constraint: -304.222717, duals [0.01]| lrm: 0.482558| num_tokens: 944
Step 01603/03096 | Training loss: 1.181940 | Training constraint: -393.680084, duals [0.01]| lrm: 0.482235| num_tokens: 4,198
Step 01604/03096 | Training loss: 1.196622 | Training constraint: -141.037003, duals [0.01]| lrm: 0.481912| num_tokens: 4,763
Step 01605/03096 | Training loss: 1.187427 | Training constraint: -320.227295, duals [0.01]| lrm: 0.481589| num_tokens: 3,019
Step 01606/03096 | Training loss: 1.031122 | Training constraint: -254.712463, duals [0.01]| lrm: 0.481266| num_tokens: 2,604
Step 01607/03096 | Training loss: 1.086897 | Training constraint: -301.359253, duals [0.01]| lrm: 0.480943| num_tokens: 2,103
Step 01608/03096 | Training loss: 1.133348 | Training constraint: -236.715134, duals [0.01]| lrm: 0.480620| num_tokens: 3,599
Step 01609/03096 | Training loss: 0.820392 | Training constraint: -255.110764, duals [0.01]| lrm: 0.480297| num_tokens: 2,393
Step 01610/03096 | Training loss: 1.203138 | Training constraint: -241.037811, duals [0.01]| lrm: 0.479974| num_tokens: 3,519
Step 01611/03096 | Training loss: 0.805594 | Training constraint: -180.619232, duals [0.01]| lrm: 0.479651| num_tokens: 3,500
Step 01612/03096 | Training loss: 1.018762 | Training constraint: -346.947083, duals [0.01]| lrm: 0.479328| num_tokens: 3,684
Step 01613/03096 | Training loss: 0.947860 | Training constraint: -586.901428, duals [0.01]| lrm: 0.479005| num_tokens: 3,190
Step 01614/03096 | Training loss: 0.876327 | Training constraint: -186.463135, duals [0.01]| lrm: 0.478682| num_tokens: 2,044
Step 01615/03096 | Training loss: 1.197786 | Training constraint: -268.180786, duals [0.01]| lrm: 0.478359| num_tokens: 2,927
Step 01616/03096 | Training loss: 0.973058 | Training constraint: -372.329651, duals [0.01]| lrm: 0.478036| num_tokens: 3,485
Step 01617/03096 | Training loss: 1.077112 | Training constraint: -225.899094, duals [0.01]| lrm: 0.477713| num_tokens: 4,743
Step 01618/03096 | Training loss: 1.050873 | Training constraint: -139.977478, duals [0.01]| lrm: 0.477390| num_tokens: 4,133
Step 01619/03096 | Training loss: 1.043871 | Training constraint: -245.131058, duals [0.01]| lrm: 0.477067| num_tokens: 3,763
Step 01620/03096 | Training loss: 0.923855 | Training constraint: -323.447876, duals [0.01]| lrm: 0.476744| num_tokens: 1,673
Step 01621/03096 | Training loss: 0.765439 | Training constraint: -682.219604, duals [0.01]| lrm: 0.476421| num_tokens: 5,441
Step 01622/03096 | Training loss: 1.092750 | Training constraint: -355.445068, duals [0.01]| lrm: 0.476098| num_tokens: 3,309
Step 01623/03096 | Training loss: 0.949212 | Training constraint: -373.387360, duals [0.01]| lrm: 0.475775| num_tokens: 4,646
Step 01624/03096 | Training loss: 1.153140 | Training constraint: -316.776550, duals [0.01]| lrm: 0.475452| num_tokens: 4,662
Step 01625/03096 | Training loss: 1.148920 | Training constraint: -194.183197, duals [0.01]| lrm: 0.475129| num_tokens: 4,878
Step 01626/03096 | Training loss: 0.832101 | Training constraint: -364.839630, duals [0.01]| lrm: 0.474806| num_tokens: 2,713
Step 01627/03096 | Training loss: 0.946773 | Training constraint: -282.155670, duals [0.01]| lrm: 0.474483| num_tokens: 4,292
Step 01628/03096 | Training loss: 1.118007 | Training constraint: -369.588989, duals [0.01]| lrm: 0.474160| num_tokens: 2,014
Step 01629/03096 | Training loss: 0.982958 | Training constraint: -262.555817, duals [0.01]| lrm: 0.473837| num_tokens: 3,885
Step 01630/03096 | Training loss: 0.913796 | Training constraint: -503.684265, duals [0.01]| lrm: 0.473514| num_tokens: 2,740
Step 01631/03096 | Training loss: 0.886123 | Training constraint: -343.069580, duals [0.01]| lrm: 0.473191| num_tokens: 1,953
Step 01632/03096 | Training loss: 1.057552 | Training constraint: -227.714081, duals [0.01]| lrm: 0.472868| num_tokens: 2,418
Step 01633/03096 | Training loss: 1.021122 | Training constraint: -388.747345, duals [0.01]| lrm: 0.472545| num_tokens: 3,691
Step 01634/03096 | Training loss: 1.069318 | Training constraint: -377.571533, duals [0.01]| lrm: 0.472222| num_tokens: 3,537
Step 01635/03096 | Training loss: 0.815049 | Training constraint: -459.448547, duals [0.01]| lrm: 0.471899| num_tokens: 1,891
Step 01636/03096 | Training loss: 0.940794 | Training constraint: -530.934204, duals [0.01]| lrm: 0.471576| num_tokens: 1,695
Step 01637/03096 | Training loss: 1.060633 | Training constraint: -281.214355, duals [0.01]| lrm: 0.471253| num_tokens: 3,159
Step 01638/03096 | Training loss: 0.890073 | Training constraint: -160.025208, duals [0.01]| lrm: 0.470930| num_tokens: 4,883
Step 01639/03096 | Training loss: 1.082379 | Training constraint: -486.374878, duals [0.01]| lrm: 0.470607| num_tokens: 2,428
Step 01640/03096 | Training loss: 1.084520 | Training constraint: -471.009796, duals [0.01]| lrm: 0.470284| num_tokens: 1,556
Step 01641/03096 | Training loss: 0.957740 | Training constraint: -389.930725, duals [0.01]| lrm: 0.469961| num_tokens: 4,056
Step 01642/03096 | Training loss: 0.907792 | Training constraint: -326.026306, duals [0.01]| lrm: 0.469638| num_tokens: 1,811
Step 01643/03096 | Training loss: 0.993946 | Training constraint: -342.288635, duals [0.01]| lrm: 0.469315| num_tokens: 3,246
Step 01644/03096 | Training loss: 1.080392 | Training constraint: -304.361298, duals [0.01]| lrm: 0.468992| num_tokens: 3,179
Step 01645/03096 | Training loss: 1.115275 | Training constraint: -183.010147, duals [0.01]| lrm: 0.468669| num_tokens: 4,670
Step 01646/03096 | Training loss: 0.957298 | Training constraint: -338.143585, duals [0.01]| lrm: 0.468346| num_tokens: 3,259
Step 01647/03096 | Training loss: 1.079892 | Training constraint: -219.238190, duals [0.01]| lrm: 0.468023| num_tokens: 2,717
Step 01648/03096 | Training loss: 0.812603 | Training constraint: -141.699951, duals [0.01]| lrm: 0.467700| num_tokens: 4,656
Step 01649/03096 | Training loss: 0.945840 | Training constraint: -320.409912, duals [0.01]| lrm: 0.467377| num_tokens: 5,442
Step 01650/03096 | Training loss: 1.042281 | Training constraint: -220.596481, duals [0.01]| lrm: 0.467054| num_tokens: 2,344
Step 01651/03096 | Training loss: 0.991226 | Training constraint: -424.645813, duals [0.01]| lrm: 0.466731| num_tokens: 3,321
Step 01652/03096 | Training loss: 1.108464 | Training constraint: -314.935669, duals [0.01]| lrm: 0.466408| num_tokens: 3,538
Step 01653/03096 | Training loss: 1.119938 | Training constraint: -408.075134, duals [0.01]| lrm: 0.466085| num_tokens: 2,923
Step 01654/03096 | Training loss: 0.975086 | Training constraint: -333.491028, duals [0.01]| lrm: 0.465762| num_tokens: 5,619
Step 01655/03096 | Training loss: 1.062508 | Training constraint: -301.361938, duals [0.01]| lrm: 0.465439| num_tokens: 5,139
Step 01656/03096 | Training loss: 1.140977 | Training constraint: -361.365845, duals [0.01]| lrm: 0.465116| num_tokens: 4,053
Step 01657/03096 | Training loss: 0.852170 | Training constraint: -411.743286, duals [0.01]| lrm: 0.464793| num_tokens: 3,235
Step 01658/03096 | Training loss: 0.942792 | Training constraint: -374.755402, duals [0.01]| lrm: 0.464470| num_tokens: 2,687
Step 01659/03096 | Training loss: 1.043007 | Training constraint: -265.028168, duals [0.01]| lrm: 0.464147| num_tokens: 1,499
Step 01660/03096 | Training loss: 0.998158 | Training constraint: -337.334106, duals [0.01]| lrm: 0.463824| num_tokens: 2,910
Step 01661/03096 | Training loss: 1.174333 | Training constraint: -341.890320, duals [0.01]| lrm: 0.463501| num_tokens: 4,409
Step 01662/03096 | Training loss: 0.936198 | Training constraint: -287.306213, duals [0.01]| lrm: 0.463178| num_tokens: 4,033
Step 01663/03096 | Training loss: 1.027475 | Training constraint: -408.011261, duals [0.01]| lrm: 0.462855| num_tokens: 5,195
Step 01664/03096 | Training loss: 0.949273 | Training constraint: -399.498749, duals [0.01]| lrm: 0.462532| num_tokens: 6,291
Step 01665/03096 | Training loss: 0.803940 | Training constraint: -228.533127, duals [0.01]| lrm: 0.462209| num_tokens: 5,582
Step 01666/03096 | Training loss: 0.993960 | Training constraint: -251.485306, duals [0.01]| lrm: 0.461886| num_tokens: 3,104
Step 01667/03096 | Training loss: 0.688111 | Training constraint: -379.004486, duals [0.01]| lrm: 0.461563| num_tokens: 7,146
Step 01668/03096 | Training loss: 0.979675 | Training constraint: -264.065765, duals [0.01]| lrm: 0.461240| num_tokens: 2,020
Step 01669/03096 | Training loss: 0.763525 | Training constraint: -107.835518, duals [0.01]| lrm: 0.460917| num_tokens: 2,260
Step 01670/03096 | Training loss: 0.906107 | Training constraint: -217.631470, duals [0.01]| lrm: 0.460594| num_tokens: 2,908
Step 01671/03096 | Training loss: 0.917363 | Training constraint: -276.186218, duals [0.01]| lrm: 0.460271| num_tokens: 3,982
Step 01672/03096 | Training loss: 1.005295 | Training constraint: -119.311218, duals [0.01]| lrm: 0.459948| num_tokens: 3,715
Step 01673/03096 | Training loss: 1.108341 | Training constraint: -260.696838, duals [0.01]| lrm: 0.459625| num_tokens: 3,713
Step 01674/03096 | Training loss: 1.131089 | Training constraint: -196.847366, duals [0.01]| lrm: 0.459302| num_tokens: 1,325
Step 01675/03096 | Training loss: 1.108882 | Training constraint: -348.089020, duals [0.01]| lrm: 0.458979| num_tokens: 3,850
Step 01676/03096 | Training loss: 0.895501 | Training constraint: -372.937195, duals [0.01]| lrm: 0.458656| num_tokens: 6,016
Step 01677/03096 | Training loss: 0.790496 | Training constraint: -587.804382, duals [0.01]| lrm: 0.458333| num_tokens: 1,922
Step 01678/03096 | Training loss: 0.969313 | Training constraint: -307.191589, duals [0.01]| lrm: 0.458010| num_tokens: 3,985
Step 01679/03096 | Training loss: 0.961604 | Training constraint: -418.141846, duals [0.01]| lrm: 0.457687| num_tokens: 2,681
Step 01680/03096 | Training loss: 0.752761 | Training constraint: -398.987732, duals [0.01]| lrm: 0.457364| num_tokens: 2,759
Step 01681/03096 | Training loss: 1.113322 | Training constraint: -280.164215, duals [0.01]| lrm: 0.457041| num_tokens: 3,852
Step 01682/03096 | Training loss: 0.799470 | Training constraint: -249.670685, duals [0.01]| lrm: 0.456718| num_tokens: 5,894
Step 01683/03096 | Training loss: 1.009323 | Training constraint: -371.116241, duals [0.01]| lrm: 0.456395| num_tokens: 3,584
Step 01684/03096 | Training loss: 1.242339 | Training constraint: -520.167297, duals [0.01]| lrm: 0.456072| num_tokens: 4,317
Step 01685/03096 | Training loss: 0.906013 | Training constraint: -300.468262, duals [0.01]| lrm: 0.455749| num_tokens: 3,114
Step 01686/03096 | Training loss: 0.990901 | Training constraint: -215.034943, duals [0.01]| lrm: 0.455426| num_tokens: 2,916
Step 01687/03096 | Training loss: 1.051635 | Training constraint: -302.943817, duals [0.01]| lrm: 0.455103| num_tokens: 4,611
Step 01688/03096 | Training loss: 0.931931 | Training constraint: -212.090637, duals [0.01]| lrm: 0.454780| num_tokens: 1,963
Step 01689/03096 | Training loss: 1.075990 | Training constraint: -336.143494, duals [0.01]| lrm: 0.454457| num_tokens: 4,374
Step 01690/03096 | Training loss: 0.709401 | Training constraint: -263.626923, duals [0.01]| lrm: 0.454134| num_tokens: 2,182
Step 01691/03096 | Training loss: 0.907543 | Training constraint: -219.797897, duals [0.01]| lrm: 0.453811| num_tokens: 4,308
Step 01692/03096 | Training loss: 1.085881 | Training constraint: -348.573303, duals [0.01]| lrm: 0.453488| num_tokens: 2,007
Step 01693/03096 | Training loss: 0.667260 | Training constraint: -527.421509, duals [0.01]| lrm: 0.453165| num_tokens: 3,115
Step 01694/03096 | Training loss: 1.102339 | Training constraint: -256.434052, duals [0.01]| lrm: 0.452842| num_tokens: 5,450
Step 01695/03096 | Training loss: 1.201539 | Training constraint: -273.497406, duals [0.01]| lrm: 0.452519| num_tokens: 2,921
Step 01696/03096 | Training loss: 0.945998 | Training constraint: -314.387665, duals [0.01]| lrm: 0.452196| num_tokens: 3,362
Step 01697/03096 | Training loss: 1.246589 | Training constraint: -268.737732, duals [0.01]| lrm: 0.451873| num_tokens: 2,800
Step 01698/03096 | Training loss: 0.965494 | Training constraint: -440.172211, duals [0.01]| lrm: 0.451550| num_tokens: 2,280
Step 01699/03096 | Training loss: 1.121414 | Training constraint: -432.396851, duals [0.01]| lrm: 0.451227| num_tokens: 3,945
Step 01700 | Validation loss: 1.165382
Step 01700/03096 | Training loss: 1.003527 | Training constraint: -395.477173, duals [0.01]| lrm: 0.450904| num_tokens: 2,378
Step 01701/03096 | Training loss: 1.028971 | Training constraint: -371.696045, duals [0.01]| lrm: 0.450581| num_tokens: 2,675
Step 01702/03096 | Training loss: 1.059002 | Training constraint: -347.578857, duals [0.01]| lrm: 0.450258| num_tokens: 2,999
Step 01703/03096 | Training loss: 1.060355 | Training constraint: -544.345093, duals [0.01]| lrm: 0.449935| num_tokens: 2,181
Step 01704/03096 | Training loss: 1.175183 | Training constraint: -403.970642, duals [0.01]| lrm: 0.449612| num_tokens: 1,648
Step 01705/03096 | Training loss: 0.847317 | Training constraint: -272.041199, duals [0.01]| lrm: 0.449289| num_tokens: 4,535
Step 01706/03096 | Training loss: 1.121581 | Training constraint: -409.985748, duals [0.01]| lrm: 0.448966| num_tokens: 4,237
Step 01707/03096 | Training loss: 1.122561 | Training constraint: -226.150162, duals [0.01]| lrm: 0.448643| num_tokens: 2,917
Step 01708/03096 | Training loss: 1.242564 | Training constraint: -624.122925, duals [0.01]| lrm: 0.448320| num_tokens: 4,292
Step 01709/03096 | Training loss: 0.899030 | Training constraint: -183.405884, duals [0.01]| lrm: 0.447997| num_tokens: 5,663
Step 01710/03096 | Training loss: 1.018467 | Training constraint: -272.941742, duals [0.01]| lrm: 0.447674| num_tokens: 4,360
Step 01711/03096 | Training loss: 1.102247 | Training constraint: -367.726990, duals [0.01]| lrm: 0.447351| num_tokens: 4,203
Step 01712/03096 | Training loss: 1.087471 | Training constraint: -316.206940, duals [0.01]| lrm: 0.447028| num_tokens: 3,193
Step 01713/03096 | Training loss: 1.027023 | Training constraint: -348.392151, duals [0.01]| lrm: 0.446705| num_tokens: 2,822
Step 01714/03096 | Training loss: 1.066279 | Training constraint: -362.561829, duals [0.01]| lrm: 0.446382| num_tokens: 2,197
Step 01715/03096 | Training loss: 0.974195 | Training constraint: -587.784058, duals [0.01]| lrm: 0.446059| num_tokens: 3,353
Step 01716/03096 | Training loss: 1.068492 | Training constraint: -301.259094, duals [0.01]| lrm: 0.445736| num_tokens: 5,737
Step 01717/03096 | Training loss: 1.002471 | Training constraint: -378.854431, duals [0.01]| lrm: 0.445413| num_tokens: 2,967
Step 01718/03096 | Training loss: 1.029117 | Training constraint: -311.337128, duals [0.01]| lrm: 0.445090| num_tokens: 1,821
Step 01719/03096 | Training loss: 1.139011 | Training constraint: -204.233047, duals [0.01]| lrm: 0.444767| num_tokens: 2,874
Step 01720/03096 | Training loss: 1.193407 | Training constraint: -383.645264, duals [0.01]| lrm: 0.444444| num_tokens: 5,293
Step 01721/03096 | Training loss: 1.261621 | Training constraint: -247.684723, duals [0.01]| lrm: 0.444121| num_tokens: 1,419
Step 01722/03096 | Training loss: 1.016850 | Training constraint: -455.355865, duals [0.01]| lrm: 0.443798| num_tokens: 1,586
Step 01723/03096 | Training loss: 1.127199 | Training constraint: -264.203827, duals [0.01]| lrm: 0.443475| num_tokens: 2,574
Step 01724/03096 | Training loss: 1.068081 | Training constraint: -253.026764, duals [0.01]| lrm: 0.443152| num_tokens: 4,478
Step 01725/03096 | Training loss: 1.009375 | Training constraint: -432.197296, duals [0.01]| lrm: 0.442829| num_tokens: 2,971
Step 01726/03096 | Training loss: 0.953727 | Training constraint: -253.068253, duals [0.01]| lrm: 0.442506| num_tokens: 2,499
Step 01727/03096 | Training loss: 0.767036 | Training constraint: -302.212830, duals [0.01]| lrm: 0.442183| num_tokens: 3,189
Step 01728/03096 | Training loss: 1.262663 | Training constraint: -258.208374, duals [0.01]| lrm: 0.441860| num_tokens: 2,349
Step 01729/03096 | Training loss: 1.106418 | Training constraint: -429.507324, duals [0.01]| lrm: 0.441537| num_tokens: 3,076
Step 01730/03096 | Training loss: 0.940643 | Training constraint: -313.266815, duals [0.01]| lrm: 0.441214| num_tokens: 2,357
Step 01731/03096 | Training loss: 1.398553 | Training constraint: -472.915283, duals [0.01]| lrm: 0.440891| num_tokens: 4,354
Step 01732/03096 | Training loss: 1.210818 | Training constraint: -467.057556, duals [0.01]| lrm: 0.440568| num_tokens: 5,464
Step 01733/03096 | Training loss: 0.907401 | Training constraint: -528.653992, duals [0.01]| lrm: 0.440245| num_tokens: 2,578
Step 01734/03096 | Training loss: 1.241007 | Training constraint: -553.060852, duals [0.01]| lrm: 0.439922| num_tokens: 6,178
Step 01735/03096 | Training loss: 0.880110 | Training constraint: -191.504150, duals [0.01]| lrm: 0.439599| num_tokens: 2,236
Step 01736/03096 | Training loss: 1.173012 | Training constraint: -256.812439, duals [0.01]| lrm: 0.439276| num_tokens: 1,014
Step 01737/03096 | Training loss: 0.954407 | Training constraint: -281.095123, duals [0.01]| lrm: 0.438953| num_tokens: 3,314
Step 01738/03096 | Training loss: 0.878877 | Training constraint: -227.833572, duals [0.01]| lrm: 0.438630| num_tokens: 2,655
Step 01739/03096 | Training loss: 1.273382 | Training constraint: -370.578552, duals [0.01]| lrm: 0.438307| num_tokens: 3,359
Step 01740/03096 | Training loss: 1.155936 | Training constraint: -427.073334, duals [0.01]| lrm: 0.437984| num_tokens: 4,310
Step 01741/03096 | Training loss: 1.006268 | Training constraint: -485.509064, duals [0.01]| lrm: 0.437661| num_tokens: 3,964
Step 01742/03096 | Training loss: 0.961236 | Training constraint: -342.165771, duals [0.01]| lrm: 0.437339| num_tokens: 2,515
Step 01743/03096 | Training loss: 0.882281 | Training constraint: -127.773949, duals [0.01]| lrm: 0.437016| num_tokens: 2,906
Step 01744/03096 | Training loss: 0.865507 | Training constraint: -368.159180, duals [0.01]| lrm: 0.436693| num_tokens: 3,179
Step 01745/03096 | Training loss: 1.023975 | Training constraint: -242.840454, duals [0.01]| lrm: 0.436370| num_tokens: 2,795
Step 01746/03096 | Training loss: 1.014845 | Training constraint: -244.465958, duals [0.01]| lrm: 0.436047| num_tokens: 4,114
Step 01747/03096 | Training loss: 1.117958 | Training constraint: -292.276398, duals [0.01]| lrm: 0.435724| num_tokens: 2,926
Step 01748/03096 | Training loss: 1.188251 | Training constraint: -398.871155, duals [0.01]| lrm: 0.435401| num_tokens: 3,235
Step 01749/03096 | Training loss: 0.870906 | Training constraint: -225.630173, duals [0.01]| lrm: 0.435078| num_tokens: 4,441
Step 01750/03096 | Training loss: 0.911489 | Training constraint: -304.398865, duals [0.01]| lrm: 0.434755| num_tokens: 3,920
Step 01751/03096 | Training loss: 0.961687 | Training constraint: -454.678772, duals [0.01]| lrm: 0.434432| num_tokens: 3,845
Step 01752/03096 | Training loss: 1.061457 | Training constraint: -360.636139, duals [0.01]| lrm: 0.434109| num_tokens: 1,694
Step 01753/03096 | Training loss: 0.902790 | Training constraint: -512.930786, duals [0.01]| lrm: 0.433786| num_tokens: 4,897
Step 01754/03096 | Training loss: 1.066374 | Training constraint: -371.895691, duals [0.01]| lrm: 0.433463| num_tokens: 3,174
Step 01755/03096 | Training loss: 0.882173 | Training constraint: -210.994186, duals [0.01]| lrm: 0.433140| num_tokens: 4,548
Step 01756/03096 | Training loss: 1.025216 | Training constraint: -317.269043, duals [0.01]| lrm: 0.432817| num_tokens: 2,221
Step 01757/03096 | Training loss: 0.984873 | Training constraint: -412.974884, duals [0.01]| lrm: 0.432494| num_tokens: 3,899
Step 01758/03096 | Training loss: 0.768942 | Training constraint: -271.033661, duals [0.01]| lrm: 0.432171| num_tokens: 4,588
Step 01759/03096 | Training loss: 0.944789 | Training constraint: -262.609222, duals [0.01]| lrm: 0.431848| num_tokens: 1,157
Step 01760/03096 | Training loss: 0.971963 | Training constraint: -433.881775, duals [0.01]| lrm: 0.431525| num_tokens: 3,628
Step 01761/03096 | Training loss: 0.888171 | Training constraint: -420.631226, duals [0.01]| lrm: 0.431202| num_tokens: 2,708
Step 01762/03096 | Training loss: 1.228434 | Training constraint: -362.824890, duals [0.01]| lrm: 0.430879| num_tokens: 3,341
Step 01763/03096 | Training loss: 0.964520 | Training constraint: -354.549866, duals [0.01]| lrm: 0.430556| num_tokens: 3,356
Step 01764/03096 | Training loss: 1.251832 | Training constraint: -399.840881, duals [0.01]| lrm: 0.430233| num_tokens: 2,526
Step 01765/03096 | Training loss: 1.076874 | Training constraint: -424.464966, duals [0.01]| lrm: 0.429910| num_tokens: 3,891
Step 01766/03096 | Training loss: 0.860305 | Training constraint: -418.790466, duals [0.01]| lrm: 0.429587| num_tokens: 3,262
Step 01767/03096 | Training loss: 0.825598 | Training constraint: -346.191254, duals [0.01]| lrm: 0.429264| num_tokens: 2,373
Step 01768/03096 | Training loss: 0.987002 | Training constraint: -364.576172, duals [0.01]| lrm: 0.428941| num_tokens: 3,878
Step 01769/03096 | Training loss: 1.094970 | Training constraint: -210.337585, duals [0.01]| lrm: 0.428618| num_tokens: 2,476
Step 01770/03096 | Training loss: 0.981570 | Training constraint: -295.184174, duals [0.01]| lrm: 0.428295| num_tokens: 2,974
Step 01771/03096 | Training loss: 0.937327 | Training constraint: -272.770660, duals [0.01]| lrm: 0.427972| num_tokens: 2,121
Step 01772/03096 | Training loss: 1.216205 | Training constraint: -448.886505, duals [0.01]| lrm: 0.427649| num_tokens: 3,221
Step 01773/03096 | Training loss: 0.813002 | Training constraint: -181.798233, duals [0.01]| lrm: 0.427326| num_tokens: 3,689
Step 01774/03096 | Training loss: 0.933105 | Training constraint: -454.561096, duals [0.01]| lrm: 0.427003| num_tokens: 4,327
Step 01775/03096 | Training loss: 1.146609 | Training constraint: -294.055634, duals [0.01]| lrm: 0.426680| num_tokens: 6,260
Step 01776/03096 | Training loss: 1.159171 | Training constraint: -463.397736, duals [0.01]| lrm: 0.426357| num_tokens: 5,608
Step 01777/03096 | Training loss: 0.967614 | Training constraint: -431.526611, duals [0.01]| lrm: 0.426034| num_tokens: 2,697
Step 01778/03096 | Training loss: 0.863621 | Training constraint: -429.887146, duals [0.01]| lrm: 0.425711| num_tokens: 2,504
Step 01779/03096 | Training loss: 0.975698 | Training constraint: -317.351624, duals [0.01]| lrm: 0.425388| num_tokens: 3,062
Step 01780/03096 | Training loss: 1.010593 | Training constraint: -221.142334, duals [0.01]| lrm: 0.425065| num_tokens: 1,916
Step 01781/03096 | Training loss: 0.952874 | Training constraint: -400.746613, duals [0.01]| lrm: 0.424742| num_tokens: 3,351
Step 01782/03096 | Training loss: 1.205755 | Training constraint: -356.855652, duals [0.01]| lrm: 0.424419| num_tokens: 4,959
Step 01783/03096 | Training loss: 0.958799 | Training constraint: -338.685883, duals [0.01]| lrm: 0.424096| num_tokens: 3,040
Step 01784/03096 | Training loss: 0.845136 | Training constraint: -391.208893, duals [0.01]| lrm: 0.423773| num_tokens: 2,446
Step 01785/03096 | Training loss: 0.982207 | Training constraint: -373.461914, duals [0.01]| lrm: 0.423450| num_tokens: 6,041
Step 01786/03096 | Training loss: 1.006219 | Training constraint: -285.100983, duals [0.01]| lrm: 0.423127| num_tokens: 4,302
Step 01787/03096 | Training loss: 1.215879 | Training constraint: -315.210510, duals [0.01]| lrm: 0.422804| num_tokens: 3,761
Step 01788/03096 | Training loss: 1.085989 | Training constraint: -398.551392, duals [0.01]| lrm: 0.422481| num_tokens: 3,380
Step 01789/03096 | Training loss: 0.918386 | Training constraint: -203.575165, duals [0.01]| lrm: 0.422158| num_tokens: 1,025
Step 01790/03096 | Training loss: 0.856766 | Training constraint: -324.788666, duals [0.01]| lrm: 0.421835| num_tokens: 4,642
Step 01791/03096 | Training loss: 0.964352 | Training constraint: -220.749786, duals [0.01]| lrm: 0.421512| num_tokens: 2,307
Step 01792/03096 | Training loss: 0.921741 | Training constraint: -395.668396, duals [0.01]| lrm: 0.421189| num_tokens: 3,982
Step 01793/03096 | Training loss: 1.125955 | Training constraint: -493.769287, duals [0.01]| lrm: 0.420866| num_tokens: 3,832
Step 01794/03096 | Training loss: 1.065441 | Training constraint: -319.797974, duals [0.01]| lrm: 0.420543| num_tokens: 3,328
Step 01795/03096 | Training loss: 0.825873 | Training constraint: -350.590149, duals [0.01]| lrm: 0.420220| num_tokens: 3,987
Step 01796/03096 | Training loss: 1.154273 | Training constraint: -281.701782, duals [0.01]| lrm: 0.419897| num_tokens: 3,877
Step 01797/03096 | Training loss: 0.922009 | Training constraint: -371.277466, duals [0.01]| lrm: 0.419574| num_tokens: 2,961
Step 01798/03096 | Training loss: 1.239478 | Training constraint: -254.400604, duals [0.01]| lrm: 0.419251| num_tokens: 2,343
Step 01799/03096 | Training loss: 1.099429 | Training constraint: -377.682404, duals [0.01]| lrm: 0.418928| num_tokens: 2,638
Step 01800 | Validation loss: 1.166414
2026-01-21 14:16:42,339 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:16:42,341 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:16:42,344 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:16:42,346 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:16:42,459 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:42,462 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:42,802 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:42,830 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:43,195 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:16:43,224 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:16:43,347 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:16:43,365 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 303/1024 (29.59%)
2026-01-21 14:16:43,948 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:16:43,949 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:16:43,953 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:16:43,953 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:16:44,067 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:44,078 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:44,191 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:44,197 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:16:44,306 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:16:44,313 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:16:44,434 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:16:44,437 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:16:44,551 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:16:44,552 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 356/1024 (34.77%)
Step 01800 | mmlu_acc: 0.295898, arc_easy_acc: 0.347656
Step 01800/03096 | Training loss: 0.825366 | Training constraint: -201.242950, duals [0.01]| lrm: 0.418605| num_tokens: 5,683
Step 01801/03096 | Training loss: 0.920140 | Training constraint: -319.041382, duals [0.01]| lrm: 0.418282| num_tokens: 3,480
Step 01802/03096 | Training loss: 0.903597 | Training constraint: -304.944000, duals [0.01]| lrm: 0.417959| num_tokens: 5,606
Step 01803/03096 | Training loss: 1.228838 | Training constraint: -319.179596, duals [0.01]| lrm: 0.417636| num_tokens: 5,620
Step 01804/03096 | Training loss: 1.008035 | Training constraint: -356.651428, duals [0.01]| lrm: 0.417313| num_tokens: 3,640
Step 01805/03096 | Training loss: 0.937506 | Training constraint: -350.352203, duals [0.01]| lrm: 0.416990| num_tokens: 2,794
Step 01806/03096 | Training loss: 1.046118 | Training constraint: -250.383270, duals [0.01]| lrm: 0.416667| num_tokens: 1,259
Step 01807/03096 | Training loss: 1.006815 | Training constraint: -397.113464, duals [0.01]| lrm: 0.416344| num_tokens: 4,153
Step 01808/03096 | Training loss: 0.889295 | Training constraint: -300.053131, duals [0.01]| lrm: 0.416021| num_tokens: 3,044
Step 01809/03096 | Training loss: 0.979026 | Training constraint: -220.530579, duals [0.01]| lrm: 0.415698| num_tokens: 2,643
Step 01810/03096 | Training loss: 0.952013 | Training constraint: -322.541931, duals [0.01]| lrm: 0.415375| num_tokens: 2,985
Step 01811/03096 | Training loss: 1.184973 | Training constraint: -212.677979, duals [0.01]| lrm: 0.415052| num_tokens: 3,148
Step 01812/03096 | Training loss: 0.768560 | Training constraint: -217.107147, duals [0.01]| lrm: 0.414729| num_tokens: 2,000
Step 01813/03096 | Training loss: 1.027784 | Training constraint: -307.347778, duals [0.01]| lrm: 0.414406| num_tokens: 3,728
Step 01814/03096 | Training loss: 1.017552 | Training constraint: -338.959229, duals [0.01]| lrm: 0.414083| num_tokens: 7,008
Step 01815/03096 | Training loss: 1.281252 | Training constraint: -411.332825, duals [0.01]| lrm: 0.413760| num_tokens: 4,848
Step 01816/03096 | Training loss: 1.241629 | Training constraint: -203.840576, duals [0.01]| lrm: 0.413437| num_tokens: 3,419
Step 01817/03096 | Training loss: 0.857341 | Training constraint: -371.847473, duals [0.01]| lrm: 0.413114| num_tokens: 5,133
Step 01818/03096 | Training loss: 1.067695 | Training constraint: -225.047852, duals [0.01]| lrm: 0.412791| num_tokens: 3,015
Step 01819/03096 | Training loss: 1.064885 | Training constraint: -434.720764, duals [0.01]| lrm: 0.412468| num_tokens: 5,632
Step 01820/03096 | Training loss: 0.960275 | Training constraint: -374.042023, duals [0.01]| lrm: 0.412145| num_tokens: 6,731
Step 01821/03096 | Training loss: 1.070778 | Training constraint: -277.912384, duals [0.01]| lrm: 0.411822| num_tokens: 3,999
Step 01822/03096 | Training loss: 1.222162 | Training constraint: -383.067535, duals [0.01]| lrm: 0.411499| num_tokens: 3,119
Step 01823/03096 | Training loss: 1.327484 | Training constraint: -264.086243, duals [0.01]| lrm: 0.411176| num_tokens: 2,570
Step 01824/03096 | Training loss: 0.983562 | Training constraint: -254.097092, duals [0.01]| lrm: 0.410853| num_tokens: 2,094
Step 01825/03096 | Training loss: 0.981425 | Training constraint: -409.472717, duals [0.01]| lrm: 0.410530| num_tokens: 2,734
Step 01826/03096 | Training loss: 0.955124 | Training constraint: -443.570526, duals [0.01]| lrm: 0.410207| num_tokens: 3,052
Step 01827/03096 | Training loss: 0.869589 | Training constraint: -177.122543, duals [0.01]| lrm: 0.409884| num_tokens: 2,251
Step 01828/03096 | Training loss: 1.031079 | Training constraint: -277.990784, duals [0.01]| lrm: 0.409561| num_tokens: 2,329
Step 01829/03096 | Training loss: 0.909292 | Training constraint: -379.254395, duals [0.01]| lrm: 0.409238| num_tokens: 1,344
Step 01830/03096 | Training loss: 0.745212 | Training constraint: -355.038666, duals [0.01]| lrm: 0.408915| num_tokens: 3,498
Step 01831/03096 | Training loss: 0.917672 | Training constraint: -490.422974, duals [0.01]| lrm: 0.408592| num_tokens: 3,101
Step 01832/03096 | Training loss: 0.889881 | Training constraint: -250.937332, duals [0.01]| lrm: 0.408269| num_tokens: 7,118
Step 01833/03096 | Training loss: 1.152864 | Training constraint: -384.659882, duals [0.01]| lrm: 0.407946| num_tokens: 7,001
Step 01834/03096 | Training loss: 1.041260 | Training constraint: -280.600403, duals [0.01]| lrm: 0.407623| num_tokens: 4,344
Step 01835/03096 | Training loss: 0.933478 | Training constraint: -151.508286, duals [0.01]| lrm: 0.407300| num_tokens: 1,789
Step 01836/03096 | Training loss: 1.001077 | Training constraint: -317.046448, duals [0.01]| lrm: 0.406977| num_tokens: 5,911
Step 01837/03096 | Training loss: 0.865827 | Training constraint: -648.086304, duals [0.01]| lrm: 0.406654| num_tokens: 1,298
Step 01838/03096 | Training loss: 0.880682 | Training constraint: -417.660767, duals [0.01]| lrm: 0.406331| num_tokens: 2,610
Step 01839/03096 | Training loss: 1.104490 | Training constraint: -121.214554, duals [0.01]| lrm: 0.406008| num_tokens: 5,034
Step 01840/03096 | Training loss: 0.769816 | Training constraint: -285.689392, duals [0.01]| lrm: 0.405685| num_tokens: 4,972
Step 01841/03096 | Training loss: 0.780280 | Training constraint: -380.995392, duals [0.01]| lrm: 0.405362| num_tokens: 2,426
Step 01842/03096 | Training loss: 1.110910 | Training constraint: -488.405823, duals [0.01]| lrm: 0.405039| num_tokens: 1,840
Step 01843/03096 | Training loss: 0.967452 | Training constraint: -255.755371, duals [0.01]| lrm: 0.404716| num_tokens: 2,387
Step 01844/03096 | Training loss: 1.058673 | Training constraint: -475.209045, duals [0.01]| lrm: 0.404393| num_tokens: 4,432
Step 01845/03096 | Training loss: 1.110491 | Training constraint: -308.619080, duals [0.01]| lrm: 0.404070| num_tokens: 1,906
Step 01846/03096 | Training loss: 1.159741 | Training constraint: -446.591553, duals [0.01]| lrm: 0.403747| num_tokens: 5,832
Step 01847/03096 | Training loss: 0.867231 | Training constraint: -248.942749, duals [0.01]| lrm: 0.403424| num_tokens: 3,693
Step 01848/03096 | Training loss: 1.148364 | Training constraint: -263.767487, duals [0.01]| lrm: 0.403101| num_tokens: 2,299
Step 01849/03096 | Training loss: 0.998732 | Training constraint: -296.540771, duals [0.01]| lrm: 0.402778| num_tokens: 2,542
Step 01850/03096 | Training loss: 0.945431 | Training constraint: -286.362244, duals [0.01]| lrm: 0.402455| num_tokens: 2,697
Step 01851/03096 | Training loss: 1.074239 | Training constraint: -247.742569, duals [0.01]| lrm: 0.402132| num_tokens: 3,935
Step 01852/03096 | Training loss: 0.820281 | Training constraint: -372.628906, duals [0.01]| lrm: 0.401809| num_tokens: 4,546
Step 01853/03096 | Training loss: 0.951341 | Training constraint: -269.658081, duals [0.01]| lrm: 0.401486| num_tokens: 4,755
Step 01854/03096 | Training loss: 1.047235 | Training constraint: -409.038300, duals [0.01]| lrm: 0.401163| num_tokens: 1,797
Step 01855/03096 | Training loss: 0.974898 | Training constraint: -273.979706, duals [0.01]| lrm: 0.400840| num_tokens: 3,790
Step 01856/03096 | Training loss: 0.948660 | Training constraint: -93.955734, duals [0.01]| lrm: 0.400517| num_tokens: 6,648
Step 01857/03096 | Training loss: 1.236838 | Training constraint: -400.947693, duals [0.01]| lrm: 0.400194| num_tokens: 3,478
Step 01858/03096 | Training loss: 0.936856 | Training constraint: -126.814812, duals [0.01]| lrm: 0.399871| num_tokens: 4,977
Step 01859/03096 | Training loss: 0.649246 | Training constraint: -206.048019, duals [0.01]| lrm: 0.399548| num_tokens: 4,589
Step 01860/03096 | Training loss: 1.189880 | Training constraint: -254.126465, duals [0.01]| lrm: 0.399225| num_tokens: 5,079
Step 01861/03096 | Training loss: 1.156349 | Training constraint: -281.742004, duals [0.01]| lrm: 0.398902| num_tokens: 2,525
Step 01862/03096 | Training loss: 0.979941 | Training constraint: -361.385620, duals [0.01]| lrm: 0.398579| num_tokens: 3,942
Step 01863/03096 | Training loss: 1.020914 | Training constraint: -377.421265, duals [0.01]| lrm: 0.398256| num_tokens: 3,341
Step 01864/03096 | Training loss: 1.177962 | Training constraint: -457.941223, duals [0.01]| lrm: 0.397933| num_tokens: 4,907
Step 01865/03096 | Training loss: 0.877250 | Training constraint: -607.985291, duals [0.01]| lrm: 0.397610| num_tokens: 3,795
Step 01866/03096 | Training loss: 0.975061 | Training constraint: -229.512512, duals [0.01]| lrm: 0.397287| num_tokens: 2,022
Step 01867/03096 | Training loss: 1.075084 | Training constraint: -360.308167, duals [0.01]| lrm: 0.396964| num_tokens: 4,791
Step 01868/03096 | Training loss: 1.402693 | Training constraint: -276.185486, duals [0.01]| lrm: 0.396641| num_tokens: 4,426
Step 01869/03096 | Training loss: 1.144812 | Training constraint: -264.157074, duals [0.01]| lrm: 0.396318| num_tokens: 4,314
Step 01870/03096 | Training loss: 1.106417 | Training constraint: -436.499695, duals [0.01]| lrm: 0.395995| num_tokens: 1,696
Step 01871/03096 | Training loss: 0.999769 | Training constraint: -365.902710, duals [0.01]| lrm: 0.395672| num_tokens: 3,153
Step 01872/03096 | Training loss: 1.191309 | Training constraint: -287.862030, duals [0.01]| lrm: 0.395349| num_tokens: 5,892
Step 01873/03096 | Training loss: 0.816976 | Training constraint: -455.828247, duals [0.01]| lrm: 0.395026| num_tokens: 4,085
Step 01874/03096 | Training loss: 1.161407 | Training constraint: -342.248108, duals [0.01]| lrm: 0.394703| num_tokens: 3,539
Step 01875/03096 | Training loss: 1.079968 | Training constraint: -554.985107, duals [0.01]| lrm: 0.394380| num_tokens: 5,704
Step 01876/03096 | Training loss: 1.172703 | Training constraint: -297.251770, duals [0.01]| lrm: 0.394057| num_tokens: 1,868
Step 01877/03096 | Training loss: 1.015953 | Training constraint: -637.692261, duals [0.01]| lrm: 0.393734| num_tokens: 1,627
Step 01878/03096 | Training loss: 1.279382 | Training constraint: -288.184479, duals [0.01]| lrm: 0.393411| num_tokens: 3,755
Step 01879/03096 | Training loss: 1.228757 | Training constraint: -263.313904, duals [0.01]| lrm: 0.393088| num_tokens: 4,352
Step 01880/03096 | Training loss: 1.053584 | Training constraint: -559.069885, duals [0.01]| lrm: 0.392765| num_tokens: 5,352
Step 01881/03096 | Training loss: 1.097412 | Training constraint: -400.835205, duals [0.01]| lrm: 0.392442| num_tokens: 2,761
Step 01882/03096 | Training loss: 1.146348 | Training constraint: -348.732178, duals [0.01]| lrm: 0.392119| num_tokens: 3,055
Step 01883/03096 | Training loss: 1.020597 | Training constraint: -334.292084, duals [0.01]| lrm: 0.391796| num_tokens: 4,182
Step 01884/03096 | Training loss: 1.046945 | Training constraint: -268.450897, duals [0.01]| lrm: 0.391473| num_tokens: 5,798
Step 01885/03096 | Training loss: 0.990524 | Training constraint: -215.183105, duals [0.01]| lrm: 0.391150| num_tokens: 4,914
Step 01886/03096 | Training loss: 1.037836 | Training constraint: -370.513214, duals [0.01]| lrm: 0.390827| num_tokens: 1,616
Step 01887/03096 | Training loss: 0.819609 | Training constraint: -185.799454, duals [0.01]| lrm: 0.390504| num_tokens: 3,165
Step 01888/03096 | Training loss: 0.650913 | Training constraint: -246.935120, duals [0.01]| lrm: 0.390181| num_tokens: 1,964
Step 01889/03096 | Training loss: 1.207657 | Training constraint: -410.312317, duals [0.01]| lrm: 0.389858| num_tokens: 2,211
Step 01890/03096 | Training loss: 0.959354 | Training constraint: -419.270325, duals [0.01]| lrm: 0.389535| num_tokens: 3,059
Step 01891/03096 | Training loss: 1.137309 | Training constraint: -378.516174, duals [0.01]| lrm: 0.389212| num_tokens: 3,121
Step 01892/03096 | Training loss: 1.034091 | Training constraint: -419.023102, duals [0.01]| lrm: 0.388889| num_tokens: 3,604
Step 01893/03096 | Training loss: 1.076275 | Training constraint: -461.528839, duals [0.01]| lrm: 0.388566| num_tokens: 2,549
Step 01894/03096 | Training loss: 1.003182 | Training constraint: -252.263611, duals [0.01]| lrm: 0.388243| num_tokens: 3,544
Step 01895/03096 | Training loss: 1.123671 | Training constraint: -305.831635, duals [0.01]| lrm: 0.387920| num_tokens: 3,148
Step 01896/03096 | Training loss: 1.021535 | Training constraint: -411.404297, duals [0.01]| lrm: 0.387597| num_tokens: 785
Step 01897/03096 | Training loss: 0.790756 | Training constraint: -347.363739, duals [0.01]| lrm: 0.387274| num_tokens: 2,440
Step 01898/03096 | Training loss: 1.524450 | Training constraint: -266.451050, duals [0.01]| lrm: 0.386951| num_tokens: 1,108
Step 01899/03096 | Training loss: 0.936585 | Training constraint: -306.297119, duals [0.01]| lrm: 0.386628| num_tokens: 2,535
Step 01900 | Validation loss: 1.167458
Step 01900/03096 | Training loss: 0.835141 | Training constraint: -394.088196, duals [0.01]| lrm: 0.386305| num_tokens: 3,223
Step 01901/03096 | Training loss: 0.870449 | Training constraint: -381.017639, duals [0.01]| lrm: 0.385982| num_tokens: 2,893
Step 01902/03096 | Training loss: 1.092881 | Training constraint: -371.586670, duals [0.01]| lrm: 0.385659| num_tokens: 3,706
Step 01903/03096 | Training loss: 1.197484 | Training constraint: -294.636475, duals [0.01]| lrm: 0.385336| num_tokens: 3,873
Step 01904/03096 | Training loss: 0.689374 | Training constraint: -573.703247, duals [0.01]| lrm: 0.385013| num_tokens: 4,187
Step 01905/03096 | Training loss: 1.202979 | Training constraint: -247.847961, duals [0.01]| lrm: 0.384690| num_tokens: 4,609
Step 01906/03096 | Training loss: 1.140171 | Training constraint: -251.426514, duals [0.01]| lrm: 0.384367| num_tokens: 4,888
Step 01907/03096 | Training loss: 1.111501 | Training constraint: -183.052536, duals [0.01]| lrm: 0.384044| num_tokens: 3,839
Step 01908/03096 | Training loss: 0.901004 | Training constraint: -183.836761, duals [0.01]| lrm: 0.383721| num_tokens: 3,380
Step 01909/03096 | Training loss: 0.911444 | Training constraint: -367.975891, duals [0.01]| lrm: 0.383398| num_tokens: 4,035
Step 01910/03096 | Training loss: 1.065773 | Training constraint: -573.692505, duals [0.01]| lrm: 0.383075| num_tokens: 1,389
Step 01911/03096 | Training loss: 0.936070 | Training constraint: -214.380920, duals [0.01]| lrm: 0.382752| num_tokens: 2,305
Step 01912/03096 | Training loss: 0.830792 | Training constraint: -326.277100, duals [0.01]| lrm: 0.382429| num_tokens: 4,708
Step 01913/03096 | Training loss: 0.996970 | Training constraint: -391.383911, duals [0.01]| lrm: 0.382106| num_tokens: 2,590
Step 01914/03096 | Training loss: 1.157846 | Training constraint: -385.653931, duals [0.01]| lrm: 0.381783| num_tokens: 3,401
Step 01915/03096 | Training loss: 0.779146 | Training constraint: -249.970673, duals [0.01]| lrm: 0.381460| num_tokens: 2,328
Step 01916/03096 | Training loss: 1.139808 | Training constraint: -437.761841, duals [0.01]| lrm: 0.381137| num_tokens: 2,792
Step 01917/03096 | Training loss: 0.853939 | Training constraint: -154.295959, duals [0.01]| lrm: 0.380814| num_tokens: 2,720
Step 01918/03096 | Training loss: 1.157670 | Training constraint: -409.485596, duals [0.01]| lrm: 0.380491| num_tokens: 4,483
Step 01919/03096 | Training loss: 1.085781 | Training constraint: -281.629242, duals [0.01]| lrm: 0.380168| num_tokens: 3,818
Step 01920/03096 | Training loss: 1.098273 | Training constraint: -389.572296, duals [0.01]| lrm: 0.379845| num_tokens: 3,986
Step 01921/03096 | Training loss: 0.766989 | Training constraint: -512.270996, duals [0.01]| lrm: 0.379522| num_tokens: 2,361
Step 01922/03096 | Training loss: 1.125148 | Training constraint: -201.849945, duals [0.01]| lrm: 0.379199| num_tokens: 1,909
Step 01923/03096 | Training loss: 0.880995 | Training constraint: -420.780823, duals [0.01]| lrm: 0.378876| num_tokens: 3,699
Step 01924/03096 | Training loss: 0.978683 | Training constraint: -284.464691, duals [0.01]| lrm: 0.378553| num_tokens: 5,419
Step 01925/03096 | Training loss: 1.006704 | Training constraint: -417.682892, duals [0.01]| lrm: 0.378230| num_tokens: 2,799
Step 01926/03096 | Training loss: 1.071979 | Training constraint: -310.585358, duals [0.01]| lrm: 0.377907| num_tokens: 1,287
Step 01927/03096 | Training loss: 1.051155 | Training constraint: -316.927246, duals [0.01]| lrm: 0.377584| num_tokens: 3,960
Step 01928/03096 | Training loss: 1.136767 | Training constraint: -258.361176, duals [0.01]| lrm: 0.377261| num_tokens: 3,811
Step 01929/03096 | Training loss: 0.972791 | Training constraint: -388.966003, duals [0.01]| lrm: 0.376938| num_tokens: 2,990
Step 01930/03096 | Training loss: 1.187896 | Training constraint: -298.943817, duals [0.01]| lrm: 0.376615| num_tokens: 2,088
Step 01931/03096 | Training loss: 0.921218 | Training constraint: -515.924438, duals [0.01]| lrm: 0.376292| num_tokens: 3,341
Step 01932/03096 | Training loss: 1.131703 | Training constraint: -427.121155, duals [0.01]| lrm: 0.375969| num_tokens: 4,467
Step 01933/03096 | Training loss: 0.896479 | Training constraint: -274.213562, duals [0.01]| lrm: 0.375646| num_tokens: 3,944
Step 01934/03096 | Training loss: 1.100849 | Training constraint: -354.474121, duals [0.01]| lrm: 0.375323| num_tokens: 2,360
Step 01935/03096 | Training loss: 1.222545 | Training constraint: -401.256714, duals [0.01]| lrm: 0.375000| num_tokens: 1,841
Step 01936/03096 | Training loss: 1.142677 | Training constraint: -197.153946, duals [0.01]| lrm: 0.374677| num_tokens: 3,770
Step 01937/03096 | Training loss: 1.070177 | Training constraint: -424.229034, duals [0.01]| lrm: 0.374354| num_tokens: 2,498
Step 01938/03096 | Training loss: 1.003048 | Training constraint: -301.963928, duals [0.01]| lrm: 0.374031| num_tokens: 4,840
Step 01939/03096 | Training loss: 1.073032 | Training constraint: -407.726837, duals [0.01]| lrm: 0.373708| num_tokens: 2,167
Step 01940/03096 | Training loss: 0.805950 | Training constraint: -428.340454, duals [0.01]| lrm: 0.373385| num_tokens: 3,238
Step 01941/03096 | Training loss: 0.691557 | Training constraint: -184.332062, duals [0.01]| lrm: 0.373062| num_tokens: 868
Step 01942/03096 | Training loss: 1.132373 | Training constraint: -359.617432, duals [0.01]| lrm: 0.372739| num_tokens: 4,452
Step 01943/03096 | Training loss: 1.049146 | Training constraint: -392.894196, duals [0.01]| lrm: 0.372416| num_tokens: 4,490
Step 01944/03096 | Training loss: 1.233875 | Training constraint: -347.896210, duals [0.01]| lrm: 0.372093| num_tokens: 2,753
Step 01945/03096 | Training loss: 0.768982 | Training constraint: -301.269379, duals [0.01]| lrm: 0.371770| num_tokens: 2,746
Step 01946/03096 | Training loss: 1.042331 | Training constraint: -224.782043, duals [0.01]| lrm: 0.371447| num_tokens: 2,315
Step 01947/03096 | Training loss: 1.083335 | Training constraint: -380.286163, duals [0.01]| lrm: 0.371124| num_tokens: 1,333
Step 01948/03096 | Training loss: 0.861945 | Training constraint: -369.640717, duals [0.01]| lrm: 0.370801| num_tokens: 5,226
Step 01949/03096 | Training loss: 0.907938 | Training constraint: -186.597336, duals [0.01]| lrm: 0.370478| num_tokens: 4,003
Step 01950/03096 | Training loss: 0.919397 | Training constraint: -238.861038, duals [0.01]| lrm: 0.370155| num_tokens: 4,160
Step 01951/03096 | Training loss: 0.796992 | Training constraint: -400.283386, duals [0.01]| lrm: 0.369832| num_tokens: 3,655
Step 01952/03096 | Training loss: 1.019703 | Training constraint: -403.704163, duals [0.01]| lrm: 0.369509| num_tokens: 2,226
Step 01953/03096 | Training loss: 1.092876 | Training constraint: -280.276855, duals [0.01]| lrm: 0.369186| num_tokens: 4,230
Step 01954/03096 | Training loss: 0.919671 | Training constraint: -210.258575, duals [0.01]| lrm: 0.368863| num_tokens: 2,768
Step 01955/03096 | Training loss: 0.862386 | Training constraint: -269.953735, duals [0.01]| lrm: 0.368540| num_tokens: 896
Step 01956/03096 | Training loss: 1.004379 | Training constraint: -270.993591, duals [0.01]| lrm: 0.368217| num_tokens: 5,798
Step 01957/03096 | Training loss: 0.812117 | Training constraint: -379.808044, duals [0.01]| lrm: 0.367894| num_tokens: 1,089
Step 01958/03096 | Training loss: 0.940562 | Training constraint: -288.368591, duals [0.01]| lrm: 0.367571| num_tokens: 2,915
Step 01959/03096 | Training loss: 0.954955 | Training constraint: -201.975403, duals [0.01]| lrm: 0.367248| num_tokens: 4,002
Step 01960/03096 | Training loss: 1.242392 | Training constraint: -284.769440, duals [0.01]| lrm: 0.366925| num_tokens: 3,573
Step 01961/03096 | Training loss: 1.015828 | Training constraint: -431.741547, duals [0.01]| lrm: 0.366602| num_tokens: 2,054
Step 01962/03096 | Training loss: 1.150164 | Training constraint: -331.516418, duals [0.01]| lrm: 0.366279| num_tokens: 3,320
Step 01963/03096 | Training loss: 1.082966 | Training constraint: -240.456909, duals [0.01]| lrm: 0.365956| num_tokens: 3,840
Step 01964/03096 | Training loss: 0.883729 | Training constraint: -450.393555, duals [0.01]| lrm: 0.365633| num_tokens: 3,189
Step 01965/03096 | Training loss: 1.011429 | Training constraint: -302.747101, duals [0.01]| lrm: 0.365310| num_tokens: 4,102
Step 01966/03096 | Training loss: 0.900522 | Training constraint: -280.217712, duals [0.01]| lrm: 0.364987| num_tokens: 4,511
Step 01967/03096 | Training loss: 1.176491 | Training constraint: -310.643219, duals [0.01]| lrm: 0.364664| num_tokens: 3,415
Step 01968/03096 | Training loss: 1.047123 | Training constraint: -355.850800, duals [0.01]| lrm: 0.364341| num_tokens: 2,736
Step 01969/03096 | Training loss: 0.848042 | Training constraint: -296.081909, duals [0.01]| lrm: 0.364018| num_tokens: 3,228
Step 01970/03096 | Training loss: 1.101722 | Training constraint: -231.765091, duals [0.01]| lrm: 0.363695| num_tokens: 3,595
Step 01971/03096 | Training loss: 0.917891 | Training constraint: -305.660248, duals [0.01]| lrm: 0.363372| num_tokens: 6,404
Step 01972/03096 | Training loss: 1.090899 | Training constraint: -219.087433, duals [0.01]| lrm: 0.363049| num_tokens: 3,713
Step 01973/03096 | Training loss: 0.776304 | Training constraint: -532.775391, duals [0.01]| lrm: 0.362726| num_tokens: 2,917
Step 01974/03096 | Training loss: 0.916686 | Training constraint: -186.092209, duals [0.01]| lrm: 0.362403| num_tokens: 938
Step 01975/03096 | Training loss: 0.835721 | Training constraint: -433.110413, duals [0.01]| lrm: 0.362080| num_tokens: 4,078
Step 01976/03096 | Training loss: 1.159014 | Training constraint: -353.234985, duals [0.01]| lrm: 0.361757| num_tokens: 2,931
Step 01977/03096 | Training loss: 1.009880 | Training constraint: -233.522552, duals [0.01]| lrm: 0.361434| num_tokens: 5,499
Step 01978/03096 | Training loss: 1.246593 | Training constraint: -142.978897, duals [0.01]| lrm: 0.361111| num_tokens: 3,377
Step 01979/03096 | Training loss: 1.148869 | Training constraint: -376.835602, duals [0.01]| lrm: 0.360788| num_tokens: 5,136
Step 01980/03096 | Training loss: 1.093568 | Training constraint: -344.594879, duals [0.01]| lrm: 0.360465| num_tokens: 3,977
Step 01981/03096 | Training loss: 1.011415 | Training constraint: -317.670319, duals [0.01]| lrm: 0.360142| num_tokens: 2,444
Step 01982/03096 | Training loss: 0.947156 | Training constraint: -304.623474, duals [0.01]| lrm: 0.359819| num_tokens: 5,633
Step 01983/03096 | Training loss: 0.869637 | Training constraint: -351.578369, duals [0.01]| lrm: 0.359496| num_tokens: 4,581
Step 01984/03096 | Training loss: 1.191584 | Training constraint: -319.025269, duals [0.01]| lrm: 0.359173| num_tokens: 3,571
Step 01985/03096 | Training loss: 0.923797 | Training constraint: -242.889236, duals [0.01]| lrm: 0.358850| num_tokens: 2,193
Step 01986/03096 | Training loss: 1.079808 | Training constraint: -423.477600, duals [0.01]| lrm: 0.358527| num_tokens: 3,458
Step 01987/03096 | Training loss: 1.058214 | Training constraint: -348.016418, duals [0.01]| lrm: 0.358204| num_tokens: 3,273
Step 01988/03096 | Training loss: 1.160998 | Training constraint: -308.745422, duals [0.01]| lrm: 0.357881| num_tokens: 3,243
Step 01989/03096 | Training loss: 1.112981 | Training constraint: -509.133942, duals [0.01]| lrm: 0.357558| num_tokens: 4,148
Step 01990/03096 | Training loss: 1.062351 | Training constraint: -294.303009, duals [0.01]| lrm: 0.357235| num_tokens: 2,220
Step 01991/03096 | Training loss: 1.147856 | Training constraint: -292.561249, duals [0.01]| lrm: 0.356912| num_tokens: 4,395
Step 01992/03096 | Training loss: 0.970669 | Training constraint: -323.277618, duals [0.01]| lrm: 0.356589| num_tokens: 2,473
Step 01993/03096 | Training loss: 1.107540 | Training constraint: -295.750366, duals [0.01]| lrm: 0.356266| num_tokens: 4,556
Step 01994/03096 | Training loss: 1.425619 | Training constraint: -374.184448, duals [0.01]| lrm: 0.355943| num_tokens: 4,745
Step 01995/03096 | Training loss: 1.186875 | Training constraint: -338.318848, duals [0.01]| lrm: 0.355620| num_tokens: 1,798
Step 01996/03096 | Training loss: 1.098927 | Training constraint: -392.296600, duals [0.01]| lrm: 0.355297| num_tokens: 3,195
Step 01997/03096 | Training loss: 0.950865 | Training constraint: -370.262787, duals [0.01]| lrm: 0.354974| num_tokens: 958
Step 01998/03096 | Training loss: 1.181611 | Training constraint: -395.914307, duals [0.01]| lrm: 0.354651| num_tokens: 3,977
Step 01999/03096 | Training loss: 0.990409 | Training constraint: -292.109528, duals [0.01]| lrm: 0.354328| num_tokens: 5,405
Step 02000 | Validation loss: 1.168519
2026-01-21 14:17:19,987 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:17:19,988 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:17:19,991 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:17:19,992 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:17:20,104 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:20,105 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:20,477 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:20,484 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:20,673 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:17:20,698 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:17:20,852 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:17:20,855 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 312/1024 (30.47%)
2026-01-21 14:17:21,455 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:17:21,455 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:17:21,460 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:17:21,460 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:17:21,572 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:21,573 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:21,694 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:21,695 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:21,812 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:17:21,813 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:17:21,940 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:17:21,944 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:17:22,056 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:17:22,061 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 351/1024 (34.28%)
Step 02000 | mmlu_acc: 0.304688, arc_easy_acc: 0.342773
Step 02000/03096 | Training loss: 1.236974 | Training constraint: -427.064514, duals [0.01]| lrm: 0.354005| num_tokens: 3,210
Step 02001/03096 | Training loss: 0.977453 | Training constraint: -381.798523, duals [0.01]| lrm: 0.353682| num_tokens: 1,858
Step 02002/03096 | Training loss: 0.801601 | Training constraint: -405.556702, duals [0.01]| lrm: 0.353359| num_tokens: 4,441
Step 02003/03096 | Training loss: 1.173156 | Training constraint: -355.532043, duals [0.01]| lrm: 0.353036| num_tokens: 3,540
Step 02004/03096 | Training loss: 1.282270 | Training constraint: -279.314819, duals [0.01]| lrm: 0.352713| num_tokens: 3,554
Step 02005/03096 | Training loss: 1.046456 | Training constraint: -369.725250, duals [0.01]| lrm: 0.352390| num_tokens: 3,689
Step 02006/03096 | Training loss: 0.884962 | Training constraint: -221.323120, duals [0.01]| lrm: 0.352067| num_tokens: 1,562
Step 02007/03096 | Training loss: 1.432624 | Training constraint: -341.994202, duals [0.01]| lrm: 0.351744| num_tokens: 3,327
Step 02008/03096 | Training loss: 1.082684 | Training constraint: -426.515625, duals [0.01]| lrm: 0.351421| num_tokens: 3,669
Step 02009/03096 | Training loss: 0.939231 | Training constraint: -195.252701, duals [0.01]| lrm: 0.351098| num_tokens: 2,089
Step 02010/03096 | Training loss: 0.999255 | Training constraint: -328.286926, duals [0.01]| lrm: 0.350775| num_tokens: 3,661
Step 02011/03096 | Training loss: 1.156246 | Training constraint: -520.179565, duals [0.01]| lrm: 0.350452| num_tokens: 1,750
Step 02012/03096 | Training loss: 1.074052 | Training constraint: -323.461884, duals [0.01]| lrm: 0.350129| num_tokens: 3,518
Step 02013/03096 | Training loss: 0.869647 | Training constraint: -363.442810, duals [0.01]| lrm: 0.349806| num_tokens: 4,082
Step 02014/03096 | Training loss: 0.977793 | Training constraint: -230.420166, duals [0.01]| lrm: 0.349483| num_tokens: 2,191
Step 02015/03096 | Training loss: 0.752734 | Training constraint: -333.041809, duals [0.01]| lrm: 0.349160| num_tokens: 3,216
Step 02016/03096 | Training loss: 0.998168 | Training constraint: -285.144257, duals [0.01]| lrm: 0.348837| num_tokens: 3,937
Step 02017/03096 | Training loss: 1.052069 | Training constraint: -478.696381, duals [0.01]| lrm: 0.348514| num_tokens: 3,310
Step 02018/03096 | Training loss: 1.188152 | Training constraint: -393.664032, duals [0.01]| lrm: 0.348191| num_tokens: 3,893
Step 02019/03096 | Training loss: 1.129442 | Training constraint: -371.611664, duals [0.01]| lrm: 0.347868| num_tokens: 2,420
Step 02020/03096 | Training loss: 1.117082 | Training constraint: -296.741852, duals [0.01]| lrm: 0.347545| num_tokens: 4,676
Step 02021/03096 | Training loss: 1.135723 | Training constraint: -385.567200, duals [0.01]| lrm: 0.347222| num_tokens: 5,835
Step 02022/03096 | Training loss: 1.034953 | Training constraint: -317.907898, duals [0.01]| lrm: 0.346899| num_tokens: 4,888
Step 02023/03096 | Training loss: 0.983707 | Training constraint: -341.041809, duals [0.01]| lrm: 0.346576| num_tokens: 2,540
Step 02024/03096 | Training loss: 1.018494 | Training constraint: -322.130280, duals [0.01]| lrm: 0.346253| num_tokens: 2,660
Step 02025/03096 | Training loss: 1.093074 | Training constraint: -383.580048, duals [0.01]| lrm: 0.345930| num_tokens: 3,651
Step 02026/03096 | Training loss: 1.124104 | Training constraint: -293.538208, duals [0.01]| lrm: 0.345607| num_tokens: 3,196
Step 02027/03096 | Training loss: 1.013255 | Training constraint: -207.115433, duals [0.01]| lrm: 0.345284| num_tokens: 4,075
Step 02028/03096 | Training loss: 1.254742 | Training constraint: -437.248688, duals [0.01]| lrm: 0.344961| num_tokens: 4,432
Step 02029/03096 | Training loss: 0.963624 | Training constraint: -297.829346, duals [0.01]| lrm: 0.344638| num_tokens: 3,580
Step 02030/03096 | Training loss: 0.934625 | Training constraint: -467.557861, duals [0.01]| lrm: 0.344315| num_tokens: 1,893
Step 02031/03096 | Training loss: 0.944348 | Training constraint: -290.405060, duals [0.01]| lrm: 0.343992| num_tokens: 3,128
Step 02032/03096 | Training loss: 0.918048 | Training constraint: -282.507812, duals [0.01]| lrm: 0.343669| num_tokens: 3,400
Step 02033/03096 | Training loss: 0.838779 | Training constraint: -456.434143, duals [0.01]| lrm: 0.343346| num_tokens: 4,528
Step 02034/03096 | Training loss: 1.126674 | Training constraint: -367.290039, duals [0.01]| lrm: 0.343023| num_tokens: 5,170
Step 02035/03096 | Training loss: 1.035526 | Training constraint: -336.510162, duals [0.01]| lrm: 0.342700| num_tokens: 2,160
Step 02036/03096 | Training loss: 1.161379 | Training constraint: -377.024597, duals [0.01]| lrm: 0.342377| num_tokens: 4,074
Step 02037/03096 | Training loss: 0.929386 | Training constraint: -330.610535, duals [0.01]| lrm: 0.342054| num_tokens: 3,839
Step 02038/03096 | Training loss: 1.189707 | Training constraint: -457.127869, duals [0.01]| lrm: 0.341731| num_tokens: 3,612
Step 02039/03096 | Training loss: 1.010308 | Training constraint: -395.854034, duals [0.01]| lrm: 0.341408| num_tokens: 4,254
Step 02040/03096 | Training loss: 1.041277 | Training constraint: -276.022888, duals [0.01]| lrm: 0.341085| num_tokens: 3,973
Step 02041/03096 | Training loss: 1.156784 | Training constraint: -398.002869, duals [0.01]| lrm: 0.340762| num_tokens: 2,108
Step 02042/03096 | Training loss: 0.997624 | Training constraint: -243.784973, duals [0.01]| lrm: 0.340439| num_tokens: 3,670
Step 02043/03096 | Training loss: 0.990095 | Training constraint: -333.693451, duals [0.01]| lrm: 0.340116| num_tokens: 2,538
Step 02044/03096 | Training loss: 0.976360 | Training constraint: -205.213821, duals [0.01]| lrm: 0.339793| num_tokens: 5,720
Step 02045/03096 | Training loss: 0.905730 | Training constraint: -399.723511, duals [0.01]| lrm: 0.339470| num_tokens: 5,928
Step 02046/03096 | Training loss: 1.192070 | Training constraint: -285.846161, duals [0.01]| lrm: 0.339147| num_tokens: 4,713
Step 02047/03096 | Training loss: 0.907874 | Training constraint: -250.009308, duals [0.01]| lrm: 0.338824| num_tokens: 3,990
Step 02048/03096 | Training loss: 1.135630 | Training constraint: -337.713196, duals [0.01]| lrm: 0.338501| num_tokens: 6,206
Step 02049/03096 | Training loss: 1.230089 | Training constraint: -393.328369, duals [0.01]| lrm: 0.338178| num_tokens: 3,202
Step 02050/03096 | Training loss: 1.006348 | Training constraint: -373.751862, duals [0.01]| lrm: 0.337855| num_tokens: 2,812
Step 02051/03096 | Training loss: 1.206524 | Training constraint: -544.626282, duals [0.01]| lrm: 0.337532| num_tokens: 1,774
Step 02052/03096 | Training loss: 0.926681 | Training constraint: -321.623169, duals [0.01]| lrm: 0.337209| num_tokens: 3,608
Step 02053/03096 | Training loss: 0.807871 | Training constraint: -370.162415, duals [0.01]| lrm: 0.336886| num_tokens: 2,932
Step 02054/03096 | Training loss: 0.994333 | Training constraint: -331.560028, duals [0.01]| lrm: 0.336563| num_tokens: 2,459
Step 02055/03096 | Training loss: 1.184565 | Training constraint: -487.420868, duals [0.01]| lrm: 0.336240| num_tokens: 2,648
Step 02056/03096 | Training loss: 1.033643 | Training constraint: -280.126923, duals [0.01]| lrm: 0.335917| num_tokens: 2,871
Step 02057/03096 | Training loss: 1.063494 | Training constraint: -279.014709, duals [0.01]| lrm: 0.335594| num_tokens: 3,296
Step 02058/03096 | Training loss: 1.122567 | Training constraint: -466.564514, duals [0.01]| lrm: 0.335271| num_tokens: 6,530
Step 02059/03096 | Training loss: 1.041715 | Training constraint: -262.364166, duals [0.01]| lrm: 0.334948| num_tokens: 2,091
Step 02060/03096 | Training loss: 0.787044 | Training constraint: -49.134659, duals [0.01]| lrm: 0.334625| num_tokens: 1,961
Step 02061/03096 | Training loss: 1.223968 | Training constraint: -540.281860, duals [0.01]| lrm: 0.334302| num_tokens: 3,389
Step 02062/03096 | Training loss: 1.160535 | Training constraint: -283.751007, duals [0.01]| lrm: 0.333979| num_tokens: 5,606
Step 02063/03096 | Training loss: 1.132944 | Training constraint: -373.451141, duals [0.01]| lrm: 0.333656| num_tokens: 4,641
Step 02064/03096 | Training loss: 0.856384 | Training constraint: -336.188538, duals [0.01]| lrm: 0.333333| num_tokens: 2,040
Step 02065/03096 | Training loss: 0.843471 | Training constraint: -237.475998, duals [0.01]| lrm: 0.333010| num_tokens: 3,143
Step 02066/03096 | Training loss: 1.069571 | Training constraint: -297.784210, duals [0.01]| lrm: 0.332687| num_tokens: 2,610
Step 02067/03096 | Training loss: 1.073264 | Training constraint: -377.966858, duals [0.01]| lrm: 0.332364| num_tokens: 3,540
Step 02068/03096 | Training loss: 0.818740 | Training constraint: -237.176056, duals [0.01]| lrm: 0.332041| num_tokens: 6,517
Step 02069/03096 | Training loss: 1.009962 | Training constraint: -584.629517, duals [0.01]| lrm: 0.331718| num_tokens: 3,508
Step 02070/03096 | Training loss: 1.333832 | Training constraint: -339.962616, duals [0.01]| lrm: 0.331395| num_tokens: 6,477
Step 02071/03096 | Training loss: 1.143400 | Training constraint: -310.625122, duals [0.01]| lrm: 0.331072| num_tokens: 1,846
Step 02072/03096 | Training loss: 0.853496 | Training constraint: -161.214401, duals [0.01]| lrm: 0.330749| num_tokens: 3,504
Step 02073/03096 | Training loss: 1.017750 | Training constraint: -493.959167, duals [0.01]| lrm: 0.330426| num_tokens: 3,522
Step 02074/03096 | Training loss: 0.930735 | Training constraint: -338.670776, duals [0.01]| lrm: 0.330103| num_tokens: 3,411
Step 02075/03096 | Training loss: 1.037657 | Training constraint: -288.703369, duals [0.01]| lrm: 0.329780| num_tokens: 2,921
Step 02076/03096 | Training loss: 1.044443 | Training constraint: -368.815491, duals [0.01]| lrm: 0.329457| num_tokens: 2,551
Step 02077/03096 | Training loss: 0.888688 | Training constraint: -318.125610, duals [0.01]| lrm: 0.329134| num_tokens: 1,691
Step 02078/03096 | Training loss: 1.044802 | Training constraint: -286.954956, duals [0.01]| lrm: 0.328811| num_tokens: 2,919
Step 02079/03096 | Training loss: 1.095164 | Training constraint: -429.099457, duals [0.01]| lrm: 0.328488| num_tokens: 2,064
Step 02080/03096 | Training loss: 1.176508 | Training constraint: -454.968231, duals [0.01]| lrm: 0.328165| num_tokens: 3,291
Step 02081/03096 | Training loss: 1.115493 | Training constraint: -310.441620, duals [0.01]| lrm: 0.327842| num_tokens: 3,266
Step 02082/03096 | Training loss: 1.090775 | Training constraint: -505.655975, duals [0.01]| lrm: 0.327519| num_tokens: 656
Step 02083/03096 | Training loss: 0.985302 | Training constraint: -447.197144, duals [0.01]| lrm: 0.327196| num_tokens: 2,530
Step 02084/03096 | Training loss: 0.959794 | Training constraint: -280.773865, duals [0.01]| lrm: 0.326873| num_tokens: 3,976
Step 02085/03096 | Training loss: 0.932396 | Training constraint: -335.249786, duals [0.01]| lrm: 0.326550| num_tokens: 4,448
Step 02086/03096 | Training loss: 0.724748 | Training constraint: -272.909058, duals [0.01]| lrm: 0.326227| num_tokens: 3,590
Step 02087/03096 | Training loss: 1.006951 | Training constraint: -358.523804, duals [0.01]| lrm: 0.325904| num_tokens: 3,964
Step 02088/03096 | Training loss: 1.181009 | Training constraint: -550.648804, duals [0.01]| lrm: 0.325581| num_tokens: 3,328
Step 02089/03096 | Training loss: 0.970645 | Training constraint: -255.922302, duals [0.01]| lrm: 0.325258| num_tokens: 3,868
Step 02090/03096 | Training loss: 0.995198 | Training constraint: -587.642212, duals [0.01]| lrm: 0.324935| num_tokens: 3,444
Step 02091/03096 | Training loss: 0.889086 | Training constraint: -362.152344, duals [0.01]| lrm: 0.324612| num_tokens: 3,916
Step 02092/03096 | Training loss: 0.801461 | Training constraint: -316.282562, duals [0.01]| lrm: 0.324289| num_tokens: 3,000
Step 02093/03096 | Training loss: 1.061054 | Training constraint: -246.903931, duals [0.01]| lrm: 0.323966| num_tokens: 4,094
Step 02094/03096 | Training loss: 0.976015 | Training constraint: -483.952820, duals [0.01]| lrm: 0.323643| num_tokens: 4,737
Step 02095/03096 | Training loss: 0.941953 | Training constraint: -304.521790, duals [0.01]| lrm: 0.323320| num_tokens: 3,001
Step 02096/03096 | Training loss: 1.200963 | Training constraint: -535.118652, duals [0.01]| lrm: 0.322997| num_tokens: 5,923
Step 02097/03096 | Training loss: 0.820558 | Training constraint: -381.929382, duals [0.01]| lrm: 0.322674| num_tokens: 3,319
Step 02098/03096 | Training loss: 1.016092 | Training constraint: -267.946106, duals [0.01]| lrm: 0.322351| num_tokens: 2,519
Step 02099/03096 | Training loss: 0.977918 | Training constraint: -307.912689, duals [0.01]| lrm: 0.322028| num_tokens: 3,698
Step 02100 | Validation loss: 1.169436
Step 02100/03096 | Training loss: 0.967756 | Training constraint: -264.652435, duals [0.01]| lrm: 0.321705| num_tokens: 3,954
Step 02101/03096 | Training loss: 0.672443 | Training constraint: -309.236725, duals [0.01]| lrm: 0.321382| num_tokens: 2,792
Step 02102/03096 | Training loss: 1.120167 | Training constraint: -288.011688, duals [0.01]| lrm: 0.321059| num_tokens: 2,007
Step 02103/03096 | Training loss: 0.897551 | Training constraint: -255.947021, duals [0.01]| lrm: 0.320736| num_tokens: 4,276
Step 02104/03096 | Training loss: 0.965060 | Training constraint: -330.467377, duals [0.01]| lrm: 0.320413| num_tokens: 3,830
Step 02105/03096 | Training loss: 1.108893 | Training constraint: -264.249176, duals [0.01]| lrm: 0.320090| num_tokens: 2,609
Step 02106/03096 | Training loss: 1.117783 | Training constraint: -425.360382, duals [0.01]| lrm: 0.319767| num_tokens: 2,615
Step 02107/03096 | Training loss: 1.133066 | Training constraint: -329.448364, duals [0.01]| lrm: 0.319444| num_tokens: 3,537
Step 02108/03096 | Training loss: 1.131011 | Training constraint: -324.354309, duals [0.01]| lrm: 0.319121| num_tokens: 4,271
Step 02109/03096 | Training loss: 1.078616 | Training constraint: -243.788177, duals [0.01]| lrm: 0.318798| num_tokens: 3,074
Step 02110/03096 | Training loss: 0.697806 | Training constraint: -337.527679, duals [0.01]| lrm: 0.318475| num_tokens: 1,475
Step 02111/03096 | Training loss: 1.037824 | Training constraint: -444.588226, duals [0.01]| lrm: 0.318152| num_tokens: 4,394
Step 02112/03096 | Training loss: 0.950774 | Training constraint: -247.036774, duals [0.01]| lrm: 0.317829| num_tokens: 4,659
Step 02113/03096 | Training loss: 1.125852 | Training constraint: -335.549500, duals [0.01]| lrm: 0.317506| num_tokens: 2,900
Step 02114/03096 | Training loss: 1.006030 | Training constraint: -203.886383, duals [0.01]| lrm: 0.317183| num_tokens: 3,837
Step 02115/03096 | Training loss: 0.990480 | Training constraint: -370.488739, duals [0.01]| lrm: 0.316860| num_tokens: 1,343
Step 02116/03096 | Training loss: 1.348722 | Training constraint: -234.223648, duals [0.01]| lrm: 0.316537| num_tokens: 1,719
Step 02117/03096 | Training loss: 0.993050 | Training constraint: -221.681488, duals [0.01]| lrm: 0.316214| num_tokens: 5,297
Step 02118/03096 | Training loss: 1.032004 | Training constraint: -242.957397, duals [0.01]| lrm: 0.315891| num_tokens: 1,669
Step 02119/03096 | Training loss: 1.055208 | Training constraint: -232.596344, duals [0.01]| lrm: 0.315568| num_tokens: 2,484
Step 02120/03096 | Training loss: 1.086398 | Training constraint: -403.932709, duals [0.01]| lrm: 0.315245| num_tokens: 4,948
Step 02121/03096 | Training loss: 0.889786 | Training constraint: -472.636292, duals [0.01]| lrm: 0.314922| num_tokens: 2,018
Step 02122/03096 | Training loss: 0.961617 | Training constraint: -359.890747, duals [0.01]| lrm: 0.314599| num_tokens: 3,498
Step 02123/03096 | Training loss: 1.304572 | Training constraint: -353.772461, duals [0.01]| lrm: 0.314276| num_tokens: 2,414
Step 02124/03096 | Training loss: 0.972304 | Training constraint: -391.484833, duals [0.01]| lrm: 0.313953| num_tokens: 4,617
Step 02125/03096 | Training loss: 1.072932 | Training constraint: -306.477325, duals [0.01]| lrm: 0.313630| num_tokens: 3,246
Step 02126/03096 | Training loss: 1.156629 | Training constraint: -350.149994, duals [0.01]| lrm: 0.313307| num_tokens: 3,870
Step 02127/03096 | Training loss: 1.076436 | Training constraint: -311.075378, duals [0.01]| lrm: 0.312984| num_tokens: 2,720
Step 02128/03096 | Training loss: 0.897637 | Training constraint: -382.626801, duals [0.01]| lrm: 0.312661| num_tokens: 1,261
Step 02129/03096 | Training loss: 0.826375 | Training constraint: -273.161194, duals [0.01]| lrm: 0.312339| num_tokens: 1,006
Step 02130/03096 | Training loss: 0.769396 | Training constraint: -276.715637, duals [0.01]| lrm: 0.312016| num_tokens: 2,672
Step 02131/03096 | Training loss: 0.791399 | Training constraint: -421.106079, duals [0.01]| lrm: 0.311693| num_tokens: 3,842
Step 02132/03096 | Training loss: 0.992388 | Training constraint: -322.092957, duals [0.01]| lrm: 0.311370| num_tokens: 4,892
Step 02133/03096 | Training loss: 1.082636 | Training constraint: -231.441925, duals [0.01]| lrm: 0.311047| num_tokens: 4,724
Step 02134/03096 | Training loss: 0.993035 | Training constraint: -252.623123, duals [0.01]| lrm: 0.310724| num_tokens: 4,146
Step 02135/03096 | Training loss: 1.062394 | Training constraint: -266.817780, duals [0.01]| lrm: 0.310401| num_tokens: 2,231
Step 02136/03096 | Training loss: 1.090963 | Training constraint: -226.287674, duals [0.01]| lrm: 0.310078| num_tokens: 4,752
Step 02137/03096 | Training loss: 0.748823 | Training constraint: -299.046265, duals [0.01]| lrm: 0.309755| num_tokens: 5,967
Step 02138/03096 | Training loss: 1.012726 | Training constraint: -201.576431, duals [0.01]| lrm: 0.309432| num_tokens: 3,451
Step 02139/03096 | Training loss: 0.910278 | Training constraint: -334.596222, duals [0.01]| lrm: 0.309109| num_tokens: 1,495
Step 02140/03096 | Training loss: 1.124507 | Training constraint: -233.813950, duals [0.01]| lrm: 0.308786| num_tokens: 5,852
Step 02141/03096 | Training loss: 0.842614 | Training constraint: -306.843231, duals [0.01]| lrm: 0.308463| num_tokens: 2,791
Step 02142/03096 | Training loss: 0.896979 | Training constraint: -447.233398, duals [0.01]| lrm: 0.308140| num_tokens: 2,408
Step 02143/03096 | Training loss: 1.106088 | Training constraint: -414.918396, duals [0.01]| lrm: 0.307817| num_tokens: 4,518
Step 02144/03096 | Training loss: 0.919639 | Training constraint: -175.924316, duals [0.01]| lrm: 0.307494| num_tokens: 1,778
Step 02145/03096 | Training loss: 1.068931 | Training constraint: -360.649353, duals [0.01]| lrm: 0.307171| num_tokens: 4,005
Step 02146/03096 | Training loss: 1.188646 | Training constraint: -222.593018, duals [0.01]| lrm: 0.306848| num_tokens: 1,919
Step 02147/03096 | Training loss: 1.065448 | Training constraint: -253.736023, duals [0.01]| lrm: 0.306525| num_tokens: 3,351
Step 02148/03096 | Training loss: 0.710935 | Training constraint: -234.215256, duals [0.01]| lrm: 0.306202| num_tokens: 5,502
Step 02149/03096 | Training loss: 0.880193 | Training constraint: -169.739670, duals [0.01]| lrm: 0.305879| num_tokens: 2,404
Step 02150/03096 | Training loss: 0.902533 | Training constraint: -323.796417, duals [0.01]| lrm: 0.305556| num_tokens: 2,400
Step 02151/03096 | Training loss: 1.027090 | Training constraint: -287.725952, duals [0.01]| lrm: 0.305233| num_tokens: 3,948
Step 02152/03096 | Training loss: 1.062999 | Training constraint: -280.824677, duals [0.01]| lrm: 0.304910| num_tokens: 3,506
Step 02153/03096 | Training loss: 1.094503 | Training constraint: -209.411774, duals [0.01]| lrm: 0.304587| num_tokens: 2,551
Step 02154/03096 | Training loss: 0.900177 | Training constraint: -422.717438, duals [0.01]| lrm: 0.304264| num_tokens: 2,691
Step 02155/03096 | Training loss: 0.889640 | Training constraint: -325.252258, duals [0.01]| lrm: 0.303941| num_tokens: 3,402
Step 02156/03096 | Training loss: 0.874153 | Training constraint: -171.263794, duals [0.01]| lrm: 0.303618| num_tokens: 3,066
Step 02157/03096 | Training loss: 0.803164 | Training constraint: -609.337524, duals [0.01]| lrm: 0.303295| num_tokens: 4,471
Step 02158/03096 | Training loss: 0.612329 | Training constraint: -405.747986, duals [0.01]| lrm: 0.302972| num_tokens: 3,697
Step 02159/03096 | Training loss: 1.079955 | Training constraint: -247.949631, duals [0.01]| lrm: 0.302649| num_tokens: 4,844
Step 02160/03096 | Training loss: 0.896843 | Training constraint: -264.142334, duals [0.01]| lrm: 0.302326| num_tokens: 4,434
Step 02161/03096 | Training loss: 1.395465 | Training constraint: -165.445297, duals [0.01]| lrm: 0.302003| num_tokens: 1,595
Step 02162/03096 | Training loss: 0.774100 | Training constraint: -355.740662, duals [0.01]| lrm: 0.301680| num_tokens: 3,621
Step 02163/03096 | Training loss: 1.066613 | Training constraint: -304.027039, duals [0.01]| lrm: 0.301357| num_tokens: 3,344
Step 02164/03096 | Training loss: 1.173524 | Training constraint: -391.764954, duals [0.01]| lrm: 0.301034| num_tokens: 4,574
Step 02165/03096 | Training loss: 0.813650 | Training constraint: -240.397995, duals [0.01]| lrm: 0.300711| num_tokens: 2,591
Step 02166/03096 | Training loss: 1.093190 | Training constraint: -428.772919, duals [0.01]| lrm: 0.300388| num_tokens: 1,410
Step 02167/03096 | Training loss: 1.017143 | Training constraint: -276.656708, duals [0.01]| lrm: 0.300065| num_tokens: 4,322
Step 02168/03096 | Training loss: 0.888754 | Training constraint: -415.774475, duals [0.01]| lrm: 0.299742| num_tokens: 2,810
Step 02169/03096 | Training loss: 1.039172 | Training constraint: -272.463531, duals [0.01]| lrm: 0.299419| num_tokens: 3,282
Step 02170/03096 | Training loss: 0.969460 | Training constraint: -351.184937, duals [0.01]| lrm: 0.299096| num_tokens: 2,031
Step 02171/03096 | Training loss: 0.962341 | Training constraint: -274.077515, duals [0.01]| lrm: 0.298773| num_tokens: 1,110
Step 02172/03096 | Training loss: 0.896049 | Training constraint: -406.456543, duals [0.01]| lrm: 0.298450| num_tokens: 1,826
Step 02173/03096 | Training loss: 0.968458 | Training constraint: -299.680725, duals [0.01]| lrm: 0.298127| num_tokens: 2,798
Step 02174/03096 | Training loss: 1.093714 | Training constraint: -428.939667, duals [0.01]| lrm: 0.297804| num_tokens: 5,129
Step 02175/03096 | Training loss: 1.196956 | Training constraint: -234.208038, duals [0.01]| lrm: 0.297481| num_tokens: 1,717
Step 02176/03096 | Training loss: 0.883802 | Training constraint: -168.911774, duals [0.01]| lrm: 0.297158| num_tokens: 5,967
Step 02177/03096 | Training loss: 0.887097 | Training constraint: -282.244019, duals [0.01]| lrm: 0.296835| num_tokens: 2,690
Step 02178/03096 | Training loss: 1.066644 | Training constraint: -328.641235, duals [0.01]| lrm: 0.296512| num_tokens: 3,744
Step 02179/03096 | Training loss: 0.801522 | Training constraint: -232.294373, duals [0.01]| lrm: 0.296189| num_tokens: 2,892
Step 02180/03096 | Training loss: 1.048400 | Training constraint: -178.393097, duals [0.01]| lrm: 0.295866| num_tokens: 4,837
Step 02181/03096 | Training loss: 1.147762 | Training constraint: -596.968750, duals [0.01]| lrm: 0.295543| num_tokens: 3,534
Step 02182/03096 | Training loss: 1.126815 | Training constraint: -414.019592, duals [0.01]| lrm: 0.295220| num_tokens: 2,089
Step 02183/03096 | Training loss: 1.172003 | Training constraint: -302.928436, duals [0.01]| lrm: 0.294897| num_tokens: 2,610
Step 02184/03096 | Training loss: 1.192798 | Training constraint: -489.382935, duals [0.01]| lrm: 0.294574| num_tokens: 4,506
Step 02185/03096 | Training loss: 0.896646 | Training constraint: -354.516846, duals [0.01]| lrm: 0.294251| num_tokens: 2,363
Step 02186/03096 | Training loss: 1.206282 | Training constraint: -344.594788, duals [0.01]| lrm: 0.293928| num_tokens: 1,908
Step 02187/03096 | Training loss: 1.019771 | Training constraint: -310.273132, duals [0.01]| lrm: 0.293605| num_tokens: 3,157
Step 02188/03096 | Training loss: 1.024835 | Training constraint: -177.427368, duals [0.01]| lrm: 0.293282| num_tokens: 2,008
Step 02189/03096 | Training loss: 1.101698 | Training constraint: -342.284393, duals [0.01]| lrm: 0.292959| num_tokens: 2,155
Step 02190/03096 | Training loss: 1.045224 | Training constraint: -283.234741, duals [0.01]| lrm: 0.292636| num_tokens: 5,024
Step 02191/03096 | Training loss: 0.641833 | Training constraint: -478.048065, duals [0.01]| lrm: 0.292313| num_tokens: 3,610
Step 02192/03096 | Training loss: 0.857280 | Training constraint: -306.345947, duals [0.01]| lrm: 0.291990| num_tokens: 4,030
Step 02193/03096 | Training loss: 0.956167 | Training constraint: -396.221008, duals [0.01]| lrm: 0.291667| num_tokens: 4,329
Step 02194/03096 | Training loss: 1.056766 | Training constraint: -491.860565, duals [0.01]| lrm: 0.291344| num_tokens: 2,444
Step 02195/03096 | Training loss: 1.216600 | Training constraint: -407.282684, duals [0.01]| lrm: 0.291021| num_tokens: 3,310
Step 02196/03096 | Training loss: 1.383573 | Training constraint: -397.870789, duals [0.01]| lrm: 0.290698| num_tokens: 4,266
Step 02197/03096 | Training loss: 0.973958 | Training constraint: -256.469421, duals [0.01]| lrm: 0.290375| num_tokens: 1,024
Step 02198/03096 | Training loss: 0.902022 | Training constraint: -157.637192, duals [0.01]| lrm: 0.290052| num_tokens: 1,675
Step 02199/03096 | Training loss: 0.842100 | Training constraint: -310.261475, duals [0.01]| lrm: 0.289729| num_tokens: 3,223
Step 02200 | Validation loss: 1.170298
2026-01-21 14:17:57,464 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:17:57,469 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:17:57,495 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:17:57,500 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:17:57,587 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:57,613 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:57,930 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:57,953 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:58,127 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:17:58,145 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:17:58,274 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:17:58,292 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 308/1024 (30.08%)
2026-01-21 14:17:58,879 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:17:58,884 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:17:58,896 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:17:58,900 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:17:58,998 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:59,016 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:59,115 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:59,134 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:17:59,230 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:17:59,250 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:17:59,355 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:17:59,376 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:17:59,469 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:17:59,492 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 353/1024 (34.47%)
Step 02200 | mmlu_acc: 0.300781, arc_easy_acc: 0.344727
Step 02200/03096 | Training loss: 1.063057 | Training constraint: -294.822754, duals [0.01]| lrm: 0.289406| num_tokens: 2,240
Step 02201/03096 | Training loss: 0.907489 | Training constraint: -283.652039, duals [0.01]| lrm: 0.289083| num_tokens: 3,394
Step 02202/03096 | Training loss: 0.980751 | Training constraint: -381.221039, duals [0.01]| lrm: 0.288760| num_tokens: 3,951
Step 02203/03096 | Training loss: 0.866582 | Training constraint: -320.429230, duals [0.01]| lrm: 0.288437| num_tokens: 2,693
Step 02204/03096 | Training loss: 0.927547 | Training constraint: -426.209930, duals [0.01]| lrm: 0.288114| num_tokens: 2,395
Step 02205/03096 | Training loss: 1.090293 | Training constraint: -293.042938, duals [0.01]| lrm: 0.287791| num_tokens: 6,607
Step 02206/03096 | Training loss: 0.746168 | Training constraint: -417.360992, duals [0.01]| lrm: 0.287468| num_tokens: 2,855
Step 02207/03096 | Training loss: 0.924378 | Training constraint: -317.739014, duals [0.01]| lrm: 0.287145| num_tokens: 2,687
Step 02208/03096 | Training loss: 0.883979 | Training constraint: -283.339142, duals [0.01]| lrm: 0.286822| num_tokens: 3,318
Step 02209/03096 | Training loss: 1.088893 | Training constraint: -404.003662, duals [0.01]| lrm: 0.286499| num_tokens: 4,060
Step 02210/03096 | Training loss: 0.962046 | Training constraint: -476.535522, duals [0.01]| lrm: 0.286176| num_tokens: 4,225
Step 02211/03096 | Training loss: 0.997246 | Training constraint: -335.756897, duals [0.01]| lrm: 0.285853| num_tokens: 2,966
Step 02212/03096 | Training loss: 1.072527 | Training constraint: -269.314545, duals [0.01]| lrm: 0.285530| num_tokens: 4,961
Step 02213/03096 | Training loss: 1.094862 | Training constraint: -431.056946, duals [0.01]| lrm: 0.285207| num_tokens: 4,041
Step 02214/03096 | Training loss: 1.113400 | Training constraint: -489.532715, duals [0.01]| lrm: 0.284884| num_tokens: 2,913
Step 02215/03096 | Training loss: 0.840254 | Training constraint: -173.582474, duals [0.01]| lrm: 0.284561| num_tokens: 1,981
Step 02216/03096 | Training loss: 0.874834 | Training constraint: -250.383102, duals [0.01]| lrm: 0.284238| num_tokens: 4,480
Step 02217/03096 | Training loss: 1.056414 | Training constraint: -424.178925, duals [0.01]| lrm: 0.283915| num_tokens: 960
Step 02218/03096 | Training loss: 0.973422 | Training constraint: -280.646332, duals [0.01]| lrm: 0.283592| num_tokens: 2,681
Step 02219/03096 | Training loss: 0.892036 | Training constraint: -198.163437, duals [0.01]| lrm: 0.283269| num_tokens: 3,574
Step 02220/03096 | Training loss: 1.036095 | Training constraint: -306.884766, duals [0.01]| lrm: 0.282946| num_tokens: 4,691
Step 02221/03096 | Training loss: 1.273095 | Training constraint: -330.798492, duals [0.01]| lrm: 0.282623| num_tokens: 2,519
Step 02222/03096 | Training loss: 1.069515 | Training constraint: -336.260284, duals [0.01]| lrm: 0.282300| num_tokens: 4,486
Step 02223/03096 | Training loss: 1.226637 | Training constraint: -384.219788, duals [0.01]| lrm: 0.281977| num_tokens: 4,472
Step 02224/03096 | Training loss: 0.956422 | Training constraint: -413.211609, duals [0.01]| lrm: 0.281654| num_tokens: 827
Step 02225/03096 | Training loss: 1.015934 | Training constraint: -327.176514, duals [0.01]| lrm: 0.281331| num_tokens: 2,690
Step 02226/03096 | Training loss: 0.891965 | Training constraint: -219.154144, duals [0.01]| lrm: 0.281008| num_tokens: 3,370
Step 02227/03096 | Training loss: 0.895288 | Training constraint: -290.906219, duals [0.01]| lrm: 0.280685| num_tokens: 1,781
Step 02228/03096 | Training loss: 0.780597 | Training constraint: -462.053009, duals [0.01]| lrm: 0.280362| num_tokens: 3,660
Step 02229/03096 | Training loss: 1.005284 | Training constraint: -394.868835, duals [0.01]| lrm: 0.280039| num_tokens: 3,693
Step 02230/03096 | Training loss: 1.191508 | Training constraint: -240.548447, duals [0.01]| lrm: 0.279716| num_tokens: 3,835
Step 02231/03096 | Training loss: 0.869918 | Training constraint: -256.113342, duals [0.01]| lrm: 0.279393| num_tokens: 2,298
Step 02232/03096 | Training loss: 0.886049 | Training constraint: -189.896729, duals [0.01]| lrm: 0.279070| num_tokens: 2,162
Step 02233/03096 | Training loss: 1.015852 | Training constraint: -309.124237, duals [0.01]| lrm: 0.278747| num_tokens: 2,771
Step 02234/03096 | Training loss: 1.004882 | Training constraint: -339.071808, duals [0.01]| lrm: 0.278424| num_tokens: 2,162
Step 02235/03096 | Training loss: 0.959310 | Training constraint: -356.463318, duals [0.01]| lrm: 0.278101| num_tokens: 2,627
Step 02236/03096 | Training loss: 1.003059 | Training constraint: -255.226501, duals [0.01]| lrm: 0.277778| num_tokens: 3,797
Step 02237/03096 | Training loss: 0.723758 | Training constraint: -587.029236, duals [0.01]| lrm: 0.277455| num_tokens: 2,410
Step 02238/03096 | Training loss: 1.036851 | Training constraint: -199.567993, duals [0.01]| lrm: 0.277132| num_tokens: 3,087
Step 02239/03096 | Training loss: 1.164181 | Training constraint: -254.265381, duals [0.01]| lrm: 0.276809| num_tokens: 2,655
Step 02240/03096 | Training loss: 1.085081 | Training constraint: -232.836090, duals [0.01]| lrm: 0.276486| num_tokens: 4,086
Step 02241/03096 | Training loss: 0.910511 | Training constraint: -325.200226, duals [0.01]| lrm: 0.276163| num_tokens: 3,501
Step 02242/03096 | Training loss: 1.046558 | Training constraint: -398.351868, duals [0.01]| lrm: 0.275840| num_tokens: 3,174
Step 02243/03096 | Training loss: 0.804345 | Training constraint: -224.758728, duals [0.01]| lrm: 0.275517| num_tokens: 2,590
Step 02244/03096 | Training loss: 0.857455 | Training constraint: -246.201096, duals [0.01]| lrm: 0.275194| num_tokens: 3,984
Step 02245/03096 | Training loss: 0.795480 | Training constraint: -234.890442, duals [0.01]| lrm: 0.274871| num_tokens: 3,087
Step 02246/03096 | Training loss: 1.125848 | Training constraint: -472.740204, duals [0.01]| lrm: 0.274548| num_tokens: 3,864
Step 02247/03096 | Training loss: 0.954720 | Training constraint: -256.531311, duals [0.01]| lrm: 0.274225| num_tokens: 2,830
Step 02248/03096 | Training loss: 1.051194 | Training constraint: -257.611816, duals [0.01]| lrm: 0.273902| num_tokens: 3,516
Step 02249/03096 | Training loss: 1.110512 | Training constraint: -225.524750, duals [0.01]| lrm: 0.273579| num_tokens: 4,115
Step 02250/03096 | Training loss: 0.876181 | Training constraint: -525.976685, duals [0.01]| lrm: 0.273256| num_tokens: 2,542
Step 02251/03096 | Training loss: 0.727421 | Training constraint: -233.006226, duals [0.01]| lrm: 0.272933| num_tokens: 2,656
Step 02252/03096 | Training loss: 1.048128 | Training constraint: -466.642456, duals [0.01]| lrm: 0.272610| num_tokens: 3,902
Step 02253/03096 | Training loss: 0.553198 | Training constraint: -349.012634, duals [0.01]| lrm: 0.272287| num_tokens: 5,682
Step 02254/03096 | Training loss: 1.135220 | Training constraint: -452.998657, duals [0.01]| lrm: 0.271964| num_tokens: 3,803
Step 02255/03096 | Training loss: 1.188521 | Training constraint: -352.633148, duals [0.01]| lrm: 0.271641| num_tokens: 2,537
Step 02256/03096 | Training loss: 1.103688 | Training constraint: -432.409607, duals [0.01]| lrm: 0.271318| num_tokens: 4,007
Step 02257/03096 | Training loss: 1.203064 | Training constraint: -304.893066, duals [0.01]| lrm: 0.270995| num_tokens: 3,195
Step 02258/03096 | Training loss: 1.030244 | Training constraint: -328.234070, duals [0.01]| lrm: 0.270672| num_tokens: 5,264
Step 02259/03096 | Training loss: 0.961843 | Training constraint: -337.507721, duals [0.01]| lrm: 0.270349| num_tokens: 2,265
Step 02260/03096 | Training loss: 0.801490 | Training constraint: -531.762695, duals [0.01]| lrm: 0.270026| num_tokens: 2,354
Step 02261/03096 | Training loss: 0.986422 | Training constraint: -497.676880, duals [0.01]| lrm: 0.269703| num_tokens: 3,588
Step 02262/03096 | Training loss: 1.292098 | Training constraint: -258.094208, duals [0.01]| lrm: 0.269380| num_tokens: 1,452
Step 02263/03096 | Training loss: 1.057524 | Training constraint: -424.619019, duals [0.01]| lrm: 0.269057| num_tokens: 2,837
Step 02264/03096 | Training loss: 1.023343 | Training constraint: -183.163940, duals [0.01]| lrm: 0.268734| num_tokens: 5,746
Step 02265/03096 | Training loss: 1.088648 | Training constraint: -465.563690, duals [0.01]| lrm: 0.268411| num_tokens: 2,543
Step 02266/03096 | Training loss: 0.753385 | Training constraint: -199.958725, duals [0.01]| lrm: 0.268088| num_tokens: 3,341
Step 02267/03096 | Training loss: 0.884942 | Training constraint: -358.117126, duals [0.01]| lrm: 0.267765| num_tokens: 3,101
Step 02268/03096 | Training loss: 1.046155 | Training constraint: -314.625610, duals [0.01]| lrm: 0.267442| num_tokens: 2,566
Step 02269/03096 | Training loss: 1.115138 | Training constraint: -510.122986, duals [0.01]| lrm: 0.267119| num_tokens: 3,357
Step 02270/03096 | Training loss: 1.180551 | Training constraint: -442.313873, duals [0.01]| lrm: 0.266796| num_tokens: 1,612
Step 02271/03096 | Training loss: 1.046738 | Training constraint: -431.310516, duals [0.01]| lrm: 0.266473| num_tokens: 6,144
Step 02272/03096 | Training loss: 1.066419 | Training constraint: -193.140244, duals [0.01]| lrm: 0.266150| num_tokens: 3,781
Step 02273/03096 | Training loss: 1.069875 | Training constraint: -143.558716, duals [0.01]| lrm: 0.265827| num_tokens: 1,466
Step 02274/03096 | Training loss: 0.924804 | Training constraint: -288.810883, duals [0.01]| lrm: 0.265504| num_tokens: 753
Step 02275/03096 | Training loss: 1.142312 | Training constraint: -374.611938, duals [0.01]| lrm: 0.265181| num_tokens: 3,421
Step 02276/03096 | Training loss: 0.975645 | Training constraint: -289.601135, duals [0.01]| lrm: 0.264858| num_tokens: 3,916
Step 02277/03096 | Training loss: 1.145345 | Training constraint: -344.223816, duals [0.01]| lrm: 0.264535| num_tokens: 3,846
Step 02278/03096 | Training loss: 0.820137 | Training constraint: -240.020508, duals [0.01]| lrm: 0.264212| num_tokens: 1,765
Step 02279/03096 | Training loss: 0.957968 | Training constraint: -326.725037, duals [0.01]| lrm: 0.263889| num_tokens: 3,470
Step 02280/03096 | Training loss: 1.032954 | Training constraint: -270.147095, duals [0.01]| lrm: 0.263566| num_tokens: 3,878
Step 02281/03096 | Training loss: 0.772403 | Training constraint: -346.704346, duals [0.01]| lrm: 0.263243| num_tokens: 4,129
Step 02282/03096 | Training loss: 0.990072 | Training constraint: -222.772369, duals [0.01]| lrm: 0.262920| num_tokens: 5,160
Step 02283/03096 | Training loss: 0.993692 | Training constraint: -311.518799, duals [0.01]| lrm: 0.262597| num_tokens: 2,590
Step 02284/03096 | Training loss: 1.043464 | Training constraint: -292.547241, duals [0.01]| lrm: 0.262274| num_tokens: 4,475
Step 02285/03096 | Training loss: 0.991527 | Training constraint: -319.198181, duals [0.01]| lrm: 0.261951| num_tokens: 3,517
Step 02286/03096 | Training loss: 1.153953 | Training constraint: -293.979431, duals [0.01]| lrm: 0.261628| num_tokens: 2,616
Step 02287/03096 | Training loss: 1.088843 | Training constraint: -423.400452, duals [0.01]| lrm: 0.261305| num_tokens: 3,494
Step 02288/03096 | Training loss: 0.943530 | Training constraint: -345.989563, duals [0.01]| lrm: 0.260982| num_tokens: 3,561
Step 02289/03096 | Training loss: 1.081680 | Training constraint: -359.458069, duals [0.01]| lrm: 0.260659| num_tokens: 3,499
Step 02290/03096 | Training loss: 1.070980 | Training constraint: -338.862305, duals [0.01]| lrm: 0.260336| num_tokens: 6,026
Step 02291/03096 | Training loss: 1.060231 | Training constraint: -126.676346, duals [0.01]| lrm: 0.260013| num_tokens: 5,371
Step 02292/03096 | Training loss: 1.099811 | Training constraint: -180.001236, duals [0.01]| lrm: 0.259690| num_tokens: 2,157
Step 02293/03096 | Training loss: 1.141765 | Training constraint: -327.358643, duals [0.01]| lrm: 0.259367| num_tokens: 2,257
Step 02294/03096 | Training loss: 1.070432 | Training constraint: -526.191650, duals [0.01]| lrm: 0.259044| num_tokens: 2,382
Step 02295/03096 | Training loss: 1.224403 | Training constraint: -211.750183, duals [0.01]| lrm: 0.258721| num_tokens: 1,582
Step 02296/03096 | Training loss: 1.185357 | Training constraint: -483.211945, duals [0.01]| lrm: 0.258398| num_tokens: 2,623
Step 02297/03096 | Training loss: 0.910621 | Training constraint: -387.184753, duals [0.01]| lrm: 0.258075| num_tokens: 2,542
Step 02298/03096 | Training loss: 0.842373 | Training constraint: -302.854797, duals [0.01]| lrm: 0.257752| num_tokens: 2,399
Step 02299/03096 | Training loss: 0.818049 | Training constraint: -277.600739, duals [0.01]| lrm: 0.257429| num_tokens: 3,800
Step 02300 | Validation loss: 1.171078
Step 02300/03096 | Training loss: 1.155431 | Training constraint: -358.698822, duals [0.01]| lrm: 0.257106| num_tokens: 5,654
Step 02301/03096 | Training loss: 1.092416 | Training constraint: -502.005280, duals [0.01]| lrm: 0.256783| num_tokens: 3,153
Step 02302/03096 | Training loss: 1.081200 | Training constraint: -309.860291, duals [0.01]| lrm: 0.256460| num_tokens: 3,063
Step 02303/03096 | Training loss: 0.894649 | Training constraint: -495.851990, duals [0.01]| lrm: 0.256137| num_tokens: 4,572
Step 02304/03096 | Training loss: 1.232715 | Training constraint: -151.295486, duals [0.01]| lrm: 0.255814| num_tokens: 2,638
Step 02305/03096 | Training loss: 0.947857 | Training constraint: -227.678085, duals [0.01]| lrm: 0.255491| num_tokens: 4,679
Step 02306/03096 | Training loss: 0.887162 | Training constraint: -269.544952, duals [0.01]| lrm: 0.255168| num_tokens: 1,963
Step 02307/03096 | Training loss: 0.861937 | Training constraint: -166.154541, duals [0.01]| lrm: 0.254845| num_tokens: 2,773
Step 02308/03096 | Training loss: 1.004297 | Training constraint: -394.204773, duals [0.01]| lrm: 0.254522| num_tokens: 2,845
Step 02309/03096 | Training loss: 0.848935 | Training constraint: -396.751434, duals [0.01]| lrm: 0.254199| num_tokens: 3,842
Step 02310/03096 | Training loss: 0.958296 | Training constraint: -450.959595, duals [0.01]| lrm: 0.253876| num_tokens: 4,063
Step 02311/03096 | Training loss: 1.085203 | Training constraint: -516.282104, duals [0.01]| lrm: 0.253553| num_tokens: 2,306
Step 02312/03096 | Training loss: 1.096444 | Training constraint: -378.942139, duals [0.01]| lrm: 0.253230| num_tokens: 3,145
Step 02313/03096 | Training loss: 1.086793 | Training constraint: -302.026733, duals [0.01]| lrm: 0.252907| num_tokens: 4,096
Step 02314/03096 | Training loss: 0.855367 | Training constraint: -494.320038, duals [0.01]| lrm: 0.252584| num_tokens: 3,054
Step 02315/03096 | Training loss: 0.991997 | Training constraint: -153.021881, duals [0.01]| lrm: 0.252261| num_tokens: 3,406
Step 02316/03096 | Training loss: 1.060945 | Training constraint: -217.865967, duals [0.01]| lrm: 0.251938| num_tokens: 3,681
Step 02317/03096 | Training loss: 0.973355 | Training constraint: -354.441895, duals [0.01]| lrm: 0.251615| num_tokens: 3,722
Step 02318/03096 | Training loss: 0.906241 | Training constraint: -318.063171, duals [0.01]| lrm: 0.251292| num_tokens: 5,414
Step 02319/03096 | Training loss: 1.005768 | Training constraint: -286.103699, duals [0.01]| lrm: 0.250969| num_tokens: 5,408
Step 02320/03096 | Training loss: 1.153801 | Training constraint: -298.329346, duals [0.01]| lrm: 0.250646| num_tokens: 5,340
Step 02321/03096 | Training loss: 0.979817 | Training constraint: -371.712585, duals [0.01]| lrm: 0.250323| num_tokens: 3,715
Step 02322/03096 | Training loss: 1.206776 | Training constraint: -191.828339, duals [0.01]| lrm: 0.250000| num_tokens: 3,351
Step 02323/03096 | Training loss: 1.065903 | Training constraint: -304.610352, duals [0.01]| lrm: 0.249677| num_tokens: 3,572
Step 02324/03096 | Training loss: 1.163619 | Training constraint: -501.248535, duals [0.01]| lrm: 0.249354| num_tokens: 2,320
Step 02325/03096 | Training loss: 0.965590 | Training constraint: -305.211121, duals [0.01]| lrm: 0.249031| num_tokens: 1,708
Step 02326/03096 | Training loss: 0.915834 | Training constraint: -496.706360, duals [0.01]| lrm: 0.248708| num_tokens: 2,190
Step 02327/03096 | Training loss: 0.868354 | Training constraint: -288.717010, duals [0.01]| lrm: 0.248385| num_tokens: 3,127
Step 02328/03096 | Training loss: 1.071561 | Training constraint: -238.454239, duals [0.01]| lrm: 0.248062| num_tokens: 1,863
Step 02329/03096 | Training loss: 1.137306 | Training constraint: -439.446838, duals [0.01]| lrm: 0.247739| num_tokens: 3,387
Step 02330/03096 | Training loss: 0.929582 | Training constraint: -434.590210, duals [0.01]| lrm: 0.247416| num_tokens: 3,760
Step 02331/03096 | Training loss: 0.760311 | Training constraint: -542.702759, duals [0.01]| lrm: 0.247093| num_tokens: 3,226
Step 02332/03096 | Training loss: 0.963630 | Training constraint: -351.491364, duals [0.01]| lrm: 0.246770| num_tokens: 1,027
Step 02333/03096 | Training loss: 0.955134 | Training constraint: -428.959656, duals [0.01]| lrm: 0.246447| num_tokens: 3,593
Step 02334/03096 | Training loss: 1.038388 | Training constraint: -321.587372, duals [0.01]| lrm: 0.246124| num_tokens: 4,395
Step 02335/03096 | Training loss: 0.860228 | Training constraint: -506.993286, duals [0.01]| lrm: 0.245801| num_tokens: 3,225
Step 02336/03096 | Training loss: 1.168790 | Training constraint: -203.344482, duals [0.01]| lrm: 0.245478| num_tokens: 4,108
Step 02337/03096 | Training loss: 0.971503 | Training constraint: -198.589111, duals [0.01]| lrm: 0.245155| num_tokens: 4,272
Step 02338/03096 | Training loss: 0.954107 | Training constraint: -320.481354, duals [0.01]| lrm: 0.244832| num_tokens: 2,563
Step 02339/03096 | Training loss: 0.802102 | Training constraint: -150.279495, duals [0.01]| lrm: 0.244509| num_tokens: 961
Step 02340/03096 | Training loss: 0.913609 | Training constraint: -229.770782, duals [0.01]| lrm: 0.244186| num_tokens: 1,666
Step 02341/03096 | Training loss: 1.024041 | Training constraint: -131.973724, duals [0.01]| lrm: 0.243863| num_tokens: 4,992
Step 02342/03096 | Training loss: 0.892989 | Training constraint: -476.544312, duals [0.01]| lrm: 0.243540| num_tokens: 2,458
Step 02343/03096 | Training loss: 1.193407 | Training constraint: -317.877350, duals [0.01]| lrm: 0.243217| num_tokens: 3,510
Step 02344/03096 | Training loss: 1.079820 | Training constraint: -338.767151, duals [0.01]| lrm: 0.242894| num_tokens: 4,614
Step 02345/03096 | Training loss: 1.070806 | Training constraint: -397.712372, duals [0.01]| lrm: 0.242571| num_tokens: 4,287
Step 02346/03096 | Training loss: 1.103035 | Training constraint: -450.845978, duals [0.01]| lrm: 0.242248| num_tokens: 3,013
Step 02347/03096 | Training loss: 0.985912 | Training constraint: -322.010406, duals [0.01]| lrm: 0.241925| num_tokens: 4,984
Step 02348/03096 | Training loss: 0.856658 | Training constraint: -422.805115, duals [0.01]| lrm: 0.241602| num_tokens: 2,381
Step 02349/03096 | Training loss: 1.053745 | Training constraint: -392.164520, duals [0.01]| lrm: 0.241279| num_tokens: 3,516
Step 02350/03096 | Training loss: 0.762538 | Training constraint: -424.741638, duals [0.01]| lrm: 0.240956| num_tokens: 3,218
Step 02351/03096 | Training loss: 0.705508 | Training constraint: -468.202209, duals [0.01]| lrm: 0.240633| num_tokens: 4,390
Step 02352/03096 | Training loss: 1.067481 | Training constraint: -344.782990, duals [0.01]| lrm: 0.240310| num_tokens: 3,210
Step 02353/03096 | Training loss: 1.074755 | Training constraint: -347.229736, duals [0.01]| lrm: 0.239987| num_tokens: 3,351
Step 02354/03096 | Training loss: 0.779253 | Training constraint: -309.915649, duals [0.01]| lrm: 0.239664| num_tokens: 3,698
Step 02355/03096 | Training loss: 1.122546 | Training constraint: -263.733948, duals [0.01]| lrm: 0.239341| num_tokens: 3,257
Step 02356/03096 | Training loss: 0.952555 | Training constraint: -374.068085, duals [0.01]| lrm: 0.239018| num_tokens: 3,737
Step 02357/03096 | Training loss: 1.152741 | Training constraint: -413.239563, duals [0.01]| lrm: 0.238695| num_tokens: 1,502
Step 02358/03096 | Training loss: 1.138351 | Training constraint: -224.053970, duals [0.01]| lrm: 0.238372| num_tokens: 4,484
Step 02359/03096 | Training loss: 0.792709 | Training constraint: -305.126434, duals [0.01]| lrm: 0.238049| num_tokens: 4,290
Step 02360/03096 | Training loss: 0.821702 | Training constraint: -511.817749, duals [0.01]| lrm: 0.237726| num_tokens: 3,967
Step 02361/03096 | Training loss: 0.938024 | Training constraint: -536.317383, duals [0.01]| lrm: 0.237403| num_tokens: 1,928
Step 02362/03096 | Training loss: 1.291064 | Training constraint: -464.410156, duals [0.01]| lrm: 0.237080| num_tokens: 3,388
Step 02363/03096 | Training loss: 0.931112 | Training constraint: -373.152893, duals [0.01]| lrm: 0.236757| num_tokens: 2,826
Step 02364/03096 | Training loss: 1.255700 | Training constraint: -296.100708, duals [0.01]| lrm: 0.236434| num_tokens: 5,498
Step 02365/03096 | Training loss: 1.041085 | Training constraint: -344.645416, duals [0.01]| lrm: 0.236111| num_tokens: 4,444
Step 02366/03096 | Training loss: 0.892110 | Training constraint: -355.032074, duals [0.01]| lrm: 0.235788| num_tokens: 4,406
Step 02367/03096 | Training loss: 0.976206 | Training constraint: -343.872437, duals [0.01]| lrm: 0.235465| num_tokens: 2,999
Step 02368/03096 | Training loss: 0.915139 | Training constraint: -144.520844, duals [0.01]| lrm: 0.235142| num_tokens: 1,467
Step 02369/03096 | Training loss: 0.937208 | Training constraint: -348.405945, duals [0.01]| lrm: 0.234819| num_tokens: 2,415
Step 02370/03096 | Training loss: 0.929380 | Training constraint: -233.755737, duals [0.01]| lrm: 0.234496| num_tokens: 2,888
Step 02371/03096 | Training loss: 1.036648 | Training constraint: -498.706879, duals [0.01]| lrm: 0.234173| num_tokens: 2,395
Step 02372/03096 | Training loss: 1.071156 | Training constraint: -316.751587, duals [0.01]| lrm: 0.233850| num_tokens: 2,807
Step 02373/03096 | Training loss: 0.978267 | Training constraint: -285.366821, duals [0.01]| lrm: 0.233527| num_tokens: 3,709
Step 02374/03096 | Training loss: 0.749095 | Training constraint: -288.669525, duals [0.01]| lrm: 0.233204| num_tokens: 2,400
Step 02375/03096 | Training loss: 1.090329 | Training constraint: -469.034668, duals [0.01]| lrm: 0.232881| num_tokens: 2,955
Step 02376/03096 | Training loss: 1.000896 | Training constraint: -270.984222, duals [0.01]| lrm: 0.232558| num_tokens: 2,105
Step 02377/03096 | Training loss: 1.113529 | Training constraint: -285.993347, duals [0.01]| lrm: 0.232235| num_tokens: 2,821
Step 02378/03096 | Training loss: 1.121617 | Training constraint: -301.531250, duals [0.01]| lrm: 0.231912| num_tokens: 3,926
Step 02379/03096 | Training loss: 1.006156 | Training constraint: -245.550278, duals [0.01]| lrm: 0.231589| num_tokens: 3,474
Step 02380/03096 | Training loss: 1.026871 | Training constraint: -303.421600, duals [0.01]| lrm: 0.231266| num_tokens: 3,178
Step 02381/03096 | Training loss: 1.119841 | Training constraint: -341.967072, duals [0.01]| lrm: 0.230943| num_tokens: 3,450
Step 02382/03096 | Training loss: 1.400280 | Training constraint: -365.836151, duals [0.01]| lrm: 0.230620| num_tokens: 3,896
Step 02383/03096 | Training loss: 0.696874 | Training constraint: -497.617706, duals [0.01]| lrm: 0.230297| num_tokens: 3,326
Step 02384/03096 | Training loss: 1.072266 | Training constraint: -578.149719, duals [0.01]| lrm: 0.229974| num_tokens: 3,298
Step 02385/03096 | Training loss: 0.980934 | Training constraint: -350.145447, duals [0.01]| lrm: 0.229651| num_tokens: 3,146
Step 02386/03096 | Training loss: 1.259791 | Training constraint: -375.630127, duals [0.01]| lrm: 0.229328| num_tokens: 4,465
Step 02387/03096 | Training loss: 0.907106 | Training constraint: -433.811371, duals [0.01]| lrm: 0.229005| num_tokens: 2,895
Step 02388/03096 | Training loss: 1.042114 | Training constraint: -325.183929, duals [0.01]| lrm: 0.228682| num_tokens: 1,743
Step 02389/03096 | Training loss: 1.020946 | Training constraint: -466.855591, duals [0.01]| lrm: 0.228359| num_tokens: 2,763
Step 02390/03096 | Training loss: 0.941163 | Training constraint: -322.313110, duals [0.01]| lrm: 0.228036| num_tokens: 3,114
Step 02391/03096 | Training loss: 0.539628 | Training constraint: -282.163208, duals [0.01]| lrm: 0.227713| num_tokens: 1,942
Step 02392/03096 | Training loss: 0.685489 | Training constraint: -241.878311, duals [0.01]| lrm: 0.227390| num_tokens: 4,311
Step 02393/03096 | Training loss: 1.135460 | Training constraint: -302.536957, duals [0.01]| lrm: 0.227067| num_tokens: 1,907
Step 02394/03096 | Training loss: 1.034066 | Training constraint: -339.008179, duals [0.01]| lrm: 0.226744| num_tokens: 2,156
Step 02395/03096 | Training loss: 1.005168 | Training constraint: -286.701599, duals [0.01]| lrm: 0.226421| num_tokens: 3,695
Step 02396/03096 | Training loss: 1.181908 | Training constraint: -296.212921, duals [0.01]| lrm: 0.226098| num_tokens: 5,956
Step 02397/03096 | Training loss: 1.047989 | Training constraint: -302.316559, duals [0.01]| lrm: 0.225775| num_tokens: 3,820
Step 02398/03096 | Training loss: 1.119380 | Training constraint: -476.513367, duals [0.01]| lrm: 0.225452| num_tokens: 3,219
Step 02399/03096 | Training loss: 0.664086 | Training constraint: -267.367920, duals [0.01]| lrm: 0.225129| num_tokens: 2,398
Step 02400 | Validation loss: 1.171755
2026-01-21 14:18:35,161 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:18:35,161 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:18:35,166 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:18:35,166 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:18:35,279 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:18:35,280 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:18:35,638 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:18:35,644 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:18:35,840 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:18:36,021 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:18:36,027 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:18:36,165 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 306/1024 (29.88%)
2026-01-21 14:18:36,753 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:18:36,755 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:18:36,756 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:18:36,761 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:18:36,871 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:18:36,876 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:18:36,991 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:18:36,995 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:18:37,106 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:18:37,111 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:18:37,230 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:18:37,234 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:18:37,346 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:18:37,350 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 358/1024 (34.96%)
Step 02400 | mmlu_acc: 0.298828, arc_easy_acc: 0.349609
Step 02400/03096 | Training loss: 0.784301 | Training constraint: -229.788422, duals [0.01]| lrm: 0.224806| num_tokens: 3,213
Step 02401/03096 | Training loss: 1.098187 | Training constraint: -367.637665, duals [0.01]| lrm: 0.224483| num_tokens: 2,475
Step 02402/03096 | Training loss: 0.845416 | Training constraint: -653.878967, duals [0.01]| lrm: 0.224160| num_tokens: 4,227
Step 02403/03096 | Training loss: 1.132823 | Training constraint: -271.677734, duals [0.01]| lrm: 0.223837| num_tokens: 3,889
Step 02404/03096 | Training loss: 0.926824 | Training constraint: -211.216278, duals [0.01]| lrm: 0.223514| num_tokens: 1,436
Step 02405/03096 | Training loss: 0.969897 | Training constraint: -211.493500, duals [0.01]| lrm: 0.223191| num_tokens: 4,563
Step 02406/03096 | Training loss: 0.844379 | Training constraint: -350.320557, duals [0.01]| lrm: 0.222868| num_tokens: 683
Step 02407/03096 | Training loss: 1.185309 | Training constraint: -349.291107, duals [0.01]| lrm: 0.222545| num_tokens: 3,071
Step 02408/03096 | Training loss: 1.175967 | Training constraint: -293.584503, duals [0.01]| lrm: 0.222222| num_tokens: 2,895
Step 02409/03096 | Training loss: 0.908341 | Training constraint: -277.045593, duals [0.01]| lrm: 0.221899| num_tokens: 1,599
Step 02410/03096 | Training loss: 0.931706 | Training constraint: -379.331604, duals [0.01]| lrm: 0.221576| num_tokens: 2,360
Step 02411/03096 | Training loss: 1.156049 | Training constraint: -440.682129, duals [0.01]| lrm: 0.221253| num_tokens: 4,210
Step 02412/03096 | Training loss: 1.126461 | Training constraint: -332.840240, duals [0.01]| lrm: 0.220930| num_tokens: 4,683
Step 02413/03096 | Training loss: 1.277821 | Training constraint: -385.411377, duals [0.01]| lrm: 0.220607| num_tokens: 3,016
Step 02414/03096 | Training loss: 1.080336 | Training constraint: -102.940697, duals [0.01]| lrm: 0.220284| num_tokens: 2,021
Step 02415/03096 | Training loss: 1.050290 | Training constraint: -504.722321, duals [0.01]| lrm: 0.219961| num_tokens: 5,963
Step 02416/03096 | Training loss: 0.990143 | Training constraint: -193.081345, duals [0.01]| lrm: 0.219638| num_tokens: 2,551
Step 02417/03096 | Training loss: 0.943433 | Training constraint: -276.215271, duals [0.01]| lrm: 0.219315| num_tokens: 2,531
Step 02418/03096 | Training loss: 0.984155 | Training constraint: -358.888916, duals [0.01]| lrm: 0.218992| num_tokens: 2,496
Step 02419/03096 | Training loss: 1.199490 | Training constraint: -307.328613, duals [0.01]| lrm: 0.218669| num_tokens: 5,660
Step 02420/03096 | Training loss: 0.830333 | Training constraint: -343.615417, duals [0.01]| lrm: 0.218346| num_tokens: 4,244
Step 02421/03096 | Training loss: 1.076258 | Training constraint: -278.570953, duals [0.01]| lrm: 0.218023| num_tokens: 3,168
Step 02422/03096 | Training loss: 0.921429 | Training constraint: -320.727356, duals [0.01]| lrm: 0.217700| num_tokens: 2,326
Step 02423/03096 | Training loss: 0.812125 | Training constraint: -532.797302, duals [0.01]| lrm: 0.217377| num_tokens: 4,711
Step 02424/03096 | Training loss: 1.180949 | Training constraint: -290.974762, duals [0.01]| lrm: 0.217054| num_tokens: 5,069
Step 02425/03096 | Training loss: 0.778326 | Training constraint: -387.254272, duals [0.01]| lrm: 0.216731| num_tokens: 1,918
Step 02426/03096 | Training loss: 1.059501 | Training constraint: -246.730011, duals [0.01]| lrm: 0.216408| num_tokens: 6,752
Step 02427/03096 | Training loss: 0.956456 | Training constraint: -352.735779, duals [0.01]| lrm: 0.216085| num_tokens: 1,652
Step 02428/03096 | Training loss: 0.756956 | Training constraint: -273.876892, duals [0.01]| lrm: 0.215762| num_tokens: 2,984
Step 02429/03096 | Training loss: 0.754781 | Training constraint: -157.608582, duals [0.01]| lrm: 0.215439| num_tokens: 2,725
Step 02430/03096 | Training loss: 0.972157 | Training constraint: -377.489166, duals [0.01]| lrm: 0.215116| num_tokens: 2,542
Step 02431/03096 | Training loss: 1.083919 | Training constraint: -322.816315, duals [0.01]| lrm: 0.214793| num_tokens: 4,014
Step 02432/03096 | Training loss: 0.962768 | Training constraint: -499.676208, duals [0.01]| lrm: 0.214470| num_tokens: 2,668
Step 02433/03096 | Training loss: 1.155650 | Training constraint: -302.413940, duals [0.01]| lrm: 0.214147| num_tokens: 5,672
Step 02434/03096 | Training loss: 0.913720 | Training constraint: -403.843201, duals [0.01]| lrm: 0.213824| num_tokens: 4,896
Step 02435/03096 | Training loss: 0.891449 | Training constraint: -349.605011, duals [0.01]| lrm: 0.213501| num_tokens: 1,770
Step 02436/03096 | Training loss: 0.915871 | Training constraint: -620.608398, duals [0.01]| lrm: 0.213178| num_tokens: 3,492
Step 02437/03096 | Training loss: 1.096211 | Training constraint: -199.230499, duals [0.01]| lrm: 0.212855| num_tokens: 4,361
Step 02438/03096 | Training loss: 1.004158 | Training constraint: -186.562012, duals [0.01]| lrm: 0.212532| num_tokens: 2,079
Step 02439/03096 | Training loss: 1.181531 | Training constraint: -278.043854, duals [0.01]| lrm: 0.212209| num_tokens: 2,586
Step 02440/03096 | Training loss: 1.134680 | Training constraint: -344.362091, duals [0.01]| lrm: 0.211886| num_tokens: 3,463
Step 02441/03096 | Training loss: 0.950374 | Training constraint: -394.186157, duals [0.01]| lrm: 0.211563| num_tokens: 2,363
Step 02442/03096 | Training loss: 0.867295 | Training constraint: -525.498413, duals [0.01]| lrm: 0.211240| num_tokens: 2,550
Step 02443/03096 | Training loss: 0.933139 | Training constraint: -230.428299, duals [0.01]| lrm: 0.210917| num_tokens: 4,179
Step 02444/03096 | Training loss: 1.089565 | Training constraint: -411.044708, duals [0.01]| lrm: 0.210594| num_tokens: 3,993
Step 02445/03096 | Training loss: 0.993080 | Training constraint: -186.469360, duals [0.01]| lrm: 0.210271| num_tokens: 5,015
Step 02446/03096 | Training loss: 0.982973 | Training constraint: -442.475586, duals [0.01]| lrm: 0.209948| num_tokens: 3,214
Step 02447/03096 | Training loss: 0.872559 | Training constraint: -293.192627, duals [0.01]| lrm: 0.209625| num_tokens: 2,656
Step 02448/03096 | Training loss: 1.120127 | Training constraint: -434.177643, duals [0.01]| lrm: 0.209302| num_tokens: 4,558
Step 02449/03096 | Training loss: 0.853803 | Training constraint: -163.477509, duals [0.01]| lrm: 0.208979| num_tokens: 4,031
Step 02450/03096 | Training loss: 1.063438 | Training constraint: -349.279724, duals [0.01]| lrm: 0.208656| num_tokens: 3,477
Step 02451/03096 | Training loss: 1.053526 | Training constraint: -269.793030, duals [0.01]| lrm: 0.208333| num_tokens: 3,965
Step 02452/03096 | Training loss: 1.062517 | Training constraint: -173.032684, duals [0.01]| lrm: 0.208010| num_tokens: 1,208
Step 02453/03096 | Training loss: 1.248732 | Training constraint: -399.605225, duals [0.01]| lrm: 0.207687| num_tokens: 3,306
Step 02454/03096 | Training loss: 1.061229 | Training constraint: -239.707779, duals [0.01]| lrm: 0.207364| num_tokens: 2,539
Step 02455/03096 | Training loss: 0.995545 | Training constraint: -347.382843, duals [0.01]| lrm: 0.207041| num_tokens: 3,944
Step 02456/03096 | Training loss: 1.112092 | Training constraint: -290.618256, duals [0.01]| lrm: 0.206718| num_tokens: 4,313
Step 02457/03096 | Training loss: 0.799988 | Training constraint: -284.976685, duals [0.01]| lrm: 0.206395| num_tokens: 2,006
Step 02458/03096 | Training loss: 0.944661 | Training constraint: -409.564087, duals [0.01]| lrm: 0.206072| num_tokens: 3,725
Step 02459/03096 | Training loss: 1.086744 | Training constraint: -310.297272, duals [0.01]| lrm: 0.205749| num_tokens: 2,879
Step 02460/03096 | Training loss: 1.119265 | Training constraint: -426.084869, duals [0.01]| lrm: 0.205426| num_tokens: 2,208
Step 02461/03096 | Training loss: 0.846676 | Training constraint: -248.364395, duals [0.01]| lrm: 0.205103| num_tokens: 2,041
Step 02462/03096 | Training loss: 0.842788 | Training constraint: -288.599274, duals [0.01]| lrm: 0.204780| num_tokens: 2,939
Step 02463/03096 | Training loss: 0.860638 | Training constraint: -217.486862, duals [0.01]| lrm: 0.204457| num_tokens: 1,446
Step 02464/03096 | Training loss: 0.923978 | Training constraint: -298.572998, duals [0.01]| lrm: 0.204134| num_tokens: 1,860
Step 02465/03096 | Training loss: 1.230748 | Training constraint: -345.905212, duals [0.01]| lrm: 0.203811| num_tokens: 3,516
Step 02466/03096 | Training loss: 0.809443 | Training constraint: -175.296509, duals [0.01]| lrm: 0.203488| num_tokens: 3,954
Step 02467/03096 | Training loss: 0.961700 | Training constraint: -153.966797, duals [0.01]| lrm: 0.203165| num_tokens: 5,683
Step 02468/03096 | Training loss: 1.007162 | Training constraint: -332.516083, duals [0.01]| lrm: 0.202842| num_tokens: 6,312
Step 02469/03096 | Training loss: 0.961080 | Training constraint: -173.870529, duals [0.01]| lrm: 0.202519| num_tokens: 3,247
Step 02470/03096 | Training loss: 1.069427 | Training constraint: -282.911469, duals [0.01]| lrm: 0.202196| num_tokens: 4,661
Step 02471/03096 | Training loss: 1.031218 | Training constraint: -395.696106, duals [0.01]| lrm: 0.201873| num_tokens: 4,781
Step 02472/03096 | Training loss: 1.130362 | Training constraint: -229.832108, duals [0.01]| lrm: 0.201550| num_tokens: 3,095
Step 02473/03096 | Training loss: 1.050730 | Training constraint: -378.809479, duals [0.01]| lrm: 0.201227| num_tokens: 4,296
Step 02474/03096 | Training loss: 1.110572 | Training constraint: -405.429443, duals [0.01]| lrm: 0.200904| num_tokens: 2,027
Step 02475/03096 | Training loss: 0.948678 | Training constraint: -340.574402, duals [0.01]| lrm: 0.200581| num_tokens: 3,403
Step 02476/03096 | Training loss: 1.114459 | Training constraint: -384.709778, duals [0.01]| lrm: 0.200258| num_tokens: 2,245
Step 02477/03096 | Training loss: 0.897725 | Training constraint: -458.653870, duals [0.01]| lrm: 0.199935| num_tokens: 6,207
Step 02478/03096 | Training loss: 1.095126 | Training constraint: -245.919556, duals [0.01]| lrm: 0.199612| num_tokens: 5,493
Step 02479/03096 | Training loss: 1.242355 | Training constraint: -325.781464, duals [0.01]| lrm: 0.199289| num_tokens: 1,680
Step 02480/03096 | Training loss: 0.834293 | Training constraint: -275.565552, duals [0.01]| lrm: 0.198966| num_tokens: 1,767
Step 02481/03096 | Training loss: 1.055908 | Training constraint: -490.501648, duals [0.01]| lrm: 0.198643| num_tokens: 4,702
Step 02482/03096 | Training loss: 0.970471 | Training constraint: -421.790680, duals [0.01]| lrm: 0.198320| num_tokens: 1,601
Step 02483/03096 | Training loss: 0.916083 | Training constraint: -480.508575, duals [0.01]| lrm: 0.197997| num_tokens: 4,778
Step 02484/03096 | Training loss: 0.815432 | Training constraint: -278.205780, duals [0.01]| lrm: 0.197674| num_tokens: 4,774
Step 02485/03096 | Training loss: 0.977335 | Training constraint: -263.876526, duals [0.01]| lrm: 0.197351| num_tokens: 2,203
Step 02486/03096 | Training loss: 1.146338 | Training constraint: -422.909180, duals [0.01]| lrm: 0.197028| num_tokens: 4,642
Step 02487/03096 | Training loss: 0.941506 | Training constraint: -455.594177, duals [0.01]| lrm: 0.196705| num_tokens: 3,820
Step 02488/03096 | Training loss: 1.035146 | Training constraint: -292.943604, duals [0.01]| lrm: 0.196382| num_tokens: 3,562
Step 02489/03096 | Training loss: 1.150963 | Training constraint: -297.003296, duals [0.01]| lrm: 0.196059| num_tokens: 5,334
Step 02490/03096 | Training loss: 1.135548 | Training constraint: -419.787842, duals [0.01]| lrm: 0.195736| num_tokens: 4,818
Step 02491/03096 | Training loss: 1.067887 | Training constraint: -401.807190, duals [0.01]| lrm: 0.195413| num_tokens: 4,485
Step 02492/03096 | Training loss: 1.017444 | Training constraint: -346.865723, duals [0.01]| lrm: 0.195090| num_tokens: 4,624
Step 02493/03096 | Training loss: 0.854634 | Training constraint: -253.409058, duals [0.01]| lrm: 0.194767| num_tokens: 3,943
Step 02494/03096 | Training loss: 1.073462 | Training constraint: -377.174835, duals [0.01]| lrm: 0.194444| num_tokens: 2,806
Step 02495/03096 | Training loss: 1.339157 | Training constraint: -295.150116, duals [0.01]| lrm: 0.194121| num_tokens: 3,827
Step 02496/03096 | Training loss: 0.985805 | Training constraint: -242.873871, duals [0.01]| lrm: 0.193798| num_tokens: 3,364
Step 02497/03096 | Training loss: 1.099401 | Training constraint: -305.355774, duals [0.01]| lrm: 0.193475| num_tokens: 3,252
Step 02498/03096 | Training loss: 0.881807 | Training constraint: -483.321198, duals [0.01]| lrm: 0.193152| num_tokens: 4,047
Step 02499/03096 | Training loss: 1.204956 | Training constraint: -411.892456, duals [0.01]| lrm: 0.192829| num_tokens: 4,202
Step 02500 | Validation loss: 1.172349
Step 02500/03096 | Training loss: 0.994026 | Training constraint: -267.126587, duals [0.01]| lrm: 0.192506| num_tokens: 667
Step 02501/03096 | Training loss: 1.095126 | Training constraint: -188.464264, duals [0.01]| lrm: 0.192183| num_tokens: 4,922
Step 02502/03096 | Training loss: 0.871180 | Training constraint: -452.721771, duals [0.01]| lrm: 0.191860| num_tokens: 3,606
Step 02503/03096 | Training loss: 0.737487 | Training constraint: -214.975861, duals [0.01]| lrm: 0.191537| num_tokens: 1,589
Step 02504/03096 | Training loss: 0.820593 | Training constraint: -285.176300, duals [0.01]| lrm: 0.191214| num_tokens: 4,380
Step 02505/03096 | Training loss: 0.939445 | Training constraint: -339.051514, duals [0.01]| lrm: 0.190891| num_tokens: 2,761
Step 02506/03096 | Training loss: 0.829239 | Training constraint: -539.320801, duals [0.01]| lrm: 0.190568| num_tokens: 2,099
Step 02507/03096 | Training loss: 0.790209 | Training constraint: -395.982086, duals [0.01]| lrm: 0.190245| num_tokens: 1,333
Step 02508/03096 | Training loss: 1.006624 | Training constraint: -375.333923, duals [0.01]| lrm: 0.189922| num_tokens: 3,904
Step 02509/03096 | Training loss: 1.059037 | Training constraint: -352.133087, duals [0.01]| lrm: 0.189599| num_tokens: 3,762
Step 02510/03096 | Training loss: 1.014987 | Training constraint: -289.364136, duals [0.01]| lrm: 0.189276| num_tokens: 1,816
Step 02511/03096 | Training loss: 1.160868 | Training constraint: -443.869324, duals [0.01]| lrm: 0.188953| num_tokens: 4,747
Step 02512/03096 | Training loss: 1.318121 | Training constraint: -143.915527, duals [0.01]| lrm: 0.188630| num_tokens: 3,164
Step 02513/03096 | Training loss: 0.923159 | Training constraint: -364.131500, duals [0.01]| lrm: 0.188307| num_tokens: 3,636
Step 02514/03096 | Training loss: 0.897512 | Training constraint: -148.899841, duals [0.01]| lrm: 0.187984| num_tokens: 5,036
Step 02515/03096 | Training loss: 1.026981 | Training constraint: -507.426880, duals [0.01]| lrm: 0.187661| num_tokens: 3,445
Step 02516/03096 | Training loss: 1.168305 | Training constraint: -266.495361, duals [0.01]| lrm: 0.187339| num_tokens: 319
Step 02517/03096 | Training loss: 0.924424 | Training constraint: -283.399536, duals [0.01]| lrm: 0.187016| num_tokens: 3,685
Step 02518/03096 | Training loss: 1.180722 | Training constraint: -344.776917, duals [0.01]| lrm: 0.186693| num_tokens: 2,999
Step 02519/03096 | Training loss: 1.105353 | Training constraint: -346.748169, duals [0.01]| lrm: 0.186370| num_tokens: 3,156
Step 02520/03096 | Training loss: 0.844581 | Training constraint: -266.046082, duals [0.01]| lrm: 0.186047| num_tokens: 1,396
Step 02521/03096 | Training loss: 0.676312 | Training constraint: -507.535004, duals [0.01]| lrm: 0.185724| num_tokens: 1,483
Step 02522/03096 | Training loss: 0.910467 | Training constraint: -385.091431, duals [0.01]| lrm: 0.185401| num_tokens: 3,481
Step 02523/03096 | Training loss: 1.125247 | Training constraint: -271.224762, duals [0.01]| lrm: 0.185078| num_tokens: 1,203
Step 02524/03096 | Training loss: 1.269168 | Training constraint: -316.407928, duals [0.01]| lrm: 0.184755| num_tokens: 3,660
Step 02525/03096 | Training loss: 0.916026 | Training constraint: -272.696686, duals [0.01]| lrm: 0.184432| num_tokens: 5,805
Step 02526/03096 | Training loss: 0.680184 | Training constraint: -192.804459, duals [0.01]| lrm: 0.184109| num_tokens: 4,319
Step 02527/03096 | Training loss: 1.018504 | Training constraint: -232.786926, duals [0.01]| lrm: 0.183786| num_tokens: 2,537
Step 02528/03096 | Training loss: 1.027337 | Training constraint: -279.327698, duals [0.01]| lrm: 0.183463| num_tokens: 2,066
Step 02529/03096 | Training loss: 0.780644 | Training constraint: -320.158081, duals [0.01]| lrm: 0.183140| num_tokens: 3,494
Step 02530/03096 | Training loss: 1.076840 | Training constraint: -389.313446, duals [0.01]| lrm: 0.182817| num_tokens: 1,662
Step 02531/03096 | Training loss: 1.036157 | Training constraint: -297.744629, duals [0.01]| lrm: 0.182494| num_tokens: 4,569
Step 02532/03096 | Training loss: 1.006893 | Training constraint: -258.923584, duals [0.01]| lrm: 0.182171| num_tokens: 4,162
Step 02533/03096 | Training loss: 1.318778 | Training constraint: -265.998627, duals [0.01]| lrm: 0.181848| num_tokens: 3,857
Step 02534/03096 | Training loss: 1.011184 | Training constraint: -355.928650, duals [0.01]| lrm: 0.181525| num_tokens: 2,749
Step 02535/03096 | Training loss: 0.778859 | Training constraint: -287.856384, duals [0.01]| lrm: 0.181202| num_tokens: 4,164
Step 02536/03096 | Training loss: 0.877059 | Training constraint: -291.141388, duals [0.01]| lrm: 0.180879| num_tokens: 3,824
Step 02537/03096 | Training loss: 0.777525 | Training constraint: -273.588806, duals [0.01]| lrm: 0.180556| num_tokens: 4,202
Step 02538/03096 | Training loss: 1.081236 | Training constraint: -321.858734, duals [0.01]| lrm: 0.180233| num_tokens: 5,708
Step 02539/03096 | Training loss: 1.081805 | Training constraint: -238.638687, duals [0.01]| lrm: 0.179910| num_tokens: 3,047
Step 02540/03096 | Training loss: 1.107882 | Training constraint: -411.347260, duals [0.01]| lrm: 0.179587| num_tokens: 1,733
Step 02541/03096 | Training loss: 1.037917 | Training constraint: -256.604187, duals [0.01]| lrm: 0.179264| num_tokens: 4,029
Step 02542/03096 | Training loss: 1.210024 | Training constraint: -370.290588, duals [0.01]| lrm: 0.178941| num_tokens: 3,248
Step 02543/03096 | Training loss: 1.087469 | Training constraint: -252.876846, duals [0.01]| lrm: 0.178618| num_tokens: 2,498
Step 02544/03096 | Training loss: 1.080012 | Training constraint: -449.200562, duals [0.01]| lrm: 0.178295| num_tokens: 4,405
Step 02545/03096 | Training loss: 0.750309 | Training constraint: -346.953247, duals [0.01]| lrm: 0.177972| num_tokens: 2,216
Step 02546/03096 | Training loss: 0.626615 | Training constraint: -234.380615, duals [0.01]| lrm: 0.177649| num_tokens: 1,396
Step 02547/03096 | Training loss: 1.064486 | Training constraint: -334.996338, duals [0.01]| lrm: 0.177326| num_tokens: 5,016
Step 02548/03096 | Training loss: 1.011034 | Training constraint: -269.893036, duals [0.01]| lrm: 0.177003| num_tokens: 1,710
Step 02549/03096 | Training loss: 1.080766 | Training constraint: -251.952621, duals [0.01]| lrm: 0.176680| num_tokens: 4,869
Step 02550/03096 | Training loss: 0.886654 | Training constraint: -517.298584, duals [0.01]| lrm: 0.176357| num_tokens: 4,143
Step 02551/03096 | Training loss: 0.987774 | Training constraint: -233.893860, duals [0.01]| lrm: 0.176034| num_tokens: 4,903
Step 02552/03096 | Training loss: 1.119368 | Training constraint: -233.950134, duals [0.01]| lrm: 0.175711| num_tokens: 4,979
Step 02553/03096 | Training loss: 0.978429 | Training constraint: -425.565735, duals [0.01]| lrm: 0.175388| num_tokens: 3,437
Step 02554/03096 | Training loss: 0.955771 | Training constraint: -264.337433, duals [0.01]| lrm: 0.175065| num_tokens: 4,089
Step 02555/03096 | Training loss: 0.976679 | Training constraint: -546.550537, duals [0.01]| lrm: 0.174742| num_tokens: 5,100
Step 02556/03096 | Training loss: 0.953933 | Training constraint: -345.605164, duals [0.01]| lrm: 0.174419| num_tokens: 1,662
Step 02557/03096 | Training loss: 1.065528 | Training constraint: -388.346710, duals [0.01]| lrm: 0.174096| num_tokens: 5,585
Step 02558/03096 | Training loss: 1.012194 | Training constraint: -518.370117, duals [0.01]| lrm: 0.173773| num_tokens: 4,253
Step 02559/03096 | Training loss: 0.791780 | Training constraint: -200.487061, duals [0.01]| lrm: 0.173450| num_tokens: 2,463
Step 02560/03096 | Training loss: 1.413258 | Training constraint: -484.719421, duals [0.01]| lrm: 0.173127| num_tokens: 3,688
Step 02561/03096 | Training loss: 1.177854 | Training constraint: -204.995483, duals [0.01]| lrm: 0.172804| num_tokens: 5,094
Step 02562/03096 | Training loss: 0.883926 | Training constraint: -299.091095, duals [0.01]| lrm: 0.172481| num_tokens: 655
Step 02563/03096 | Training loss: 1.049709 | Training constraint: -375.963776, duals [0.01]| lrm: 0.172158| num_tokens: 4,638
Step 02564/03096 | Training loss: 0.797640 | Training constraint: -381.326599, duals [0.01]| lrm: 0.171835| num_tokens: 3,854
Step 02565/03096 | Training loss: 0.943206 | Training constraint: -247.897491, duals [0.01]| lrm: 0.171512| num_tokens: 3,835
Step 02566/03096 | Training loss: 0.988448 | Training constraint: -328.197418, duals [0.01]| lrm: 0.171189| num_tokens: 4,825
Step 02567/03096 | Training loss: 0.955324 | Training constraint: -460.682709, duals [0.01]| lrm: 0.170866| num_tokens: 1,474
Step 02568/03096 | Training loss: 0.862855 | Training constraint: -296.966278, duals [0.01]| lrm: 0.170543| num_tokens: 2,488
Step 02569/03096 | Training loss: 0.973014 | Training constraint: -323.149780, duals [0.01]| lrm: 0.170220| num_tokens: 3,380
Step 02570/03096 | Training loss: 1.055158 | Training constraint: -393.589233, duals [0.01]| lrm: 0.169897| num_tokens: 3,619
Step 02571/03096 | Training loss: 0.914761 | Training constraint: -301.191895, duals [0.01]| lrm: 0.169574| num_tokens: 3,791
Step 02572/03096 | Training loss: 1.061220 | Training constraint: -439.606781, duals [0.01]| lrm: 0.169251| num_tokens: 2,867
Step 02573/03096 | Training loss: 1.075641 | Training constraint: -379.159210, duals [0.01]| lrm: 0.168928| num_tokens: 5,302
Step 02574/03096 | Training loss: 0.860476 | Training constraint: -223.880630, duals [0.01]| lrm: 0.168605| num_tokens: 4,967
Step 02575/03096 | Training loss: 1.166195 | Training constraint: -615.803955, duals [0.01]| lrm: 0.168282| num_tokens: 4,357
Step 02576/03096 | Training loss: 0.829972 | Training constraint: -258.141571, duals [0.01]| lrm: 0.167959| num_tokens: 2,113
Step 02577/03096 | Training loss: 0.744654 | Training constraint: -403.719971, duals [0.01]| lrm: 0.167636| num_tokens: 4,632
Step 02578/03096 | Training loss: 0.984422 | Training constraint: -251.398651, duals [0.01]| lrm: 0.167313| num_tokens: 3,608
Step 02579/03096 | Training loss: 1.039935 | Training constraint: -408.303284, duals [0.01]| lrm: 0.166990| num_tokens: 1,453
Step 02580/03096 | Training loss: 0.891631 | Training constraint: -297.966248, duals [0.01]| lrm: 0.166667| num_tokens: 2,720
Step 02581/03096 | Training loss: 0.879990 | Training constraint: -374.485779, duals [0.01]| lrm: 0.166344| num_tokens: 3,653
Step 02582/03096 | Training loss: 1.014862 | Training constraint: -273.973663, duals [0.01]| lrm: 0.166021| num_tokens: 4,217
Step 02583/03096 | Training loss: 1.081446 | Training constraint: -437.755981, duals [0.01]| lrm: 0.165698| num_tokens: 6,186
Step 02584/03096 | Training loss: 0.861292 | Training constraint: -307.675018, duals [0.01]| lrm: 0.165375| num_tokens: 3,682
Step 02585/03096 | Training loss: 0.734419 | Training constraint: -425.305206, duals [0.01]| lrm: 0.165052| num_tokens: 5,055
Step 02586/03096 | Training loss: 0.818314 | Training constraint: -343.734802, duals [0.01]| lrm: 0.164729| num_tokens: 1,719
Step 02587/03096 | Training loss: 1.018031 | Training constraint: -156.786636, duals [0.01]| lrm: 0.164406| num_tokens: 3,556
Step 02588/03096 | Training loss: 0.955302 | Training constraint: -403.521637, duals [0.01]| lrm: 0.164083| num_tokens: 5,005
Step 02589/03096 | Training loss: 1.061345 | Training constraint: -218.548721, duals [0.01]| lrm: 0.163760| num_tokens: 2,676
Step 02590/03096 | Training loss: 0.818908 | Training constraint: -366.455414, duals [0.01]| lrm: 0.163437| num_tokens: 3,029
Step 02591/03096 | Training loss: 1.003045 | Training constraint: -342.433472, duals [0.01]| lrm: 0.163114| num_tokens: 2,744
Step 02592/03096 | Training loss: 0.890368 | Training constraint: -290.530701, duals [0.01]| lrm: 0.162791| num_tokens: 2,634
Step 02593/03096 | Training loss: 1.285975 | Training constraint: -373.823975, duals [0.01]| lrm: 0.162468| num_tokens: 2,857
Step 02594/03096 | Training loss: 0.999673 | Training constraint: -384.706604, duals [0.01]| lrm: 0.162145| num_tokens: 4,362
Step 02595/03096 | Training loss: 0.923899 | Training constraint: -438.341644, duals [0.01]| lrm: 0.161822| num_tokens: 3,757
Step 02596/03096 | Training loss: 1.052743 | Training constraint: -214.903900, duals [0.01]| lrm: 0.161499| num_tokens: 2,819
Step 02597/03096 | Training loss: 1.095604 | Training constraint: -278.517548, duals [0.01]| lrm: 0.161176| num_tokens: 1,116
Step 02598/03096 | Training loss: 0.961807 | Training constraint: -210.507126, duals [0.01]| lrm: 0.160853| num_tokens: 3,009
Step 02599/03096 | Training loss: 1.354468 | Training constraint: -511.721100, duals [0.01]| lrm: 0.160530| num_tokens: 2,766
Step 02600 | Validation loss: 1.172866
2026-01-21 14:19:12,867 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:19:12,868 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:19:12,872 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:19:12,872 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:19:12,984 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:13,058 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:13,311 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:13,404 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:13,504 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:19:13,595 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:19:13,649 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:19:13,744 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 308/1024 (30.08%)
2026-01-21 14:19:14,336 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:19:14,339 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:19:14,341 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:19:14,343 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:19:14,456 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:14,485 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:14,568 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:14,607 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:14,684 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:19:14,722 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:19:14,807 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:19:14,911 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:19:14,921 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:19:15,025 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 361/1024 (35.25%)
Step 02600 | mmlu_acc: 0.300781, arc_easy_acc: 0.352539
Step 02600/03096 | Training loss: 1.072289 | Training constraint: -371.765839, duals [0.01]| lrm: 0.160207| num_tokens: 3,992
Step 02601/03096 | Training loss: 0.855748 | Training constraint: -320.102448, duals [0.01]| lrm: 0.159884| num_tokens: 4,505
Step 02602/03096 | Training loss: 0.928204 | Training constraint: -352.878021, duals [0.01]| lrm: 0.159561| num_tokens: 4,766
Step 02603/03096 | Training loss: 0.944299 | Training constraint: -326.280487, duals [0.01]| lrm: 0.159238| num_tokens: 1,905
Step 02604/03096 | Training loss: 1.223488 | Training constraint: -299.993530, duals [0.01]| lrm: 0.158915| num_tokens: 4,115
Step 02605/03096 | Training loss: 0.839201 | Training constraint: -304.133301, duals [0.01]| lrm: 0.158592| num_tokens: 2,832
Step 02606/03096 | Training loss: 0.837588 | Training constraint: -204.028015, duals [0.01]| lrm: 0.158269| num_tokens: 4,079
Step 02607/03096 | Training loss: 0.967532 | Training constraint: -401.668976, duals [0.01]| lrm: 0.157946| num_tokens: 4,420
Step 02608/03096 | Training loss: 0.740626 | Training constraint: -268.412933, duals [0.01]| lrm: 0.157623| num_tokens: 1,185
Step 02609/03096 | Training loss: 0.966196 | Training constraint: -359.984253, duals [0.01]| lrm: 0.157300| num_tokens: 1,538
Step 02610/03096 | Training loss: 1.015649 | Training constraint: -724.301453, duals [0.01]| lrm: 0.156977| num_tokens: 2,334
Step 02611/03096 | Training loss: 1.267891 | Training constraint: -288.949951, duals [0.01]| lrm: 0.156654| num_tokens: 5,143
Step 02612/03096 | Training loss: 0.966286 | Training constraint: -416.313934, duals [0.01]| lrm: 0.156331| num_tokens: 2,534
Step 02613/03096 | Training loss: 1.087762 | Training constraint: -421.362000, duals [0.01]| lrm: 0.156008| num_tokens: 3,337
Step 02614/03096 | Training loss: 1.072205 | Training constraint: -323.229675, duals [0.01]| lrm: 0.155685| num_tokens: 2,404
Step 02615/03096 | Training loss: 0.908804 | Training constraint: -256.289795, duals [0.01]| lrm: 0.155362| num_tokens: 2,749
Step 02616/03096 | Training loss: 1.062611 | Training constraint: -200.279892, duals [0.01]| lrm: 0.155039| num_tokens: 3,925
Step 02617/03096 | Training loss: 0.878876 | Training constraint: -365.127319, duals [0.01]| lrm: 0.154716| num_tokens: 3,121
Step 02618/03096 | Training loss: 0.966107 | Training constraint: -184.451874, duals [0.01]| lrm: 0.154393| num_tokens: 3,335
Step 02619/03096 | Training loss: 1.253303 | Training constraint: -304.489349, duals [0.01]| lrm: 0.154070| num_tokens: 3,189
Step 02620/03096 | Training loss: 0.928855 | Training constraint: -305.881714, duals [0.01]| lrm: 0.153747| num_tokens: 1,830
Step 02621/03096 | Training loss: 1.179511 | Training constraint: -351.083557, duals [0.01]| lrm: 0.153424| num_tokens: 1,620
Step 02622/03096 | Training loss: 1.012263 | Training constraint: -355.659668, duals [0.01]| lrm: 0.153101| num_tokens: 2,069
Step 02623/03096 | Training loss: 0.945556 | Training constraint: -287.670959, duals [0.01]| lrm: 0.152778| num_tokens: 2,949
Step 02624/03096 | Training loss: 0.968279 | Training constraint: -503.385803, duals [0.01]| lrm: 0.152455| num_tokens: 4,915
Step 02625/03096 | Training loss: 0.946126 | Training constraint: -396.496063, duals [0.01]| lrm: 0.152132| num_tokens: 3,675
Step 02626/03096 | Training loss: 1.040467 | Training constraint: -391.108124, duals [0.01]| lrm: 0.151809| num_tokens: 2,337
Step 02627/03096 | Training loss: 1.231463 | Training constraint: -396.075989, duals [0.01]| lrm: 0.151486| num_tokens: 2,944
Step 02628/03096 | Training loss: 0.857690 | Training constraint: -531.732239, duals [0.01]| lrm: 0.151163| num_tokens: 2,275
Step 02629/03096 | Training loss: 0.875793 | Training constraint: -378.386780, duals [0.01]| lrm: 0.150840| num_tokens: 3,636
Step 02630/03096 | Training loss: 1.105516 | Training constraint: -171.454544, duals [0.01]| lrm: 0.150517| num_tokens: 966
Step 02631/03096 | Training loss: 1.298486 | Training constraint: -552.371338, duals [0.01]| lrm: 0.150194| num_tokens: 3,811
Step 02632/03096 | Training loss: 1.061081 | Training constraint: -479.381226, duals [0.01]| lrm: 0.149871| num_tokens: 2,519
Step 02633/03096 | Training loss: 1.008906 | Training constraint: -289.217651, duals [0.01]| lrm: 0.149548| num_tokens: 2,095
Step 02634/03096 | Training loss: 1.019540 | Training constraint: -457.342255, duals [0.01]| lrm: 0.149225| num_tokens: 3,058
Step 02635/03096 | Training loss: 0.879791 | Training constraint: -289.183716, duals [0.01]| lrm: 0.148902| num_tokens: 2,379
Step 02636/03096 | Training loss: 1.187806 | Training constraint: -246.408173, duals [0.01]| lrm: 0.148579| num_tokens: 1,841
Step 02637/03096 | Training loss: 1.056137 | Training constraint: -286.574524, duals [0.01]| lrm: 0.148256| num_tokens: 4,581
Step 02638/03096 | Training loss: 1.155241 | Training constraint: -321.501251, duals [0.01]| lrm: 0.147933| num_tokens: 2,822
Step 02639/03096 | Training loss: 1.094346 | Training constraint: -225.741333, duals [0.01]| lrm: 0.147610| num_tokens: 2,826
Step 02640/03096 | Training loss: 1.196899 | Training constraint: -351.080139, duals [0.01]| lrm: 0.147287| num_tokens: 5,726
Step 02641/03096 | Training loss: 0.913400 | Training constraint: -197.611465, duals [0.01]| lrm: 0.146964| num_tokens: 3,062
Step 02642/03096 | Training loss: 0.887464 | Training constraint: -262.527405, duals [0.01]| lrm: 0.146641| num_tokens: 3,045
Step 02643/03096 | Training loss: 1.058273 | Training constraint: -181.264542, duals [0.01]| lrm: 0.146318| num_tokens: 2,546
Step 02644/03096 | Training loss: 0.995384 | Training constraint: -360.831635, duals [0.01]| lrm: 0.145995| num_tokens: 1,848
Step 02645/03096 | Training loss: 0.815482 | Training constraint: -397.705597, duals [0.01]| lrm: 0.145672| num_tokens: 3,248
Step 02646/03096 | Training loss: 1.107448 | Training constraint: -492.607666, duals [0.01]| lrm: 0.145349| num_tokens: 3,498
Step 02647/03096 | Training loss: 0.867049 | Training constraint: -282.774902, duals [0.01]| lrm: 0.145026| num_tokens: 3,126
Step 02648/03096 | Training loss: 1.107760 | Training constraint: -283.742950, duals [0.01]| lrm: 0.144703| num_tokens: 3,634
Step 02649/03096 | Training loss: 1.070420 | Training constraint: -352.419922, duals [0.01]| lrm: 0.144380| num_tokens: 3,193
Step 02650/03096 | Training loss: 0.985655 | Training constraint: -122.108246, duals [0.01]| lrm: 0.144057| num_tokens: 3,191
Step 02651/03096 | Training loss: 1.052542 | Training constraint: -257.573944, duals [0.01]| lrm: 0.143734| num_tokens: 3,573
Step 02652/03096 | Training loss: 1.139303 | Training constraint: -405.604828, duals [0.01]| lrm: 0.143411| num_tokens: 2,540
Step 02653/03096 | Training loss: 0.876603 | Training constraint: -274.875854, duals [0.01]| lrm: 0.143088| num_tokens: 4,756
Step 02654/03096 | Training loss: 0.820189 | Training constraint: -765.103882, duals [0.01]| lrm: 0.142765| num_tokens: 3,437
Step 02655/03096 | Training loss: 1.026552 | Training constraint: -305.880707, duals [0.01]| lrm: 0.142442| num_tokens: 3,066
Step 02656/03096 | Training loss: 0.960205 | Training constraint: -274.668060, duals [0.01]| lrm: 0.142119| num_tokens: 2,997
Step 02657/03096 | Training loss: 1.350162 | Training constraint: -249.460312, duals [0.01]| lrm: 0.141796| num_tokens: 4,590
Step 02658/03096 | Training loss: 0.769952 | Training constraint: -341.382477, duals [0.01]| lrm: 0.141473| num_tokens: 3,208
Step 02659/03096 | Training loss: 0.703883 | Training constraint: -366.983490, duals [0.01]| lrm: 0.141150| num_tokens: 3,408
Step 02660/03096 | Training loss: 1.288577 | Training constraint: -333.501953, duals [0.01]| lrm: 0.140827| num_tokens: 2,868
Step 02661/03096 | Training loss: 0.922883 | Training constraint: -328.199585, duals [0.01]| lrm: 0.140504| num_tokens: 1,958
Step 02662/03096 | Training loss: 1.026262 | Training constraint: -343.099091, duals [0.01]| lrm: 0.140181| num_tokens: 1,573
Step 02663/03096 | Training loss: 0.933063 | Training constraint: -428.460876, duals [0.01]| lrm: 0.139858| num_tokens: 3,462
Step 02664/03096 | Training loss: 1.057627 | Training constraint: -409.757751, duals [0.01]| lrm: 0.139535| num_tokens: 3,418
Step 02665/03096 | Training loss: 0.817799 | Training constraint: -313.423309, duals [0.01]| lrm: 0.139212| num_tokens: 3,151
Step 02666/03096 | Training loss: 1.025633 | Training constraint: -404.497894, duals [0.01]| lrm: 0.138889| num_tokens: 2,648
Step 02667/03096 | Training loss: 1.104847 | Training constraint: -464.604004, duals [0.01]| lrm: 0.138566| num_tokens: 3,542
Step 02668/03096 | Training loss: 0.897792 | Training constraint: -442.243103, duals [0.01]| lrm: 0.138243| num_tokens: 2,194
Step 02669/03096 | Training loss: 0.957665 | Training constraint: -426.963806, duals [0.01]| lrm: 0.137920| num_tokens: 3,076
Step 02670/03096 | Training loss: 0.799423 | Training constraint: -251.415894, duals [0.01]| lrm: 0.137597| num_tokens: 3,674
Step 02671/03096 | Training loss: 1.134152 | Training constraint: -270.414978, duals [0.01]| lrm: 0.137274| num_tokens: 4,544
Step 02672/03096 | Training loss: 1.130604 | Training constraint: -507.912262, duals [0.01]| lrm: 0.136951| num_tokens: 2,615
Step 02673/03096 | Training loss: 0.887300 | Training constraint: -499.519958, duals [0.01]| lrm: 0.136628| num_tokens: 2,977
Step 02674/03096 | Training loss: 0.989324 | Training constraint: -428.113098, duals [0.01]| lrm: 0.136305| num_tokens: 5,723
Step 02675/03096 | Training loss: 0.947423 | Training constraint: -343.503113, duals [0.01]| lrm: 0.135982| num_tokens: 3,400
Step 02676/03096 | Training loss: 1.127831 | Training constraint: -305.883301, duals [0.01]| lrm: 0.135659| num_tokens: 5,900
Step 02677/03096 | Training loss: 1.067015 | Training constraint: -285.232666, duals [0.01]| lrm: 0.135336| num_tokens: 2,399
Step 02678/03096 | Training loss: 0.834804 | Training constraint: -226.477753, duals [0.01]| lrm: 0.135013| num_tokens: 2,740
Step 02679/03096 | Training loss: 1.019217 | Training constraint: -398.090759, duals [0.01]| lrm: 0.134690| num_tokens: 3,554
Step 02680/03096 | Training loss: 0.996722 | Training constraint: -70.714844, duals [0.01]| lrm: 0.134367| num_tokens: 934
Step 02681/03096 | Training loss: 0.872122 | Training constraint: -349.131531, duals [0.01]| lrm: 0.134044| num_tokens: 3,294
Step 02682/03096 | Training loss: 1.007767 | Training constraint: -288.428955, duals [0.01]| lrm: 0.133721| num_tokens: 3,252
Step 02683/03096 | Training loss: 1.053235 | Training constraint: -317.526276, duals [0.01]| lrm: 0.133398| num_tokens: 3,966
Step 02684/03096 | Training loss: 1.108133 | Training constraint: -392.764587, duals [0.01]| lrm: 0.133075| num_tokens: 3,254
Step 02685/03096 | Training loss: 0.951139 | Training constraint: -232.642151, duals [0.01]| lrm: 0.132752| num_tokens: 2,720
Step 02686/03096 | Training loss: 1.161235 | Training constraint: -527.068359, duals [0.01]| lrm: 0.132429| num_tokens: 3,307
Step 02687/03096 | Training loss: 0.950012 | Training constraint: -295.260040, duals [0.01]| lrm: 0.132106| num_tokens: 4,193
Step 02688/03096 | Training loss: 1.022310 | Training constraint: -268.157043, duals [0.01]| lrm: 0.131783| num_tokens: 5,379
Step 02689/03096 | Training loss: 0.945787 | Training constraint: -507.777710, duals [0.01]| lrm: 0.131460| num_tokens: 2,864
Step 02690/03096 | Training loss: 0.938291 | Training constraint: -381.081726, duals [0.01]| lrm: 0.131137| num_tokens: 2,128
Step 02691/03096 | Training loss: 1.124156 | Training constraint: -429.212189, duals [0.01]| lrm: 0.130814| num_tokens: 1,350
Step 02692/03096 | Training loss: 0.953727 | Training constraint: -150.712479, duals [0.01]| lrm: 0.130491| num_tokens: 2,655
Step 02693/03096 | Training loss: 1.136437 | Training constraint: -493.116150, duals [0.01]| lrm: 0.130168| num_tokens: 2,766
Step 02694/03096 | Training loss: 1.059313 | Training constraint: -226.040894, duals [0.01]| lrm: 0.129845| num_tokens: 3,777
Step 02695/03096 | Training loss: 0.999629 | Training constraint: -436.964905, duals [0.01]| lrm: 0.129522| num_tokens: 3,431
Step 02696/03096 | Training loss: 0.846656 | Training constraint: -380.958130, duals [0.01]| lrm: 0.129199| num_tokens: 4,645
Step 02697/03096 | Training loss: 0.876283 | Training constraint: -322.981537, duals [0.01]| lrm: 0.128876| num_tokens: 3,954
Step 02698/03096 | Training loss: 1.117331 | Training constraint: -324.689148, duals [0.01]| lrm: 0.128553| num_tokens: 2,577
Step 02699/03096 | Training loss: 0.699532 | Training constraint: -359.401733, duals [0.01]| lrm: 0.128230| num_tokens: 2,827
Step 02700 | Validation loss: 1.173298
Step 02700/03096 | Training loss: 0.739492 | Training constraint: -316.860779, duals [0.01]| lrm: 0.127907| num_tokens: 3,918
Step 02701/03096 | Training loss: 0.855055 | Training constraint: -128.904541, duals [0.01]| lrm: 0.127584| num_tokens: 1,856
Step 02702/03096 | Training loss: 0.877608 | Training constraint: -167.350372, duals [0.01]| lrm: 0.127261| num_tokens: 2,632
Step 02703/03096 | Training loss: 0.837601 | Training constraint: -204.839767, duals [0.01]| lrm: 0.126938| num_tokens: 1,699
Step 02704/03096 | Training loss: 1.044382 | Training constraint: -300.015991, duals [0.01]| lrm: 0.126615| num_tokens: 1,372
Step 02705/03096 | Training loss: 1.117000 | Training constraint: -187.966858, duals [0.01]| lrm: 0.126292| num_tokens: 5,745
Step 02706/03096 | Training loss: 1.099248 | Training constraint: -260.952667, duals [0.01]| lrm: 0.125969| num_tokens: 4,033
Step 02707/03096 | Training loss: 1.129431 | Training constraint: -395.141052, duals [0.01]| lrm: 0.125646| num_tokens: 3,432
Step 02708/03096 | Training loss: 0.853063 | Training constraint: -171.282196, duals [0.01]| lrm: 0.125323| num_tokens: 1,980
Step 02709/03096 | Training loss: 0.948087 | Training constraint: -672.113037, duals [0.01]| lrm: 0.125000| num_tokens: 2,944
Step 02710/03096 | Training loss: 0.798148 | Training constraint: -280.240479, duals [0.01]| lrm: 0.124677| num_tokens: 1,511
Step 02711/03096 | Training loss: 0.993078 | Training constraint: -466.635895, duals [0.01]| lrm: 0.124354| num_tokens: 3,476
Step 02712/03096 | Training loss: 0.845304 | Training constraint: -478.300903, duals [0.01]| lrm: 0.124031| num_tokens: 3,255
Step 02713/03096 | Training loss: 0.941133 | Training constraint: -312.649780, duals [0.01]| lrm: 0.123708| num_tokens: 2,642
Step 02714/03096 | Training loss: 0.981443 | Training constraint: -272.926727, duals [0.01]| lrm: 0.123385| num_tokens: 4,549
Step 02715/03096 | Training loss: 1.018334 | Training constraint: -223.268097, duals [0.01]| lrm: 0.123062| num_tokens: 1,563
Step 02716/03096 | Training loss: 0.998064 | Training constraint: -582.499146, duals [0.01]| lrm: 0.122739| num_tokens: 3,952
Step 02717/03096 | Training loss: 1.021011 | Training constraint: -288.810791, duals [0.01]| lrm: 0.122416| num_tokens: 7,063
Step 02718/03096 | Training loss: 0.935257 | Training constraint: -428.190247, duals [0.01]| lrm: 0.122093| num_tokens: 3,875
Step 02719/03096 | Training loss: 0.900915 | Training constraint: -266.225098, duals [0.01]| lrm: 0.121770| num_tokens: 5,431
Step 02720/03096 | Training loss: 1.130391 | Training constraint: -247.162003, duals [0.01]| lrm: 0.121447| num_tokens: 3,206
Step 02721/03096 | Training loss: 0.830856 | Training constraint: -265.946869, duals [0.01]| lrm: 0.121124| num_tokens: 4,048
Step 02722/03096 | Training loss: 0.996309 | Training constraint: -287.275787, duals [0.01]| lrm: 0.120801| num_tokens: 2,137
Step 02723/03096 | Training loss: 0.795158 | Training constraint: -282.488922, duals [0.01]| lrm: 0.120478| num_tokens: 5,814
Step 02724/03096 | Training loss: 1.122727 | Training constraint: -370.794189, duals [0.01]| lrm: 0.120155| num_tokens: 4,267
Step 02725/03096 | Training loss: 0.791074 | Training constraint: -332.836273, duals [0.01]| lrm: 0.119832| num_tokens: 3,536
Step 02726/03096 | Training loss: 0.906853 | Training constraint: -475.364380, duals [0.01]| lrm: 0.119509| num_tokens: 4,338
Step 02727/03096 | Training loss: 1.209504 | Training constraint: -208.196640, duals [0.01]| lrm: 0.119186| num_tokens: 2,187
Step 02728/03096 | Training loss: 0.896137 | Training constraint: -361.825836, duals [0.01]| lrm: 0.118863| num_tokens: 1,728
Step 02729/03096 | Training loss: 1.100974 | Training constraint: -327.602814, duals [0.01]| lrm: 0.118540| num_tokens: 4,021
Step 02730/03096 | Training loss: 1.179651 | Training constraint: -340.076080, duals [0.01]| lrm: 0.118217| num_tokens: 3,718
Step 02731/03096 | Training loss: 1.058675 | Training constraint: -494.746429, duals [0.01]| lrm: 0.117894| num_tokens: 1,840
Step 02732/03096 | Training loss: 1.056623 | Training constraint: -350.338745, duals [0.01]| lrm: 0.117571| num_tokens: 3,670
Step 02733/03096 | Training loss: 0.811304 | Training constraint: -374.257141, duals [0.01]| lrm: 0.117248| num_tokens: 1,283
Step 02734/03096 | Training loss: 1.276999 | Training constraint: -372.945374, duals [0.01]| lrm: 0.116925| num_tokens: 4,094
Step 02735/03096 | Training loss: 1.070787 | Training constraint: -514.576355, duals [0.01]| lrm: 0.116602| num_tokens: 5,107
Step 02736/03096 | Training loss: 1.115661 | Training constraint: -568.293823, duals [0.01]| lrm: 0.116279| num_tokens: 1,649
Step 02737/03096 | Training loss: 0.949063 | Training constraint: -251.838928, duals [0.01]| lrm: 0.115956| num_tokens: 2,711
Step 02738/03096 | Training loss: 0.950750 | Training constraint: -402.585449, duals [0.01]| lrm: 0.115633| num_tokens: 5,935
Step 02739/03096 | Training loss: 1.065497 | Training constraint: -286.185883, duals [0.01]| lrm: 0.115310| num_tokens: 2,019
Step 02740/03096 | Training loss: 1.221590 | Training constraint: -547.497925, duals [0.01]| lrm: 0.114987| num_tokens: 3,386
Step 02741/03096 | Training loss: 1.064706 | Training constraint: -407.145081, duals [0.01]| lrm: 0.114664| num_tokens: 2,482
Step 02742/03096 | Training loss: 1.039551 | Training constraint: -238.710526, duals [0.01]| lrm: 0.114341| num_tokens: 3,981
Step 02743/03096 | Training loss: 1.203824 | Training constraint: -399.484497, duals [0.01]| lrm: 0.114018| num_tokens: 4,241
Step 02744/03096 | Training loss: 0.777528 | Training constraint: -266.686401, duals [0.01]| lrm: 0.113695| num_tokens: 3,834
Step 02745/03096 | Training loss: 1.260187 | Training constraint: -505.231812, duals [0.01]| lrm: 0.113372| num_tokens: 4,096
Step 02746/03096 | Training loss: 1.038442 | Training constraint: -178.757767, duals [0.01]| lrm: 0.113049| num_tokens: 2,316
Step 02747/03096 | Training loss: 0.826498 | Training constraint: -517.886597, duals [0.01]| lrm: 0.112726| num_tokens: 3,780
Step 02748/03096 | Training loss: 1.125309 | Training constraint: -541.463318, duals [0.01]| lrm: 0.112403| num_tokens: 3,155
Step 02749/03096 | Training loss: 0.905981 | Training constraint: -291.079071, duals [0.01]| lrm: 0.112080| num_tokens: 4,431
Step 02750/03096 | Training loss: 1.162171 | Training constraint: -372.030090, duals [0.01]| lrm: 0.111757| num_tokens: 2,442
Step 02751/03096 | Training loss: 1.104845 | Training constraint: -264.132507, duals [0.01]| lrm: 0.111434| num_tokens: 7,054
Step 02752/03096 | Training loss: 0.956137 | Training constraint: -330.507477, duals [0.01]| lrm: 0.111111| num_tokens: 1,576
Step 02753/03096 | Training loss: 1.243548 | Training constraint: -307.866516, duals [0.01]| lrm: 0.110788| num_tokens: 3,128
Step 02754/03096 | Training loss: 1.247251 | Training constraint: -328.110413, duals [0.01]| lrm: 0.110465| num_tokens: 3,709
Step 02755/03096 | Training loss: 1.130876 | Training constraint: -378.852386, duals [0.01]| lrm: 0.110142| num_tokens: 4,744
Step 02756/03096 | Training loss: 0.863653 | Training constraint: -259.938049, duals [0.01]| lrm: 0.109819| num_tokens: 3,601
Step 02757/03096 | Training loss: 1.090690 | Training constraint: -431.205444, duals [0.01]| lrm: 0.109496| num_tokens: 3,101
Step 02758/03096 | Training loss: 1.070948 | Training constraint: -238.802490, duals [0.01]| lrm: 0.109173| num_tokens: 3,440
Step 02759/03096 | Training loss: 0.897793 | Training constraint: -405.625519, duals [0.01]| lrm: 0.108850| num_tokens: 3,242
Step 02760/03096 | Training loss: 0.904613 | Training constraint: -312.620331, duals [0.01]| lrm: 0.108527| num_tokens: 4,673
Step 02761/03096 | Training loss: 1.068967 | Training constraint: -437.460144, duals [0.01]| lrm: 0.108204| num_tokens: 647
Step 02762/03096 | Training loss: 1.285766 | Training constraint: -325.779053, duals [0.01]| lrm: 0.107881| num_tokens: 3,277
Step 02763/03096 | Training loss: 1.116322 | Training constraint: -446.730774, duals [0.01]| lrm: 0.107558| num_tokens: 3,474
Step 02764/03096 | Training loss: 1.169870 | Training constraint: -389.186920, duals [0.01]| lrm: 0.107235| num_tokens: 5,045
Step 02765/03096 | Training loss: 1.127076 | Training constraint: -616.969116, duals [0.01]| lrm: 0.106912| num_tokens: 2,895
Step 02766/03096 | Training loss: 1.014067 | Training constraint: -383.189758, duals [0.01]| lrm: 0.106589| num_tokens: 4,064
Step 02767/03096 | Training loss: 1.138278 | Training constraint: -462.155182, duals [0.01]| lrm: 0.106266| num_tokens: 2,734
Step 02768/03096 | Training loss: 0.927631 | Training constraint: -263.475952, duals [0.01]| lrm: 0.105943| num_tokens: 2,370
Step 02769/03096 | Training loss: 1.017277 | Training constraint: -177.458847, duals [0.01]| lrm: 0.105620| num_tokens: 2,407
Step 02770/03096 | Training loss: 0.987889 | Training constraint: -334.513702, duals [0.01]| lrm: 0.105297| num_tokens: 3,751
Step 02771/03096 | Training loss: 1.023137 | Training constraint: -400.128143, duals [0.01]| lrm: 0.104974| num_tokens: 2,590
Step 02772/03096 | Training loss: 1.285589 | Training constraint: -357.900574, duals [0.01]| lrm: 0.104651| num_tokens: 4,026
Step 02773/03096 | Training loss: 1.076578 | Training constraint: -582.684753, duals [0.01]| lrm: 0.104328| num_tokens: 3,698
Step 02774/03096 | Training loss: 0.988533 | Training constraint: -333.022400, duals [0.01]| lrm: 0.104005| num_tokens: 4,533
Step 02775/03096 | Training loss: 0.881705 | Training constraint: -274.696533, duals [0.01]| lrm: 0.103682| num_tokens: 2,384
Step 02776/03096 | Training loss: 0.856349 | Training constraint: -182.149368, duals [0.01]| lrm: 0.103359| num_tokens: 1,961
Step 02777/03096 | Training loss: 0.994698 | Training constraint: -368.570404, duals [0.01]| lrm: 0.103036| num_tokens: 2,044
Step 02778/03096 | Training loss: 1.004918 | Training constraint: -229.853943, duals [0.01]| lrm: 0.102713| num_tokens: 4,449
Step 02779/03096 | Training loss: 1.110808 | Training constraint: -316.609344, duals [0.01]| lrm: 0.102390| num_tokens: 3,953
Step 02780/03096 | Training loss: 1.097553 | Training constraint: -371.460571, duals [0.01]| lrm: 0.102067| num_tokens: 4,073
Step 02781/03096 | Training loss: 0.852302 | Training constraint: -336.475372, duals [0.01]| lrm: 0.101744| num_tokens: 2,115
Step 02782/03096 | Training loss: 1.088095 | Training constraint: -243.037094, duals [0.01]| lrm: 0.101421| num_tokens: 5,203
Step 02783/03096 | Training loss: 0.734738 | Training constraint: -356.925079, duals [0.01]| lrm: 0.101098| num_tokens: 3,849
Step 02784/03096 | Training loss: 1.006647 | Training constraint: -518.209229, duals [0.01]| lrm: 0.100775| num_tokens: 2,662
Step 02785/03096 | Training loss: 1.202880 | Training constraint: -358.143890, duals [0.01]| lrm: 0.100452| num_tokens: 3,531
Step 02786/03096 | Training loss: 0.976962 | Training constraint: -524.280029, duals [0.01]| lrm: 0.100129| num_tokens: 4,621
Step 02787/03096 | Training loss: 0.895094 | Training constraint: -356.832489, duals [0.01]| lrm: 0.099806| num_tokens: 4,738
Step 02788/03096 | Training loss: 0.845724 | Training constraint: -281.305634, duals [0.01]| lrm: 0.099483| num_tokens: 3,984
Step 02789/03096 | Training loss: 1.000547 | Training constraint: -384.869629, duals [0.01]| lrm: 0.099160| num_tokens: 2,747
Step 02790/03096 | Training loss: 0.985372 | Training constraint: -168.895523, duals [0.01]| lrm: 0.098837| num_tokens: 3,387
Step 02791/03096 | Training loss: 0.914204 | Training constraint: -420.386292, duals [0.01]| lrm: 0.098514| num_tokens: 7,581
Step 02792/03096 | Training loss: 0.786677 | Training constraint: -372.062012, duals [0.01]| lrm: 0.098191| num_tokens: 1,483
Step 02793/03096 | Training loss: 0.996070 | Training constraint: -322.902649, duals [0.01]| lrm: 0.097868| num_tokens: 3,018
Step 02794/03096 | Training loss: 1.062700 | Training constraint: -532.426392, duals [0.01]| lrm: 0.097545| num_tokens: 2,700
Step 02795/03096 | Training loss: 1.194696 | Training constraint: -438.679016, duals [0.01]| lrm: 0.097222| num_tokens: 2,749
Step 02796/03096 | Training loss: 1.129247 | Training constraint: -331.116089, duals [0.01]| lrm: 0.096899| num_tokens: 1,146
Step 02797/03096 | Training loss: 1.003649 | Training constraint: -423.004211, duals [0.01]| lrm: 0.096576| num_tokens: 3,485
Step 02798/03096 | Training loss: 1.001248 | Training constraint: -501.465210, duals [0.01]| lrm: 0.096253| num_tokens: 1,651
Step 02799/03096 | Training loss: 0.697584 | Training constraint: -313.850708, duals [0.01]| lrm: 0.095930| num_tokens: 3,363
Step 02800 | Validation loss: 1.173579
2026-01-21 14:19:50,708 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:19:50,712 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:19:50,744 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:19:50,749 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:19:50,826 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:50,863 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:51,191 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:51,213 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:51,383 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:19:51,406 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:19:51,550 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:19:51,556 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 305/1024 (29.79%)
2026-01-21 14:19:52,151 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:19:52,158 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:19:52,165 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:19:52,170 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:19:52,282 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:52,284 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:52,404 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:52,414 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:19:52,522 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:19:52,532 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:19:52,648 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:19:52,660 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:19:52,762 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:19:52,775 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 355/1024 (34.67%)
Step 02800 | mmlu_acc: 0.297852, arc_easy_acc: 0.346680
Step 02800/03096 | Training loss: 1.172904 | Training constraint: -337.057495, duals [0.01]| lrm: 0.095607| num_tokens: 2,478
Step 02801/03096 | Training loss: 0.862534 | Training constraint: -318.717438, duals [0.01]| lrm: 0.095284| num_tokens: 2,792
Step 02802/03096 | Training loss: 1.077468 | Training constraint: -305.663483, duals [0.01]| lrm: 0.094961| num_tokens: 3,347
Step 02803/03096 | Training loss: 0.976995 | Training constraint: -257.807983, duals [0.01]| lrm: 0.094638| num_tokens: 3,956
Step 02804/03096 | Training loss: 1.054983 | Training constraint: -392.853210, duals [0.01]| lrm: 0.094315| num_tokens: 4,056
Step 02805/03096 | Training loss: 0.809303 | Training constraint: -328.192474, duals [0.01]| lrm: 0.093992| num_tokens: 2,199
Step 02806/03096 | Training loss: 0.912834 | Training constraint: -329.561523, duals [0.01]| lrm: 0.093669| num_tokens: 3,677
Step 02807/03096 | Training loss: 1.068490 | Training constraint: -434.199799, duals [0.01]| lrm: 0.093346| num_tokens: 2,173
Step 02808/03096 | Training loss: 1.292422 | Training constraint: -275.656616, duals [0.01]| lrm: 0.093023| num_tokens: 3,546
Step 02809/03096 | Training loss: 1.022656 | Training constraint: -563.031860, duals [0.01]| lrm: 0.092700| num_tokens: 2,765
Step 02810/03096 | Training loss: 0.751845 | Training constraint: -525.836426, duals [0.01]| lrm: 0.092377| num_tokens: 2,153
Step 02811/03096 | Training loss: 1.019362 | Training constraint: -351.984985, duals [0.01]| lrm: 0.092054| num_tokens: 3,609
Step 02812/03096 | Training loss: 1.062629 | Training constraint: -274.486694, duals [0.01]| lrm: 0.091731| num_tokens: 4,282
Step 02813/03096 | Training loss: 0.895834 | Training constraint: -165.334885, duals [0.01]| lrm: 0.091408| num_tokens: 1,776
Step 02814/03096 | Training loss: 1.035160 | Training constraint: -514.050232, duals [0.01]| lrm: 0.091085| num_tokens: 3,344
Step 02815/03096 | Training loss: 1.190891 | Training constraint: -383.544830, duals [0.01]| lrm: 0.090762| num_tokens: 4,022
Step 02816/03096 | Training loss: 0.819972 | Training constraint: -463.586823, duals [0.01]| lrm: 0.090439| num_tokens: 3,206
Step 02817/03096 | Training loss: 0.908762 | Training constraint: -369.810333, duals [0.01]| lrm: 0.090116| num_tokens: 3,674
Step 02818/03096 | Training loss: 1.013618 | Training constraint: -357.757202, duals [0.01]| lrm: 0.089793| num_tokens: 1,693
Step 02819/03096 | Training loss: 1.128024 | Training constraint: -253.212280, duals [0.01]| lrm: 0.089470| num_tokens: 2,306
Step 02820/03096 | Training loss: 1.001681 | Training constraint: -241.978607, duals [0.01]| lrm: 0.089147| num_tokens: 4,612
Step 02821/03096 | Training loss: 1.135416 | Training constraint: -436.628113, duals [0.01]| lrm: 0.088824| num_tokens: 4,570
Step 02822/03096 | Training loss: 0.833727 | Training constraint: -306.427795, duals [0.01]| lrm: 0.088501| num_tokens: 4,327
Step 02823/03096 | Training loss: 0.787181 | Training constraint: -264.942352, duals [0.01]| lrm: 0.088178| num_tokens: 2,405
Step 02824/03096 | Training loss: 1.116639 | Training constraint: -269.482452, duals [0.01]| lrm: 0.087855| num_tokens: 893
Step 02825/03096 | Training loss: 0.973484 | Training constraint: -542.443115, duals [0.01]| lrm: 0.087532| num_tokens: 2,615
Step 02826/03096 | Training loss: 1.048820 | Training constraint: -417.421753, duals [0.01]| lrm: 0.087209| num_tokens: 2,453
Step 02827/03096 | Training loss: 1.047056 | Training constraint: -338.920410, duals [0.01]| lrm: 0.086886| num_tokens: 3,675
Step 02828/03096 | Training loss: 0.986445 | Training constraint: -319.618042, duals [0.01]| lrm: 0.086563| num_tokens: 3,037
Step 02829/03096 | Training loss: 0.902537 | Training constraint: -296.991577, duals [0.01]| lrm: 0.086240| num_tokens: 3,446
Step 02830/03096 | Training loss: 1.160071 | Training constraint: -329.438416, duals [0.01]| lrm: 0.085917| num_tokens: 5,175
Step 02831/03096 | Training loss: 1.245481 | Training constraint: -338.133484, duals [0.01]| lrm: 0.085594| num_tokens: 3,706
Step 02832/03096 | Training loss: 0.838051 | Training constraint: -346.689178, duals [0.01]| lrm: 0.085271| num_tokens: 2,213
Step 02833/03096 | Training loss: 0.854848 | Training constraint: -311.837891, duals [0.01]| lrm: 0.084948| num_tokens: 2,210
Step 02834/03096 | Training loss: 0.946446 | Training constraint: -280.588013, duals [0.01]| lrm: 0.084625| num_tokens: 2,604
Step 02835/03096 | Training loss: 1.084935 | Training constraint: -366.854492, duals [0.01]| lrm: 0.084302| num_tokens: 3,391
Step 02836/03096 | Training loss: 1.019203 | Training constraint: -325.419434, duals [0.01]| lrm: 0.083979| num_tokens: 3,742
Step 02837/03096 | Training loss: 0.924881 | Training constraint: -429.215149, duals [0.01]| lrm: 0.083656| num_tokens: 1,564
Step 02838/03096 | Training loss: 1.050448 | Training constraint: -305.520416, duals [0.01]| lrm: 0.083333| num_tokens: 6,063
Step 02839/03096 | Training loss: 1.037866 | Training constraint: -212.176620, duals [0.01]| lrm: 0.083010| num_tokens: 3,628
Step 02840/03096 | Training loss: 0.970173 | Training constraint: -482.249481, duals [0.01]| lrm: 0.082687| num_tokens: 2,742
Step 02841/03096 | Training loss: 0.879690 | Training constraint: -142.703903, duals [0.01]| lrm: 0.082364| num_tokens: 1,966
Step 02842/03096 | Training loss: 1.018939 | Training constraint: -401.126709, duals [0.01]| lrm: 0.082041| num_tokens: 3,719
Step 02843/03096 | Training loss: 1.008734 | Training constraint: -277.684814, duals [0.01]| lrm: 0.081718| num_tokens: 1,886
Step 02844/03096 | Training loss: 1.089761 | Training constraint: -218.448624, duals [0.01]| lrm: 0.081395| num_tokens: 4,205
Step 02845/03096 | Training loss: 0.817414 | Training constraint: -206.568924, duals [0.01]| lrm: 0.081072| num_tokens: 2,211
Step 02846/03096 | Training loss: 1.067365 | Training constraint: -334.582733, duals [0.01]| lrm: 0.080749| num_tokens: 5,295
Step 02847/03096 | Training loss: 1.057724 | Training constraint: -380.058624, duals [0.01]| lrm: 0.080426| num_tokens: 2,752
Step 02848/03096 | Training loss: 1.308527 | Training constraint: -271.228058, duals [0.01]| lrm: 0.080103| num_tokens: 5,401
Step 02849/03096 | Training loss: 1.072825 | Training constraint: -300.497742, duals [0.01]| lrm: 0.079780| num_tokens: 2,367
Step 02850/03096 | Training loss: 0.922172 | Training constraint: -411.361450, duals [0.01]| lrm: 0.079457| num_tokens: 4,234
Step 02851/03096 | Training loss: 1.331388 | Training constraint: -262.681854, duals [0.01]| lrm: 0.079134| num_tokens: 2,824
Step 02852/03096 | Training loss: 0.558111 | Training constraint: -507.545288, duals [0.01]| lrm: 0.078811| num_tokens: 1,518
Step 02853/03096 | Training loss: 1.129652 | Training constraint: -297.148438, duals [0.01]| lrm: 0.078488| num_tokens: 1,464
Step 02854/03096 | Training loss: 1.110669 | Training constraint: -338.167877, duals [0.01]| lrm: 0.078165| num_tokens: 2,867
Step 02855/03096 | Training loss: 1.330056 | Training constraint: -390.800842, duals [0.01]| lrm: 0.077842| num_tokens: 4,025
Step 02856/03096 | Training loss: 1.247535 | Training constraint: -263.476837, duals [0.01]| lrm: 0.077519| num_tokens: 2,538
Step 02857/03096 | Training loss: 0.947843 | Training constraint: -396.857147, duals [0.01]| lrm: 0.077196| num_tokens: 1,997
Step 02858/03096 | Training loss: 0.877037 | Training constraint: -319.421204, duals [0.01]| lrm: 0.076873| num_tokens: 3,927
Step 02859/03096 | Training loss: 0.897798 | Training constraint: -470.797180, duals [0.01]| lrm: 0.076550| num_tokens: 5,046
Step 02860/03096 | Training loss: 1.032768 | Training constraint: -214.229919, duals [0.01]| lrm: 0.076227| num_tokens: 2,768
Step 02861/03096 | Training loss: 0.876490 | Training constraint: -300.617523, duals [0.01]| lrm: 0.075904| num_tokens: 4,709
Step 02862/03096 | Training loss: 0.961667 | Training constraint: -325.840393, duals [0.01]| lrm: 0.075581| num_tokens: 5,193
Step 02863/03096 | Training loss: 0.697031 | Training constraint: -507.622803, duals [0.01]| lrm: 0.075258| num_tokens: 3,663
Step 02864/03096 | Training loss: 1.043740 | Training constraint: -362.773987, duals [0.01]| lrm: 0.074935| num_tokens: 801
Step 02865/03096 | Training loss: 0.850735 | Training constraint: -438.739929, duals [0.01]| lrm: 0.074612| num_tokens: 3,342
Step 02866/03096 | Training loss: 1.082933 | Training constraint: -236.541946, duals [0.01]| lrm: 0.074289| num_tokens: 5,181
Step 02867/03096 | Training loss: 1.064174 | Training constraint: -296.218933, duals [0.01]| lrm: 0.073966| num_tokens: 2,747
Step 02868/03096 | Training loss: 0.850066 | Training constraint: -191.027130, duals [0.01]| lrm: 0.073643| num_tokens: 3,209
Step 02869/03096 | Training loss: 0.956182 | Training constraint: -478.142822, duals [0.01]| lrm: 0.073320| num_tokens: 4,873
Step 02870/03096 | Training loss: 0.805470 | Training constraint: -570.060486, duals [0.01]| lrm: 0.072997| num_tokens: 4,092
Step 02871/03096 | Training loss: 1.121986 | Training constraint: -273.218109, duals [0.01]| lrm: 0.072674| num_tokens: 3,277
Step 02872/03096 | Training loss: 0.826382 | Training constraint: -163.165070, duals [0.01]| lrm: 0.072351| num_tokens: 3,350
Step 02873/03096 | Training loss: 0.883064 | Training constraint: -331.853180, duals [0.01]| lrm: 0.072028| num_tokens: 4,861
Step 02874/03096 | Training loss: 0.965596 | Training constraint: -548.984558, duals [0.01]| lrm: 0.071705| num_tokens: 939
Step 02875/03096 | Training loss: 0.999577 | Training constraint: -338.940247, duals [0.01]| lrm: 0.071382| num_tokens: 3,497
Step 02876/03096 | Training loss: 0.971400 | Training constraint: -445.699341, duals [0.01]| lrm: 0.071059| num_tokens: 3,095
Step 02877/03096 | Training loss: 1.027130 | Training constraint: -289.984253, duals [0.01]| lrm: 0.070736| num_tokens: 3,529
Step 02878/03096 | Training loss: 1.238374 | Training constraint: -545.963501, duals [0.01]| lrm: 0.070413| num_tokens: 2,321
Step 02879/03096 | Training loss: 0.952894 | Training constraint: -291.854431, duals [0.01]| lrm: 0.070090| num_tokens: 3,354
Step 02880/03096 | Training loss: 1.064011 | Training constraint: -354.550537, duals [0.01]| lrm: 0.069767| num_tokens: 4,066
Step 02881/03096 | Training loss: 0.990364 | Training constraint: -223.061905, duals [0.01]| lrm: 0.069444| num_tokens: 4,693
Step 02882/03096 | Training loss: 1.022181 | Training constraint: -225.064407, duals [0.01]| lrm: 0.069121| num_tokens: 1,965
Step 02883/03096 | Training loss: 0.979249 | Training constraint: -314.988190, duals [0.01]| lrm: 0.068798| num_tokens: 5,248
Step 02884/03096 | Training loss: 0.873553 | Training constraint: -326.042297, duals [0.01]| lrm: 0.068475| num_tokens: 3,043
Step 02885/03096 | Training loss: 1.037954 | Training constraint: -473.469208, duals [0.01]| lrm: 0.068152| num_tokens: 3,196
Step 02886/03096 | Training loss: 0.953338 | Training constraint: -229.691040, duals [0.01]| lrm: 0.067829| num_tokens: 3,132
Step 02887/03096 | Training loss: 0.987806 | Training constraint: -327.707764, duals [0.01]| lrm: 0.067506| num_tokens: 5,108
Step 02888/03096 | Training loss: 0.881786 | Training constraint: -291.862183, duals [0.01]| lrm: 0.067183| num_tokens: 2,793
Step 02889/03096 | Training loss: 1.081489 | Training constraint: -229.634277, duals [0.01]| lrm: 0.066860| num_tokens: 2,928
Step 02890/03096 | Training loss: 1.134013 | Training constraint: -307.304993, duals [0.01]| lrm: 0.066537| num_tokens: 6,180
Step 02891/03096 | Training loss: 0.595609 | Training constraint: -40.684139, duals [0.01]| lrm: 0.066214| num_tokens: 2,503
Step 02892/03096 | Training loss: 1.122895 | Training constraint: -314.397217, duals [0.01]| lrm: 0.065891| num_tokens: 5,253
Step 02893/03096 | Training loss: 1.204339 | Training constraint: -284.545837, duals [0.01]| lrm: 0.065568| num_tokens: 2,543
Step 02894/03096 | Training loss: 0.992421 | Training constraint: -284.661621, duals [0.01]| lrm: 0.065245| num_tokens: 2,700
Step 02895/03096 | Training loss: 0.975269 | Training constraint: -429.550568, duals [0.01]| lrm: 0.064922| num_tokens: 5,169
Step 02896/03096 | Training loss: 1.116273 | Training constraint: -265.992004, duals [0.01]| lrm: 0.064599| num_tokens: 1,682
Step 02897/03096 | Training loss: 0.945795 | Training constraint: -927.738403, duals [0.01]| lrm: 0.064276| num_tokens: 2,597
Step 02898/03096 | Training loss: 1.097780 | Training constraint: -215.900604, duals [0.01]| lrm: 0.063953| num_tokens: 2,640
Step 02899/03096 | Training loss: 0.890120 | Training constraint: -275.248718, duals [0.01]| lrm: 0.063630| num_tokens: 8,261
Step 02900 | Validation loss: 1.173767
Step 02900/03096 | Training loss: 1.290217 | Training constraint: -331.784790, duals [0.01]| lrm: 0.063307| num_tokens: 3,916
Step 02901/03096 | Training loss: 1.283434 | Training constraint: -293.802704, duals [0.01]| lrm: 0.062984| num_tokens: 3,973
Step 02902/03096 | Training loss: 1.013898 | Training constraint: -302.064117, duals [0.01]| lrm: 0.062661| num_tokens: 5,447
Step 02903/03096 | Training loss: 1.145995 | Training constraint: -543.386536, duals [0.01]| lrm: 0.062339| num_tokens: 3,512
Step 02904/03096 | Training loss: 1.010665 | Training constraint: -314.718628, duals [0.01]| lrm: 0.062016| num_tokens: 4,128
Step 02905/03096 | Training loss: 0.938419 | Training constraint: -462.206573, duals [0.01]| lrm: 0.061693| num_tokens: 2,489
Step 02906/03096 | Training loss: 1.126724 | Training constraint: -269.305389, duals [0.01]| lrm: 0.061370| num_tokens: 6,504
Step 02907/03096 | Training loss: 1.129267 | Training constraint: -414.035034, duals [0.01]| lrm: 0.061047| num_tokens: 3,262
Step 02908/03096 | Training loss: 1.150394 | Training constraint: -531.862366, duals [0.01]| lrm: 0.060724| num_tokens: 2,768
Step 02909/03096 | Training loss: 1.017257 | Training constraint: -500.001221, duals [0.01]| lrm: 0.060401| num_tokens: 2,510
Step 02910/03096 | Training loss: 1.138663 | Training constraint: -464.088959, duals [0.01]| lrm: 0.060078| num_tokens: 3,353
Step 02911/03096 | Training loss: 1.341503 | Training constraint: -341.956604, duals [0.01]| lrm: 0.059755| num_tokens: 3,371
Step 02912/03096 | Training loss: 1.101895 | Training constraint: -330.557770, duals [0.01]| lrm: 0.059432| num_tokens: 4,712
Step 02913/03096 | Training loss: 0.963310 | Training constraint: -562.804443, duals [0.01]| lrm: 0.059109| num_tokens: 2,917
Step 02914/03096 | Training loss: 1.257872 | Training constraint: -339.402679, duals [0.01]| lrm: 0.058786| num_tokens: 1,848
Step 02915/03096 | Training loss: 1.048756 | Training constraint: -554.622192, duals [0.01]| lrm: 0.058463| num_tokens: 3,746
Step 02916/03096 | Training loss: 0.959067 | Training constraint: -176.161591, duals [0.01]| lrm: 0.058140| num_tokens: 3,246
Step 02917/03096 | Training loss: 1.046611 | Training constraint: -269.780304, duals [0.01]| lrm: 0.057817| num_tokens: 6,301
Step 02918/03096 | Training loss: 1.066960 | Training constraint: -218.408691, duals [0.01]| lrm: 0.057494| num_tokens: 2,472
Step 02919/03096 | Training loss: 0.911323 | Training constraint: -284.016235, duals [0.01]| lrm: 0.057171| num_tokens: 2,413
Step 02920/03096 | Training loss: 0.667755 | Training constraint: -313.907898, duals [0.01]| lrm: 0.056848| num_tokens: 2,915
Step 02921/03096 | Training loss: 0.826880 | Training constraint: -329.138397, duals [0.01]| lrm: 0.056525| num_tokens: 4,417
Step 02922/03096 | Training loss: 1.318837 | Training constraint: -366.934052, duals [0.01]| lrm: 0.056202| num_tokens: 4,815
Step 02923/03096 | Training loss: 1.018619 | Training constraint: -486.331116, duals [0.01]| lrm: 0.055879| num_tokens: 2,165
Step 02924/03096 | Training loss: 0.792678 | Training constraint: -372.501465, duals [0.01]| lrm: 0.055556| num_tokens: 2,725
Step 02925/03096 | Training loss: 1.263051 | Training constraint: -433.512115, duals [0.01]| lrm: 0.055233| num_tokens: 4,663
Step 02926/03096 | Training loss: 0.942263 | Training constraint: -349.899872, duals [0.01]| lrm: 0.054910| num_tokens: 1,816
Step 02927/03096 | Training loss: 1.036040 | Training constraint: -338.480133, duals [0.01]| lrm: 0.054587| num_tokens: 6,121
Step 02928/03096 | Training loss: 1.190461 | Training constraint: -426.119995, duals [0.01]| lrm: 0.054264| num_tokens: 2,918
Step 02929/03096 | Training loss: 0.882927 | Training constraint: -390.810303, duals [0.01]| lrm: 0.053941| num_tokens: 3,134
Step 02930/03096 | Training loss: 0.968362 | Training constraint: -284.950562, duals [0.01]| lrm: 0.053618| num_tokens: 5,436
Step 02931/03096 | Training loss: 1.382757 | Training constraint: -241.843658, duals [0.01]| lrm: 0.053295| num_tokens: 5,292
Step 02932/03096 | Training loss: 0.760521 | Training constraint: -405.380249, duals [0.01]| lrm: 0.052972| num_tokens: 1,712
Step 02933/03096 | Training loss: 0.950747 | Training constraint: -380.850830, duals [0.01]| lrm: 0.052649| num_tokens: 1,902
Step 02934/03096 | Training loss: 0.830373 | Training constraint: -386.740417, duals [0.01]| lrm: 0.052326| num_tokens: 5,052
Step 02935/03096 | Training loss: 1.352316 | Training constraint: -413.660522, duals [0.01]| lrm: 0.052003| num_tokens: 1,895
Step 02936/03096 | Training loss: 0.764804 | Training constraint: -453.336792, duals [0.01]| lrm: 0.051680| num_tokens: 1,455
Step 02937/03096 | Training loss: 1.100563 | Training constraint: -354.736542, duals [0.01]| lrm: 0.051357| num_tokens: 1,883
Step 02938/03096 | Training loss: 1.231337 | Training constraint: -221.166687, duals [0.01]| lrm: 0.051034| num_tokens: 804
Step 02939/03096 | Training loss: 0.957781 | Training constraint: -276.061279, duals [0.01]| lrm: 0.050711| num_tokens: 1,688
Step 02940/03096 | Training loss: 1.168835 | Training constraint: -217.303299, duals [0.01]| lrm: 0.050388| num_tokens: 2,960
Step 02941/03096 | Training loss: 0.899895 | Training constraint: -242.806961, duals [0.01]| lrm: 0.050065| num_tokens: 2,567
Step 02942/03096 | Training loss: 0.879446 | Training constraint: -438.432678, duals [0.01]| lrm: 0.049742| num_tokens: 2,475
Step 02943/03096 | Training loss: 0.988233 | Training constraint: -487.920349, duals [0.01]| lrm: 0.049419| num_tokens: 4,329
Step 02944/03096 | Training loss: 0.856639 | Training constraint: -218.870071, duals [0.01]| lrm: 0.049096| num_tokens: 2,451
Step 02945/03096 | Training loss: 0.843688 | Training constraint: -422.017487, duals [0.01]| lrm: 0.048773| num_tokens: 1,654
Step 02946/03096 | Training loss: 1.234231 | Training constraint: -260.349945, duals [0.01]| lrm: 0.048450| num_tokens: 4,521
Step 02947/03096 | Training loss: 0.793119 | Training constraint: -456.635010, duals [0.01]| lrm: 0.048127| num_tokens: 2,907
Step 02948/03096 | Training loss: 0.957716 | Training constraint: -286.717651, duals [0.01]| lrm: 0.047804| num_tokens: 3,232
Step 02949/03096 | Training loss: 1.076019 | Training constraint: -422.323120, duals [0.01]| lrm: 0.047481| num_tokens: 2,071
Step 02950/03096 | Training loss: 1.089259 | Training constraint: -132.403687, duals [0.01]| lrm: 0.047158| num_tokens: 2,371
Step 02951/03096 | Training loss: 0.933989 | Training constraint: -410.522583, duals [0.01]| lrm: 0.046835| num_tokens: 4,696
Step 02952/03096 | Training loss: 1.255418 | Training constraint: -388.790039, duals [0.01]| lrm: 0.046512| num_tokens: 3,255
Step 02953/03096 | Training loss: 0.885567 | Training constraint: -450.004425, duals [0.01]| lrm: 0.046189| num_tokens: 2,906
Step 02954/03096 | Training loss: 0.880930 | Training constraint: -392.501099, duals [0.01]| lrm: 0.045866| num_tokens: 2,661
Step 02955/03096 | Training loss: 1.107373 | Training constraint: -335.054108, duals [0.01]| lrm: 0.045543| num_tokens: 3,727
Step 02956/03096 | Training loss: 0.766409 | Training constraint: -344.377075, duals [0.01]| lrm: 0.045220| num_tokens: 2,489
Step 02957/03096 | Training loss: 0.961879 | Training constraint: -357.305115, duals [0.01]| lrm: 0.044897| num_tokens: 3,687
Step 02958/03096 | Training loss: 1.212097 | Training constraint: -414.980286, duals [0.01]| lrm: 0.044574| num_tokens: 4,492
Step 02959/03096 | Training loss: 0.939799 | Training constraint: -247.726974, duals [0.01]| lrm: 0.044251| num_tokens: 3,932
Step 02960/03096 | Training loss: 1.141008 | Training constraint: -387.942017, duals [0.01]| lrm: 0.043928| num_tokens: 2,880
Step 02961/03096 | Training loss: 1.128377 | Training constraint: -347.428314, duals [0.01]| lrm: 0.043605| num_tokens: 1,792
Step 02962/03096 | Training loss: 1.105717 | Training constraint: -325.833923, duals [0.01]| lrm: 0.043282| num_tokens: 2,900
Step 02963/03096 | Training loss: 0.963938 | Training constraint: -355.369171, duals [0.01]| lrm: 0.042959| num_tokens: 2,663
Step 02964/03096 | Training loss: 1.114287 | Training constraint: -500.632629, duals [0.01]| lrm: 0.042636| num_tokens: 4,090
Step 02965/03096 | Training loss: 0.898317 | Training constraint: -448.737030, duals [0.01]| lrm: 0.042313| num_tokens: 1,569
Step 02966/03096 | Training loss: 1.026545 | Training constraint: -388.189758, duals [0.01]| lrm: 0.041990| num_tokens: 2,109
Step 02967/03096 | Training loss: 1.091663 | Training constraint: -248.158859, duals [0.01]| lrm: 0.041667| num_tokens: 5,579
Step 02968/03096 | Training loss: 1.114751 | Training constraint: -317.589264, duals [0.01]| lrm: 0.041344| num_tokens: 3,365
Step 02969/03096 | Training loss: 1.086557 | Training constraint: -288.220154, duals [0.01]| lrm: 0.041021| num_tokens: 2,449
Step 02970/03096 | Training loss: 1.049392 | Training constraint: -437.570679, duals [0.01]| lrm: 0.040698| num_tokens: 4,638
Step 02971/03096 | Training loss: 1.231418 | Training constraint: -394.493103, duals [0.01]| lrm: 0.040375| num_tokens: 5,086
Step 02972/03096 | Training loss: 0.711365 | Training constraint: -442.911560, duals [0.01]| lrm: 0.040052| num_tokens: 3,344
Step 02973/03096 | Training loss: 0.760127 | Training constraint: -247.163528, duals [0.01]| lrm: 0.039729| num_tokens: 2,225
Step 02974/03096 | Training loss: 0.914304 | Training constraint: -287.542480, duals [0.01]| lrm: 0.039406| num_tokens: 2,214
Step 02975/03096 | Training loss: 1.098543 | Training constraint: -414.466370, duals [0.01]| lrm: 0.039083| num_tokens: 4,309
Step 02976/03096 | Training loss: 1.191324 | Training constraint: -413.726929, duals [0.01]| lrm: 0.038760| num_tokens: 5,172
Step 02977/03096 | Training loss: 1.024744 | Training constraint: -240.626404, duals [0.01]| lrm: 0.038437| num_tokens: 7,052
Step 02978/03096 | Training loss: 0.992651 | Training constraint: -354.600739, duals [0.01]| lrm: 0.038114| num_tokens: 7,101
Step 02979/03096 | Training loss: 0.875782 | Training constraint: -309.297363, duals [0.01]| lrm: 0.037791| num_tokens: 2,877
Step 02980/03096 | Training loss: 1.094075 | Training constraint: -324.060608, duals [0.01]| lrm: 0.037468| num_tokens: 3,345
Step 02981/03096 | Training loss: 0.895313 | Training constraint: -288.610748, duals [0.01]| lrm: 0.037145| num_tokens: 2,994
Step 02982/03096 | Training loss: 0.826724 | Training constraint: -315.433167, duals [0.01]| lrm: 0.036822| num_tokens: 4,081
Step 02983/03096 | Training loss: 0.882542 | Training constraint: -308.623840, duals [0.01]| lrm: 0.036499| num_tokens: 2,219
Step 02984/03096 | Training loss: 0.826704 | Training constraint: -333.113708, duals [0.01]| lrm: 0.036176| num_tokens: 2,331
Step 02985/03096 | Training loss: 0.981938 | Training constraint: -397.984467, duals [0.01]| lrm: 0.035853| num_tokens: 2,765
Step 02986/03096 | Training loss: 1.020657 | Training constraint: -213.335754, duals [0.01]| lrm: 0.035530| num_tokens: 2,316
Step 02987/03096 | Training loss: 0.854795 | Training constraint: -325.766907, duals [0.01]| lrm: 0.035207| num_tokens: 3,151
Step 02988/03096 | Training loss: 1.013977 | Training constraint: -370.406738, duals [0.01]| lrm: 0.034884| num_tokens: 2,979
Step 02989/03096 | Training loss: 0.831958 | Training constraint: -205.198349, duals [0.01]| lrm: 0.034561| num_tokens: 990
Step 02990/03096 | Training loss: 1.061952 | Training constraint: -370.990112, duals [0.01]| lrm: 0.034238| num_tokens: 4,689
Step 02991/03096 | Training loss: 0.873211 | Training constraint: -215.359879, duals [0.01]| lrm: 0.033915| num_tokens: 2,660
Step 02992/03096 | Training loss: 1.163528 | Training constraint: -278.030365, duals [0.01]| lrm: 0.033592| num_tokens: 3,508
Step 02993/03096 | Training loss: 0.978693 | Training constraint: -331.710052, duals [0.01]| lrm: 0.033269| num_tokens: 2,301
Step 02994/03096 | Training loss: 1.069276 | Training constraint: -341.597626, duals [0.01]| lrm: 0.032946| num_tokens: 2,264
Step 02995/03096 | Training loss: 0.965570 | Training constraint: -343.908325, duals [0.01]| lrm: 0.032623| num_tokens: 1,369
Step 02996/03096 | Training loss: 1.110191 | Training constraint: -344.781311, duals [0.01]| lrm: 0.032300| num_tokens: 2,062
Step 02997/03096 | Training loss: 1.052660 | Training constraint: -414.905701, duals [0.01]| lrm: 0.031977| num_tokens: 2,227
Step 02998/03096 | Training loss: 0.932306 | Training constraint: -349.721680, duals [0.01]| lrm: 0.031654| num_tokens: 5,074
Step 02999/03096 | Training loss: 1.030868 | Training constraint: -281.845154, duals [0.01]| lrm: 0.031331| num_tokens: 3,959
Step 03000 | Validation loss: 1.173914
2026-01-21 14:20:28,712 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:20:28,712 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:20:28,716 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:20:28,717 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:20:28,831 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:28,832 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:29,178 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:29,197 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:29,369 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:20:29,389 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:20:29,516 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:20:29,536 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 309/1024 (30.18%)
2026-01-21 14:20:30,123 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:20:30,124 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:20:30,128 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:20:30,129 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:20:30,239 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:30,243 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:30,361 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:30,411 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:30,481 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:20:30,546 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:20:30,607 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:20:30,669 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:20:30,722 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:20:30,783 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 357/1024 (34.86%)
Step 03000 | mmlu_acc: 0.301758, arc_easy_acc: 0.348633
Step 03000/03096 | Training loss: 1.101473 | Training constraint: -285.320068, duals [0.01]| lrm: 0.031008| num_tokens: 3,629
Step 03001/03096 | Training loss: 0.963356 | Training constraint: -404.573547, duals [0.01]| lrm: 0.030685| num_tokens: 4,145
Step 03002/03096 | Training loss: 1.016604 | Training constraint: -297.706635, duals [0.01]| lrm: 0.030362| num_tokens: 5,043
Step 03003/03096 | Training loss: 0.931722 | Training constraint: -228.443115, duals [0.01]| lrm: 0.030039| num_tokens: 4,965
Step 03004/03096 | Training loss: 1.019556 | Training constraint: -265.359314, duals [0.01]| lrm: 0.029716| num_tokens: 1,544
Step 03005/03096 | Training loss: 0.754480 | Training constraint: -414.437866, duals [0.01]| lrm: 0.029393| num_tokens: 2,974
Step 03006/03096 | Training loss: 1.036148 | Training constraint: -376.755188, duals [0.01]| lrm: 0.029070| num_tokens: 1,610
Step 03007/03096 | Training loss: 0.827765 | Training constraint: -310.776428, duals [0.01]| lrm: 0.028747| num_tokens: 2,088
Step 03008/03096 | Training loss: 1.066343 | Training constraint: -415.620117, duals [0.01]| lrm: 0.028424| num_tokens: 4,054
Step 03009/03096 | Training loss: 0.973097 | Training constraint: -285.260101, duals [0.01]| lrm: 0.028101| num_tokens: 2,673
Step 03010/03096 | Training loss: 1.212464 | Training constraint: -232.841705, duals [0.01]| lrm: 0.027778| num_tokens: 3,044
Step 03011/03096 | Training loss: 1.128284 | Training constraint: -253.556625, duals [0.01]| lrm: 0.027455| num_tokens: 1,702
Step 03012/03096 | Training loss: 1.100102 | Training constraint: -302.853699, duals [0.01]| lrm: 0.027132| num_tokens: 1,809
Step 03013/03096 | Training loss: 1.194278 | Training constraint: -335.913330, duals [0.01]| lrm: 0.026809| num_tokens: 5,674
Step 03014/03096 | Training loss: 0.699203 | Training constraint: -338.931946, duals [0.01]| lrm: 0.026486| num_tokens: 4,694
Step 03015/03096 | Training loss: 1.025780 | Training constraint: -329.468506, duals [0.01]| lrm: 0.026163| num_tokens: 1,904
Step 03016/03096 | Training loss: 0.967059 | Training constraint: -307.054565, duals [0.01]| lrm: 0.025840| num_tokens: 1,590
Step 03017/03096 | Training loss: 1.096479 | Training constraint: -458.239349, duals [0.01]| lrm: 0.025517| num_tokens: 3,015
Step 03018/03096 | Training loss: 1.024391 | Training constraint: -272.007141, duals [0.01]| lrm: 0.025194| num_tokens: 2,338
Step 03019/03096 | Training loss: 1.031851 | Training constraint: -418.131073, duals [0.01]| lrm: 0.024871| num_tokens: 2,246
Step 03020/03096 | Training loss: 1.010886 | Training constraint: -242.111282, duals [0.01]| lrm: 0.024548| num_tokens: 1,288
Step 03021/03096 | Training loss: 1.185317 | Training constraint: -477.777527, duals [0.01]| lrm: 0.024225| num_tokens: 1,871
Step 03022/03096 | Training loss: 1.176920 | Training constraint: -488.421448, duals [0.01]| lrm: 0.023902| num_tokens: 4,915
Step 03023/03096 | Training loss: 1.137129 | Training constraint: -194.296753, duals [0.01]| lrm: 0.023579| num_tokens: 2,533
Step 03024/03096 | Training loss: 1.013286 | Training constraint: -386.060913, duals [0.01]| lrm: 0.023256| num_tokens: 2,542
Step 03025/03096 | Training loss: 1.068634 | Training constraint: -358.319672, duals [0.01]| lrm: 0.022933| num_tokens: 1,997
Step 03026/03096 | Training loss: 1.180490 | Training constraint: -310.077515, duals [0.01]| lrm: 0.022610| num_tokens: 4,403
Step 03027/03096 | Training loss: 1.366474 | Training constraint: -354.586334, duals [0.01]| lrm: 0.022287| num_tokens: 2,707
Step 03028/03096 | Training loss: 1.173236 | Training constraint: -420.869110, duals [0.01]| lrm: 0.021964| num_tokens: 4,619
Step 03029/03096 | Training loss: 1.010544 | Training constraint: -407.169250, duals [0.01]| lrm: 0.021641| num_tokens: 1,747
Step 03030/03096 | Training loss: 0.868451 | Training constraint: -284.479004, duals [0.01]| lrm: 0.021318| num_tokens: 3,117
Step 03031/03096 | Training loss: 1.116005 | Training constraint: -292.254089, duals [0.01]| lrm: 0.020995| num_tokens: 1,835
Step 03032/03096 | Training loss: 1.149789 | Training constraint: -360.816132, duals [0.01]| lrm: 0.020672| num_tokens: 6,001
Step 03033/03096 | Training loss: 1.261474 | Training constraint: -424.560913, duals [0.01]| lrm: 0.020349| num_tokens: 987
Step 03034/03096 | Training loss: 0.777970 | Training constraint: -443.829803, duals [0.01]| lrm: 0.020026| num_tokens: 2,541
Step 03035/03096 | Training loss: 0.916765 | Training constraint: -335.433716, duals [0.01]| lrm: 0.019703| num_tokens: 2,020
Step 03036/03096 | Training loss: 1.199646 | Training constraint: -406.631592, duals [0.01]| lrm: 0.019380| num_tokens: 4,942
Step 03037/03096 | Training loss: 1.182301 | Training constraint: -444.446716, duals [0.01]| lrm: 0.019057| num_tokens: 5,062
Step 03038/03096 | Training loss: 0.936956 | Training constraint: -250.225204, duals [0.01]| lrm: 0.018734| num_tokens: 2,935
Step 03039/03096 | Training loss: 1.089378 | Training constraint: -165.995392, duals [0.01]| lrm: 0.018411| num_tokens: 2,138
Step 03040/03096 | Training loss: 1.299672 | Training constraint: -542.217041, duals [0.01]| lrm: 0.018088| num_tokens: 3,252
Step 03041/03096 | Training loss: 1.173507 | Training constraint: -254.319885, duals [0.01]| lrm: 0.017765| num_tokens: 3,120
Step 03042/03096 | Training loss: 0.810264 | Training constraint: -290.723236, duals [0.01]| lrm: 0.017442| num_tokens: 2,197
Step 03043/03096 | Training loss: 0.986939 | Training constraint: -310.180054, duals [0.01]| lrm: 0.017119| num_tokens: 3,302
Step 03044/03096 | Training loss: 1.277240 | Training constraint: -513.669617, duals [0.01]| lrm: 0.016796| num_tokens: 4,066
Step 03045/03096 | Training loss: 0.989780 | Training constraint: -326.500336, duals [0.01]| lrm: 0.016473| num_tokens: 4,789
Step 03046/03096 | Training loss: 0.893555 | Training constraint: -334.403137, duals [0.01]| lrm: 0.016150| num_tokens: 2,970
Step 03047/03096 | Training loss: 0.933389 | Training constraint: -365.934540, duals [0.01]| lrm: 0.015827| num_tokens: 3,810
Step 03048/03096 | Training loss: 0.668161 | Training constraint: -214.320145, duals [0.01]| lrm: 0.015504| num_tokens: 2,833
Step 03049/03096 | Training loss: 1.173193 | Training constraint: -424.790283, duals [0.01]| lrm: 0.015181| num_tokens: 2,915
Step 03050/03096 | Training loss: 1.219788 | Training constraint: -496.078308, duals [0.01]| lrm: 0.014858| num_tokens: 4,093
Step 03051/03096 | Training loss: 0.986090 | Training constraint: -405.282959, duals [0.01]| lrm: 0.014535| num_tokens: 2,626
Step 03052/03096 | Training loss: 1.094953 | Training constraint: -374.621368, duals [0.01]| lrm: 0.014212| num_tokens: 4,995
Step 03053/03096 | Training loss: 1.314121 | Training constraint: -325.707825, duals [0.01]| lrm: 0.013889| num_tokens: 3,680
Step 03054/03096 | Training loss: 0.931216 | Training constraint: -220.866531, duals [0.01]| lrm: 0.013566| num_tokens: 4,440
Step 03055/03096 | Training loss: 1.000120 | Training constraint: -426.099182, duals [0.01]| lrm: 0.013243| num_tokens: 2,925
Step 03056/03096 | Training loss: 1.078644 | Training constraint: -311.714783, duals [0.01]| lrm: 0.012920| num_tokens: 1,662
Step 03057/03096 | Training loss: 0.956292 | Training constraint: -468.874420, duals [0.01]| lrm: 0.012597| num_tokens: 2,555
Step 03058/03096 | Training loss: 1.030499 | Training constraint: -178.832306, duals [0.01]| lrm: 0.012274| num_tokens: 1,695
Step 03059/03096 | Training loss: 1.197952 | Training constraint: -388.748352, duals [0.01]| lrm: 0.011951| num_tokens: 3,056
Step 03060/03096 | Training loss: 1.229220 | Training constraint: -335.932831, duals [0.01]| lrm: 0.011628| num_tokens: 3,268
Step 03061/03096 | Training loss: 0.922189 | Training constraint: -470.983459, duals [0.01]| lrm: 0.011305| num_tokens: 1,827
Step 03062/03096 | Training loss: 1.136118 | Training constraint: -201.112656, duals [0.01]| lrm: 0.010982| num_tokens: 2,845
Step 03063/03096 | Training loss: 0.769058 | Training constraint: -492.648743, duals [0.01]| lrm: 0.010659| num_tokens: 3,465
Step 03064/03096 | Training loss: 0.974501 | Training constraint: -267.189087, duals [0.01]| lrm: 0.010336| num_tokens: 2,242
Step 03065/03096 | Training loss: 0.832816 | Training constraint: -341.951050, duals [0.01]| lrm: 0.010013| num_tokens: 645
Step 03066/03096 | Training loss: 0.952016 | Training constraint: -492.416626, duals [0.01]| lrm: 0.009690| num_tokens: 3,310
Step 03067/03096 | Training loss: 1.067643 | Training constraint: -287.539001, duals [0.01]| lrm: 0.009367| num_tokens: 3,378
Step 03068/03096 | Training loss: 1.071001 | Training constraint: -476.618225, duals [0.01]| lrm: 0.009044| num_tokens: 2,214
Step 03069/03096 | Training loss: 1.038651 | Training constraint: -206.337341, duals [0.01]| lrm: 0.008721| num_tokens: 3,730
Step 03070/03096 | Training loss: 1.173327 | Training constraint: -500.500610, duals [0.01]| lrm: 0.008398| num_tokens: 4,524
Step 03071/03096 | Training loss: 1.116543 | Training constraint: -402.336914, duals [0.01]| lrm: 0.008075| num_tokens: 2,326
Step 03072/03096 | Training loss: 0.956133 | Training constraint: -406.661407, duals [0.01]| lrm: 0.007752| num_tokens: 1,422
Step 03073/03096 | Training loss: 0.999250 | Training constraint: -243.240753, duals [0.01]| lrm: 0.007429| num_tokens: 3,405
Step 03074/03096 | Training loss: 1.175054 | Training constraint: -310.518219, duals [0.01]| lrm: 0.007106| num_tokens: 4,940
Step 03075/03096 | Training loss: 0.831311 | Training constraint: -378.158630, duals [0.01]| lrm: 0.006783| num_tokens: 3,558
Step 03076/03096 | Training loss: 1.069117 | Training constraint: -201.441956, duals [0.01]| lrm: 0.006460| num_tokens: 1,300
Step 03077/03096 | Training loss: 0.929105 | Training constraint: -312.217010, duals [0.01]| lrm: 0.006137| num_tokens: 3,575
Step 03078/03096 | Training loss: 1.008169 | Training constraint: -406.106140, duals [0.01]| lrm: 0.005814| num_tokens: 2,391
Step 03079/03096 | Training loss: 1.233908 | Training constraint: -308.601013, duals [0.01]| lrm: 0.005491| num_tokens: 3,021
Step 03080/03096 | Training loss: 0.811873 | Training constraint: -192.240265, duals [0.01]| lrm: 0.005168| num_tokens: 3,083
Step 03081/03096 | Training loss: 1.326633 | Training constraint: -409.832947, duals [0.01]| lrm: 0.004845| num_tokens: 2,869
Step 03082/03096 | Training loss: 1.119046 | Training constraint: -353.903015, duals [0.01]| lrm: 0.004522| num_tokens: 2,093
Step 03083/03096 | Training loss: 0.989614 | Training constraint: -537.570068, duals [0.01]| lrm: 0.004199| num_tokens: 4,359
Step 03084/03096 | Training loss: 1.145402 | Training constraint: -417.270416, duals [0.01]| lrm: 0.003876| num_tokens: 2,771
Step 03085/03096 | Training loss: 0.860639 | Training constraint: -385.428284, duals [0.01]| lrm: 0.003553| num_tokens: 4,788
Step 03086/03096 | Training loss: 1.003327 | Training constraint: -399.110443, duals [0.01]| lrm: 0.003230| num_tokens: 3,511
Step 03087/03096 | Training loss: 0.872206 | Training constraint: -472.618225, duals [0.01]| lrm: 0.002907| num_tokens: 4,792
Step 03088/03096 | Training loss: 1.187600 | Training constraint: -266.987030, duals [0.01]| lrm: 0.002584| num_tokens: 4,908
Step 03089/03096 | Training loss: 1.030853 | Training constraint: -286.995270, duals [0.01]| lrm: 0.002261| num_tokens: 2,859
Step 03090/03096 | Training loss: 0.992282 | Training constraint: -407.950317, duals [0.01]| lrm: 0.001938| num_tokens: 3,269
Step 03091/03096 | Training loss: 1.082666 | Training constraint: -309.141693, duals [0.01]| lrm: 0.001615| num_tokens: 1,643
Step 03092/03096 | Training loss: 1.030798 | Training constraint: -210.063110, duals [0.01]| lrm: 0.001292| num_tokens: 7,140
Step 03093/03096 | Training loss: 0.901475 | Training constraint: -345.368713, duals [0.01]| lrm: 0.000969| num_tokens: 3,805
Step 03094/03096 | Training loss: 1.144830 | Training constraint: -310.846130, duals [0.01]| lrm: 0.000646| num_tokens: 4,150
Step 03095 | Validation loss: 1.173947
2026-01-21 14:20:47,921 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:20:47,924 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:20:47,925 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:20:47,928 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/cais/mmlu/c30699e8356da336a370243923dbaf21066bb9fe/README.md "HTTP/1.1 200 OK"
2026-01-21 14:20:48,040 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:48,042 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:48,380 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:48,391 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/cais/mmlu/cais/mmlu.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:48,572 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:20:48,585 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/cais/mmlu/resolve/c30699e8356da336a370243923dbaf21066bb9fe/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:20:48,714 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
2026-01-21 14:20:48,728 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=cais/mmlu "HTTP/1.1 200 OK"
Final: 310/1024 (30.27%)
2026-01-21 14:20:49,308 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:20:49,309 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:20:49,313 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:20:49,313 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/allenai/ai2_arc/210d026faf9955653af8916fad021475a3f00453/README.md "HTTP/1.1 200 OK"
2026-01-21 14:20:49,426 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:49,427 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:49,541 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:49,543 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/allenai/ai2_arc/allenai/ai2_arc.py "HTTP/1.1 404 Not Found"
2026-01-21 14:20:49,657 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:20:49,662 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:20:49,782 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:20:49,787 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=allenai/ai2_arc "HTTP/1.1 200 OK"
2026-01-21 14:20:49,897 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:20:49,900 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/allenai/ai2_arc/resolve/210d026faf9955653af8916fad021475a3f00453/dataset_infos.json "HTTP/1.1 404 Not Found"
Final: 357/1024 (34.86%)
Step 03095 | mmlu_acc: 0.302734, arc_easy_acc: 0.348633
2026-01-21 14:20:52,913 - nanochat.checkpoint_manager - [32m[1mINFO[0m - Saved model parameters to: /home/kliacand/.cache/nanochat/chatsft_checkpoints/d12_constr_br_pbm/model_003095.pt
2026-01-21 14:20:52,915 - nanochat.checkpoint_manager - [32m[1mINFO[0m - Saved metadata to: /home/kliacand/.cache/nanochat/chatsft_checkpoints/d12_constr_br_pbm/meta_003095.json
‚úÖ Saved model checkpoint to /home/kliacand/.cache/nanochat/chatsft_checkpoints/d12_constr_br_pbm
[W121 14:20:53.218305254 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[W121 14:20:53.480427146 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
Autodetected device type: cuda
2026-01-21 14:21:01,543 - nanochat.common - [32m[1mINFO[0m - Distributed world size: 2
2026-01-21 14:21:01,544 - nanochat.checkpoint_manager - [32m[1mINFO[0m - Loading model from /home/kliacand/.cache/nanochat/chatsft_checkpoints/d12_constr_br_pbm with step 3095
2026-01-21 14:21:06,651 - nanochat.checkpoint_manager - [32m[1mINFO[0m - Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 12, 'n_head': 6, 'n_kv_head': 6, 'n_embd': 768, 'window_pattern': 'L'}
2026-01-21 14:21:06,693 - nanochat.checkpoint_manager - [32m[1mINFO[0m - loaded state dict
2026-01-21 14:21:06,860 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/OpenCoder-LLM/opc-sft-stage2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:21:06,864 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/OpenCoder-LLM/opc-sft-stage2/7d28f40d579edd7c24402d17d0c7639f991e6f8d/README.md "HTTP/1.1 200 OK"
2026-01-21 14:21:06,906 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/OpenCoder-LLM/opc-sft-stage2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-01-21 14:21:06,910 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/OpenCoder-LLM/opc-sft-stage2/7d28f40d579edd7c24402d17d0c7639f991e6f8d/README.md "HTTP/1.1 200 OK"
2026-01-21 14:21:06,985 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/OpenCoder-LLM/opc-sft-stage2/resolve/7d28f40d579edd7c24402d17d0c7639f991e6f8d/opc-sft-stage2.py "HTTP/1.1 404 Not Found"
2026-01-21 14:21:07,023 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/OpenCoder-LLM/opc-sft-stage2/resolve/7d28f40d579edd7c24402d17d0c7639f991e6f8d/opc-sft-stage2.py "HTTP/1.1 404 Not Found"
2026-01-21 14:21:07,332 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/OpenCoder-LLM/opc-sft-stage2/OpenCoder-LLM/opc-sft-stage2.py "HTTP/1.1 404 Not Found"
2026-01-21 14:21:07,395 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/OpenCoder-LLM/opc-sft-stage2/OpenCoder-LLM/opc-sft-stage2.py "HTTP/1.1 404 Not Found"
2026-01-21 14:21:07,506 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/OpenCoder-LLM/opc-sft-stage2/revision/7d28f40d579edd7c24402d17d0c7639f991e6f8d "HTTP/1.1 200 OK"
2026-01-21 14:21:07,513 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/OpenCoder-LLM/opc-sft-stage2/revision/7d28f40d579edd7c24402d17d0c7639f991e6f8d "HTTP/1.1 200 OK"
2026-01-21 14:21:07,641 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/OpenCoder-LLM/opc-sft-stage2/resolve/7d28f40d579edd7c24402d17d0c7639f991e6f8d/.huggingface.yaml "HTTP/1.1 404 Not Found"
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-01-21 14:21:07,641 - huggingface_hub.utils._http - [33m[1mWARNING[0m - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-01-21 14:21:07,647 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/OpenCoder-LLM/opc-sft-stage2/resolve/7d28f40d579edd7c24402d17d0c7639f991e6f8d/.huggingface.yaml "HTTP/1.1 404 Not Found"
2026-01-21 14:21:07,776 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=OpenCoder-LLM/opc-sft-stage2 "HTTP/1.1 200 OK"
2026-01-21 14:21:07,781 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=OpenCoder-LLM/opc-sft-stage2 "HTTP/1.1 200 OK"
2026-01-21 14:21:07,983 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/OpenCoder-LLM/opc-sft-stage2/tree/7d28f40d579edd7c24402d17d0c7639f991e6f8d/educational_instruct?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:21:08,001 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/OpenCoder-LLM/opc-sft-stage2/tree/7d28f40d579edd7c24402d17d0c7639f991e6f8d/educational_instruct?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:21:08,199 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/OpenCoder-LLM/opc-sft-stage2/tree/7d28f40d579edd7c24402d17d0c7639f991e6f8d?recursive=false&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:21:08,319 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/OpenCoder-LLM/opc-sft-stage2/tree/7d28f40d579edd7c24402d17d0c7639f991e6f8d?recursive=false&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:21:08,426 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/OpenCoder-LLM/opc-sft-stage2/resolve/7d28f40d579edd7c24402d17d0c7639f991e6f8d/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:21:08,432 - httpx - [32m[1mINFO[0m - HTTP Request: HEAD https://huggingface.co/datasets/OpenCoder-LLM/opc-sft-stage2/resolve/7d28f40d579edd7c24402d17d0c7639f991e6f8d/dataset_infos.json "HTTP/1.1 404 Not Found"
2026-01-21 14:21:08,776 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/OpenCoder-LLM/opc-sft-stage2/tree/7d28f40d579edd7c24402d17d0c7639f991e6f8d/evol_instruct?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-21 14:21:08,786 - httpx - [32m[1mINFO[0m - HTTP Request: GET https://huggingface.co/api/datasets/OpenCoder-LLM/opc-sft-stage2/tree/7d28f40d579edd7c24402d17d0c7639f991e6f8d/evol_instruct?recursive=true&expand=false "HTTP/1.1 200 OK"
[KRank 0 | 0/1 (0.00%)[KRank 1 | 0/1 (0.00%)[KRank 1 | 0/2 (0.00%)[KRank 1 | 0/3 (0.00%)[KRank 0 | 0/2 (0.00%)[KRank 1 | 0/4 (0.00%)[KRank 1 | 0/5 (0.00%)[KRank 0 | 0/3 (0.00%)[KRank 1 | 0/6 (0.00%)[KRank 0 | 0/4 (0.00%)[KRank 1 | 0/7 (0.00%)[KRank 0 | 0/5 (0.00%)[KRank 1 | 0/8 (0.00%)[KRank 0 | 0/6 (0.00%)[KRank 1 | 0/9 (0.00%)[KRank 1 | 0/10 (0.00%)[KRank 0 | 0/7 (0.00%)[KRank 1 | 0/11 (0.00%)[KRank 0 | 0/8 (0.00%)[KRank 1 | 0/12 (0.00%)[KRank 0 | 0/9 (0.00%)[KRank 1 | 0/13 (0.00%)[KRank 0 | 0/10 (0.00%)[KRank 1 | 0/14 (0.00%)[KRank 0 | 0/11 (0.00%)[KRank 1 | 0/15 (0.00%)[KRank 0 | 0/12 (0.00%)[KRank 1 | 0/16 (0.00%)[KRank 0 | 0/13 (0.00%)[KRank 0 | 0/14 (0.00%)[KRank 1 | 0/17 (0.00%)[KRank 0 | 0/15 (0.00%)[KRank 1 | 0/18 (0.00%)[KRank 1 | 0/19 (0.00%)[KRank 0 | 0/16 (0.00%)[KRank 1 | 0/20 (0.00%)[KRank 0 | 0/17 (0.00%)[KRank 1 | 0/21 (0.00%)[KRank 1 | 0/22 (0.00%)[KRank 0 | 0/18 (0.00%)[KRank 1 | 0/23 (0.00%)[KRank 0 | 0/19 (0.00%)[KRank 1 | 0/24 (0.00%)[KRank 0 | 0/20 (0.00%)[KRank 1 | 0/25 (0.00%)[KRank 0 | 0/21 (0.00%)[KRank 1 | 0/26 (0.00%)[KRank 0 | 0/22 (0.00%)[KRank 1 | 0/27 (0.00%)[KRank 1 | 0/28 (0.00%)[KRank 0 | 0/23 (0.00%)[KRank 1 | 0/29 (0.00%)[KRank 0 | 0/24 (0.00%)[KRank 1 | 0/30 (0.00%)[KRank 0 | 0/25 (0.00%)[KRank 1 | 0/31 (0.00%)[KRank 0 | 0/26 (0.00%)[KRank 1 | 0/32 (0.00%)[KRank 0 | 0/27 (0.00%)[KRank 1 | 0/33 (0.00%)[KRank 0 | 0/28 (0.00%)[KRank 1 | 0/34 (0.00%)[KRank 0 | 0/29 (0.00%)[KRank 1 | 0/35 (0.00%)[KRank 0 | 0/30 (0.00%)[KRank 0 | 0/31 (0.00%)[KRank 1 | 0/36 (0.00%)[KRank 0 | 0/32 (0.00%)[KRank 1 | 0/37 (0.00%)[KRank 0 | 0/33 (0.00%)[KRank 1 | 0/38 (0.00%)[KRank 0 | 0/34 (0.00%)[KRank 1 | 0/39 (0.00%)[KRank 0 | 0/35 (0.00%)[KRank 0 | 0/36 (0.00%)[KRank 1 | 0/40 (0.00%)[KRank 0 | 0/37 (0.00%)[KRank 1 | 0/41 (0.00%)[KRank 0 | 0/38 (0.00%)[KRank 1 | 0/42 (0.00%)[KRank 0 | 0/39 (0.00%)[KRank 1 | 0/43 (0.00%)[KRank 1 | 0/44 (0.00%)[KRank 1 | 0/45 (0.00%)[KRank 0 | 0/40 (0.00%)[KRank 1 | 0/46 (0.00%)[KRank 0 | 0/41 (0.00%)[KRank 1 | 0/47 (0.00%)[KRank 0 | 0/42 (0.00%)[KRank 1 | 0/48 (0.00%)[KRank 0 | 0/43 (0.00%)[KRank 1 | 0/49 (0.00%)[KRank 1 | 0/50 (0.00%)[KRank 0 | 0/44 (0.00%)[KRank 1 | 0/51 (0.00%)[KRank 0 | 0/45 (0.00%)[KRank 1 | 0/52 (0.00%)[KRank 0 | 0/46 (0.00%)[KRank 1 | 0/53 (0.00%)[KRank 1 | 0/54 (0.00%)[KRank 1 | 0/55 (0.00%)[KRank 0 | 0/47 (0.00%)[KRank 1 | 0/56 (0.00%)[KRank 0 | 0/48 (0.00%)[KRank 1 | 0/57 (0.00%)[KRank 0 | 0/49 (0.00%)[KRank 1 | 0/58 (0.00%)[KRank 1 | 0/59 (0.00%)[KRank 0 | 0/50 (0.00%)[KRank 0 | 0/51 (0.00%)[KRank 1 | 0/60 (0.00%)[KRank 0 | 0/52 (0.00%)[KRank 1 | 0/61 (0.00%)[KRank 1 | 0/62 (0.00%)[KRank 0 | 0/53 (0.00%)[KRank 1 | 0/63 (0.00%)[KRank 0 | 0/54 (0.00%)[KRank 0 | 0/55 (0.00%)[KRank 1 | 0/64 (0.00%)[KRank 0 | 0/56 (0.00%)[KRank 1 | 0/65 (0.00%)[KRank 1 | 0/66 (0.00%)[KRank 0 | 0/57 (0.00%)[KRank 1 | 0/67 (0.00%)[KRank 0 | 0/58 (0.00%)[KRank 1 | 0/68 (0.00%)[KRank 0 | 0/59 (0.00%)[KRank 1 | 0/69 (0.00%)[KRank 0 | 0/60 (0.00%)[KRank 0 | 0/61 (0.00%)[KRank 1 | 0/70 (0.00%)[KRank 0 | 0/62 (0.00%)[KRank 0 | 0/63 (0.00%)[KRank 1 | 0/71 (0.00%)[KRank 0 | 0/64 (0.00%)[KRank 0 | 0/65 (0.00%)[KRank 1 | 0/72 (0.00%)[KRank 0 | 0/66 (0.00%)[KRank 1 | 0/73 (0.00%)[KRank 0 | 0/67 (0.00%)[KRank 1 | 0/74 (0.00%)[KRank 0 | 0/68 (0.00%)[KRank 1 | 0/75 (0.00%)[KRank 0 | 0/69 (0.00%)[KRank 1 | 0/76 (0.00%)[KRank 0 | 0/70 (0.00%)[KRank 1 | 0/77 (0.00%)[KRank 0 | 0/71 (0.00%)[KRank 1 | 0/78 (0.00%)[KRank 0 | 0/72 (0.00%)[KRank 1 | 0/79 (0.00%)[KRank 0 | 0/73 (0.00%)[KRank 1 | 0/80 (0.00%)[KRank 0 | 0/74 (0.00%)[KRank 0 | 0/75 (0.00%)[KRank 1 | 0/81 (0.00%)[KRank 0 | 0/76 (0.00%)[KRank 1 | 0/82 (0.00%)[KRank 0 | 0/77 (0.00%)[KRank 1 | 0/83 (0.00%)[KRank 1 | 0/84 (0.00%)[KRank 0 | 0/78 (0.00%)[KRank 0 | 0/79 (0.00%)[KRank 1 | 0/85 (0.00%)[KRank 0 | 0/80 (0.00%)[KRank 0 | 0/81 (0.00%)[KRank 1 | 0/86 (0.00%)[KRank 0 | 0/82 (0.00%)[KRank 1 | 0/87 (0.00%)[KRank 1 | 0/88 (0.00%)[KRank 1 | 0/89 (0.00%)[KRank 0 | 0/83 (0.00%)[KRank 1 | 0/90 (0.00%)[KRank 0 | 0/84 (0.00%)[KRank 0 | 0/85 (0.00%)[KRank 0 | 0/86 (0.00%)[KRank 1 | 0/91 (0.00%)[KRank 1 | 0/92 (0.00%)[KRank 0 | 0/87 (0.00%)[KRank 1 | 0/93 (0.00%)[KRank 0 | 0/88 (0.00%)[KRank 1 | 0/94 (0.00%)[KRank 0 | 0/89 (0.00%)[KRank 0 | 0/90 (0.00%)[KRank 1 | 0/95 (0.00%)[KRank 1 | 0/96 (0.00%)[KRank 0 | 0/91 (0.00%)[KRank 0 | 0/92 (0.00%)[KRank 1 | 0/97 (0.00%)[KRank 0 | 0/93 (0.00%)[KRank 1 | 0/98 (0.00%)[KRank 1 | 0/99 (0.00%)[KRank 0 | 0/94 (0.00%)[KRank 1 | 0/100 (0.00%)[KRank 0 | 0/95 (0.00%)[KRank 1 | 0/101 (0.00%)[KRank 0 | 0/96 (0.00%)[KRank 1 | 0/102 (0.00%)[KRank 0 | 0/97 (0.00%)[KRank 0 | 0/98 (0.00%)[KRank 1 | 0/103 (0.00%)[KRank 0 | 0/99 (0.00%)[KRank 1 | 0/104 (0.00%)[KRank 1 | 0/105 (0.00%)[KRank 0 | 0/100 (0.00%)[KRank 1 | 0/106 (0.00%)[KRank 0 | 0/101 (0.00%)[KRank 1 | 0/107 (0.00%)[KRank 0 | 0/102 (0.00%)[KRank 1 | 0/108 (0.00%)[KRank 0 | 0/103 (0.00%)[KRank 1 | 0/109 (0.00%)[KRank 0 | 0/104 (0.00%)[KRank 0 | 0/105 (0.00%)[KRank 1 | 0/110 (0.00%)[KRank 0 | 0/106 (0.00%)[KRank 1 | 0/111 (0.00%)[KRank 0 | 0/107 (0.00%)[KRank 1 | 0/112 (0.00%)[KRank 1 | 0/113 (0.00%)[KRank 0 | 0/108 (0.00%)[KRank 1 | 0/114 (0.00%)[KRank 0 | 0/109 (0.00%)[KRank 1 | 0/115 (0.00%)[KRank 0 | 0/110 (0.00%)[KRank 1 | 0/116 (0.00%)[KRank 0 | 0/111 (0.00%)[KRank 1 | 0/117 (0.00%)[KRank 0 | 0/112 (0.00%)[KRank 1 | 0/118 (0.00%)[KRank 0 | 0/113 (0.00%)[KRank 1 | 0/119 (0.00%)[KRank 0 | 0/114 (0.00%)[KRank 0 | 0/115 (0.00%)[KRank 1 | 0/120 (0.00%)[KRank 0 | 0/116 (0.00%)[KRank 1 | 0/121 (0.00%)[KRank 0 | 0/117 (0.00%)[KRank 1 | 0/122 (0.00%)[KRank 1 | 0/123 (0.00%)[KRank 0 | 0/118 (0.00%)[KRank 0 | 0/119 (0.00%)[KRank 1 | 0/124 (0.00%)[KRank 1 | 0/125 (0.00%)[KRank 0 | 0/120 (0.00%)[KRank 1 | 0/126 (0.00%)[KRank 0 | 0/121 (0.00%)[KRank 1 | 0/127 (0.00%)[KRank 1 | 0/128 (0.00%)[KRank 0 | 0/122 (0.00%)[KRank 0 | 0/123 (0.00%)[KRank 1 | 0/129 (0.00%)[KRank 0 | 0/124 (0.00%)[KRank 1 | 0/130 (0.00%)[KRank 0 | 0/125 (0.00%)[KRank 1 | 0/131 (0.00%)[KRank 0 | 0/126 (0.00%)[KRank 1 | 0/132 (0.00%)[KRank 1 | 0/133 (0.00%)[KRank 0 | 0/127 (0.00%)[KRank 1 | 0/134 (0.00%)[KRank 0 | 0/128 (0.00%)[KRank 0 | 0/129 (0.00%)[KRank 1 | 0/135 (0.00%)[KRank 0 | 0/130 (0.00%)[KRank 1 | 0/136 (0.00%)[KRank 1 | 0/137 (0.00%)[KRank 0 | 0/131 (0.00%)[KRank 1 | 0/138 (0.00%)[KRank 0 | 0/132 (0.00%)[KRank 1 | 0/139 (0.00%)[KRank 0 | 0/133 (0.00%)[KRank 1 | 0/140 (0.00%)[KRank 0 | 0/134 (0.00%)[KRank 1 | 0/141 (0.00%)[KRank 0 | 0/135 (0.00%)[KRank 1 | 0/142 (0.00%)[KRank 0 | 0/136 (0.00%)[KRank 1 | 0/143 (0.00%)[KRank 0 | 0/137 (0.00%)[KRank 1 | 0/144 (0.00%)[KRank 1 | 0/145 (0.00%)[KRank 0 | 0/138 (0.00%)[KRank 1 | 0/146 (0.00%)[KRank 0 | 0/139 (0.00%)[KRank 0 | 0/140 (0.00%)[KRank 0 | 0/141 (0.00%)[KRank 0 | 0/142 (0.00%)[KRank 1 | 0/147 (0.00%)[KRank 1 | 0/148 (0.00%)[KRank 0 | 0/143 (0.00%)[KRank 1 | 0/149 (0.00%)[KRank 0 | 0/144 (0.00%)[KRank 1 | 0/150 (0.00%)
[KRank 0 | 0/145 (0.00%)[KRank 0 | 0/146 (0.00%)[KRank 0 | 0/147 (0.00%)[KRank 0 | 0/148 (0.00%)[KRank 0 | 0/149 (0.00%)[KRank 0 | 0/150 (0.00%)
==================================================
Final: 0/300 (0.00%)
OpenCoder accuracy: 0.00%
